{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - Classification\n",
    "Using the top 10 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"top10_df.pkl\", \"rb\") as fp:\n",
    "    df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "features_df = df.drop([\"Decision\"], 1)\n",
    "\n",
    "scaled_df = pd.DataFrame(scaler.fit_transform(features_df), \n",
    "                               index=features_df.index, \n",
    "                               columns=features_df.columns)\n",
    "\n",
    "df = scaled_df.join(df.Decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, test, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"Decision\"], 1)\n",
    "y = df.Decision\n",
    "\n",
    "# Train, test, split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(results):\n",
    "    \"\"\"\n",
    "    Plots the loss and accuracy for the training and testing data\n",
    "    \"\"\"\n",
    "    history = results.history\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.plot(history['loss'])\n",
    "    plt.legend(['val_loss', 'loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.legend(['val_accuracy', 'accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling - NN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_175 (Dense)            (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 90)                9090      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 80)                7280      \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 60)                4260      \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 50)                3050      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 61,001\n",
      "Trainable params: 61,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instatiating the model\n",
    "model = Sequential()\n",
    "\n",
    "activ = \"relu\"\n",
    "# Input Layer\n",
    "model.add(Dense(100, activation=activ,input_shape=(X.shape[1],)))\n",
    "\n",
    "# Hidden Layers (11)\n",
    "model.add(Dense(100, activation=activ))\n",
    "model.add(Dense(90, activation=activ))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(80, activation=activ))\n",
    "model.add(Dense(70, activation=activ))\n",
    "model.add(Dense(60, activation=activ))\n",
    "model.add(Dense(50, activation=activ))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(50, activation=activ))\n",
    "model.add(Dense(50, activation=activ))\n",
    "model.add(Dense(50, activation=activ))\n",
    "model.add(Dense(50, activation=activ))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation=activ))\n",
    "model.add(Dense(50, activation=activ))\n",
    "model.add(Dense(50, activation=activ))\n",
    "model.add(Dense(50, activation=activ))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32958 samples, validate on 10986 samples\n",
      "Epoch 1/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.6121 - accuracy: 0.3735 - val_loss: 0.6227 - val_accuracy: 0.3584\n",
      "Epoch 2/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.6124 - accuracy: 0.3724 - val_loss: 0.6197 - val_accuracy: 0.3668\n",
      "Epoch 3/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.6114 - accuracy: 0.3736 - val_loss: 0.6265 - val_accuracy: 0.3514\n",
      "Epoch 4/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.6112 - accuracy: 0.3732 - val_loss: 0.6182 - val_accuracy: 0.3612\n",
      "Epoch 5/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.6094 - accuracy: 0.3770 - val_loss: 0.6232 - val_accuracy: 0.3585\n",
      "Epoch 6/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.6092 - accuracy: 0.3733 - val_loss: 0.6230 - val_accuracy: 0.3530\n",
      "Epoch 7/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.6088 - accuracy: 0.3764 - val_loss: 0.6205 - val_accuracy: 0.3687\n",
      "Epoch 8/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.6080 - accuracy: 0.3757 - val_loss: 0.6228 - val_accuracy: 0.3564\n",
      "Epoch 9/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.6096 - accuracy: 0.3745 - val_loss: 0.6188 - val_accuracy: 0.3627\n",
      "Epoch 10/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.6117 - accuracy: 0.3768 - val_loss: 0.6200 - val_accuracy: 0.3615\n",
      "Epoch 11/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.6069 - accuracy: 0.3744 - val_loss: 0.6228 - val_accuracy: 0.3533\n",
      "Epoch 12/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.6078 - accuracy: 0.3761 - val_loss: 0.6288 - val_accuracy: 0.3631\n",
      "Epoch 13/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.6066 - accuracy: 0.3773 - val_loss: 0.6237 - val_accuracy: 0.3530\n",
      "Epoch 14/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.6065 - accuracy: 0.3762 - val_loss: 0.6195 - val_accuracy: 0.3555\n",
      "Epoch 15/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.6092 - accuracy: 0.3765 - val_loss: 0.6209 - val_accuracy: 0.3609\n",
      "Epoch 16/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.6053 - accuracy: 0.3769 - val_loss: 0.6180 - val_accuracy: 0.3621\n",
      "Epoch 17/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.6059 - accuracy: 0.3757 - val_loss: 0.6203 - val_accuracy: 0.3682\n",
      "Epoch 18/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.6043 - accuracy: 0.3779 - val_loss: 0.6253 - val_accuracy: 0.3554\n",
      "Epoch 19/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.6027 - accuracy: 0.3781 - val_loss: 0.6189 - val_accuracy: 0.3614\n",
      "Epoch 20/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.6048 - accuracy: 0.3773 - val_loss: 0.6260 - val_accuracy: 0.3480\n",
      "Epoch 21/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.6038 - accuracy: 0.3767 - val_loss: 0.6176 - val_accuracy: 0.3676\n",
      "Epoch 22/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.6029 - accuracy: 0.3808 - val_loss: 0.6192 - val_accuracy: 0.3652\n",
      "Epoch 23/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.6022 - accuracy: 0.3786 - val_loss: 0.6183 - val_accuracy: 0.3672\n",
      "Epoch 24/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.6019 - accuracy: 0.3791 - val_loss: 0.6180 - val_accuracy: 0.3719\n",
      "Epoch 25/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.6025 - accuracy: 0.3783 - val_loss: 0.6276 - val_accuracy: 0.3543\n",
      "Epoch 26/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.6004 - accuracy: 0.3781 - val_loss: 0.6166 - val_accuracy: 0.3657\n",
      "Epoch 27/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.6007 - accuracy: 0.3795 - val_loss: 0.6214 - val_accuracy: 0.3610\n",
      "Epoch 28/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5985 - accuracy: 0.3822 - val_loss: 0.6189 - val_accuracy: 0.3636\n",
      "Epoch 29/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.5992 - accuracy: 0.3802 - val_loss: 0.6197 - val_accuracy: 0.3637\n",
      "Epoch 30/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5985 - accuracy: 0.3802 - val_loss: 0.6218 - val_accuracy: 0.3617\n",
      "Epoch 31/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5987 - accuracy: 0.3791 - val_loss: 0.6191 - val_accuracy: 0.3695\n",
      "Epoch 32/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.5989 - accuracy: 0.3810 - val_loss: 0.6174 - val_accuracy: 0.3676\n",
      "Epoch 33/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.5990 - accuracy: 0.3791 - val_loss: 0.6200 - val_accuracy: 0.3648\n",
      "Epoch 34/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5970 - accuracy: 0.3808 - val_loss: 0.6212 - val_accuracy: 0.3584\n",
      "Epoch 35/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5983 - accuracy: 0.3812 - val_loss: 0.6242 - val_accuracy: 0.3545\n",
      "Epoch 36/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5980 - accuracy: 0.3805 - val_loss: 0.6206 - val_accuracy: 0.3625\n",
      "Epoch 37/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5957 - accuracy: 0.3805 - val_loss: 0.6225 - val_accuracy: 0.3586\n",
      "Epoch 38/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5958 - accuracy: 0.3819 - val_loss: 0.6283 - val_accuracy: 0.3552\n",
      "Epoch 39/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.5954 - accuracy: 0.3808 - val_loss: 0.6251 - val_accuracy: 0.3566\n",
      "Epoch 40/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5964 - accuracy: 0.3793 - val_loss: 0.6307 - val_accuracy: 0.3587\n",
      "Epoch 41/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5930 - accuracy: 0.3829 - val_loss: 0.6214 - val_accuracy: 0.3659\n",
      "Epoch 42/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.5935 - accuracy: 0.3820 - val_loss: 0.6185 - val_accuracy: 0.3685\n",
      "Epoch 43/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5922 - accuracy: 0.3841 - val_loss: 0.6199 - val_accuracy: 0.3612\n",
      "Epoch 44/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5940 - accuracy: 0.3832 - val_loss: 0.6228 - val_accuracy: 0.3633\n",
      "Epoch 45/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5911 - accuracy: 0.3835 - val_loss: 0.6215 - val_accuracy: 0.3654\n",
      "Epoch 46/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5911 - accuracy: 0.3856 - val_loss: 0.6289 - val_accuracy: 0.3594\n",
      "Epoch 47/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5919 - accuracy: 0.3834 - val_loss: 0.6232 - val_accuracy: 0.3627\n",
      "Epoch 48/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5899 - accuracy: 0.3833 - val_loss: 0.6225 - val_accuracy: 0.3675\n",
      "Epoch 49/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5898 - accuracy: 0.3840 - val_loss: 0.6204 - val_accuracy: 0.3633\n",
      "Epoch 50/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5888 - accuracy: 0.3846 - val_loss: 0.6215 - val_accuracy: 0.3666\n",
      "Epoch 51/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5884 - accuracy: 0.3850 - val_loss: 0.6251 - val_accuracy: 0.3591\n",
      "Epoch 52/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.5870 - accuracy: 0.3841 - val_loss: 0.6221 - val_accuracy: 0.3585\n",
      "Epoch 53/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.5854 - accuracy: 0.3853 - val_loss: 0.6221 - val_accuracy: 0.3709\n",
      "Epoch 54/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5851 - accuracy: 0.3854 - val_loss: 0.6323 - val_accuracy: 0.3507\n",
      "Epoch 55/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5859 - accuracy: 0.3852 - val_loss: 0.6273 - val_accuracy: 0.3626\n",
      "Epoch 56/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5851 - accuracy: 0.3836 - val_loss: 0.6230 - val_accuracy: 0.3653\n",
      "Epoch 57/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5866 - accuracy: 0.3850 - val_loss: 0.6266 - val_accuracy: 0.3610\n",
      "Epoch 58/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5843 - accuracy: 0.3874 - val_loss: 0.6290 - val_accuracy: 0.3653\n",
      "Epoch 59/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.5842 - accuracy: 0.3867 - val_loss: 0.6250 - val_accuracy: 0.3631\n",
      "Epoch 60/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.5857 - accuracy: 0.3883 - val_loss: 0.6242 - val_accuracy: 0.3631\n",
      "Epoch 61/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.5819 - accuracy: 0.3886 - val_loss: 0.6224 - val_accuracy: 0.3676\n",
      "Epoch 62/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5824 - accuracy: 0.3889 - val_loss: 0.6293 - val_accuracy: 0.3660\n",
      "Epoch 63/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5802 - accuracy: 0.3888 - val_loss: 0.6261 - val_accuracy: 0.3665\n",
      "Epoch 64/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5793 - accuracy: 0.3881 - val_loss: 0.6318 - val_accuracy: 0.3591\n",
      "Epoch 65/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5794 - accuracy: 0.3907 - val_loss: 0.6280 - val_accuracy: 0.3642\n",
      "Epoch 66/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5779 - accuracy: 0.3893 - val_loss: 0.6339 - val_accuracy: 0.3605\n",
      "Epoch 67/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5769 - accuracy: 0.3932 - val_loss: 0.6265 - val_accuracy: 0.3650\n",
      "Epoch 68/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5784 - accuracy: 0.3917 - val_loss: 0.6245 - val_accuracy: 0.3616\n",
      "Epoch 69/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5774 - accuracy: 0.3915 - val_loss: 0.6273 - val_accuracy: 0.3676\n",
      "Epoch 70/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5770 - accuracy: 0.3922 - val_loss: 0.6260 - val_accuracy: 0.3635\n",
      "Epoch 71/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5768 - accuracy: 0.3923 - val_loss: 0.6256 - val_accuracy: 0.3670\n",
      "Epoch 72/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5791 - accuracy: 0.3900 - val_loss: 0.6313 - val_accuracy: 0.3585\n",
      "Epoch 73/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5799 - accuracy: 0.3901 - val_loss: 0.6269 - val_accuracy: 0.3696\n",
      "Epoch 74/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5744 - accuracy: 0.3956 - val_loss: 0.6286 - val_accuracy: 0.3682\n",
      "Epoch 75/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5743 - accuracy: 0.3925 - val_loss: 0.6352 - val_accuracy: 0.3644\n",
      "Epoch 76/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5726 - accuracy: 0.3946 - val_loss: 0.6350 - val_accuracy: 0.3677\n",
      "Epoch 77/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5721 - accuracy: 0.3921 - val_loss: 0.6311 - val_accuracy: 0.3664\n",
      "Epoch 78/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5732 - accuracy: 0.3941 - val_loss: 0.6330 - val_accuracy: 0.3655\n",
      "Epoch 79/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5692 - accuracy: 0.3954 - val_loss: 0.6303 - val_accuracy: 0.3676\n",
      "Epoch 80/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5695 - accuracy: 0.3948 - val_loss: 0.6367 - val_accuracy: 0.3677\n",
      "Epoch 81/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5694 - accuracy: 0.3942 - val_loss: 0.6363 - val_accuracy: 0.3673\n",
      "Epoch 82/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5687 - accuracy: 0.3983 - val_loss: 0.6438 - val_accuracy: 0.3651\n",
      "Epoch 83/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5696 - accuracy: 0.3970 - val_loss: 0.6331 - val_accuracy: 0.3709\n",
      "Epoch 84/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5683 - accuracy: 0.3982 - val_loss: 0.6325 - val_accuracy: 0.3729\n",
      "Epoch 85/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5684 - accuracy: 0.3978 - val_loss: 0.6391 - val_accuracy: 0.3680\n",
      "Epoch 86/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5645 - accuracy: 0.4025 - val_loss: 0.6325 - val_accuracy: 0.3697\n",
      "Epoch 87/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5663 - accuracy: 0.4015 - val_loss: 0.6415 - val_accuracy: 0.3679\n",
      "Epoch 88/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5686 - accuracy: 0.3981 - val_loss: 0.6386 - val_accuracy: 0.3680\n",
      "Epoch 89/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5656 - accuracy: 0.4015 - val_loss: 0.6337 - val_accuracy: 0.3705\n",
      "Epoch 90/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5618 - accuracy: 0.4068 - val_loss: 0.6482 - val_accuracy: 0.3673\n",
      "Epoch 91/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5635 - accuracy: 0.4036 - val_loss: 0.6388 - val_accuracy: 0.3661\n",
      "Epoch 92/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5617 - accuracy: 0.4066 - val_loss: 0.6345 - val_accuracy: 0.3710\n",
      "Epoch 93/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5601 - accuracy: 0.4058 - val_loss: 0.6313 - val_accuracy: 0.3647\n",
      "Epoch 94/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5600 - accuracy: 0.4057 - val_loss: 0.6345 - val_accuracy: 0.3676\n",
      "Epoch 95/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5575 - accuracy: 0.4036 - val_loss: 0.6368 - val_accuracy: 0.3716\n",
      "Epoch 96/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5607 - accuracy: 0.4074 - val_loss: 0.6342 - val_accuracy: 0.3679\n",
      "Epoch 97/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5581 - accuracy: 0.4086 - val_loss: 0.6422 - val_accuracy: 0.3727\n",
      "Epoch 98/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5605 - accuracy: 0.4081 - val_loss: 0.6333 - val_accuracy: 0.3686\n",
      "Epoch 99/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5595 - accuracy: 0.4085 - val_loss: 0.6354 - val_accuracy: 0.3687\n",
      "Epoch 100/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5573 - accuracy: 0.4116 - val_loss: 0.6509 - val_accuracy: 0.3705\n",
      "Epoch 101/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5575 - accuracy: 0.4131 - val_loss: 0.6420 - val_accuracy: 0.3662\n",
      "Epoch 102/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5564 - accuracy: 0.4100 - val_loss: 0.6435 - val_accuracy: 0.3671\n",
      "Epoch 103/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5544 - accuracy: 0.4116 - val_loss: 0.6424 - val_accuracy: 0.3634\n",
      "Epoch 104/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5566 - accuracy: 0.4091 - val_loss: 0.6388 - val_accuracy: 0.3678\n",
      "Epoch 105/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5530 - accuracy: 0.4143 - val_loss: 0.6472 - val_accuracy: 0.3661\n",
      "Epoch 106/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5531 - accuracy: 0.4155 - val_loss: 0.6398 - val_accuracy: 0.3710\n",
      "Epoch 107/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5537 - accuracy: 0.4118 - val_loss: 0.6394 - val_accuracy: 0.3655\n",
      "Epoch 108/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5538 - accuracy: 0.4160 - val_loss: 0.6458 - val_accuracy: 0.3737\n",
      "Epoch 109/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5517 - accuracy: 0.4141 - val_loss: 0.6466 - val_accuracy: 0.3682\n",
      "Epoch 110/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5491 - accuracy: 0.4175 - val_loss: 0.6501 - val_accuracy: 0.3694\n",
      "Epoch 111/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5493 - accuracy: 0.4166 - val_loss: 0.6432 - val_accuracy: 0.3688\n",
      "Epoch 112/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5487 - accuracy: 0.4188 - val_loss: 0.6513 - val_accuracy: 0.3631\n",
      "Epoch 113/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5472 - accuracy: 0.4217 - val_loss: 0.6438 - val_accuracy: 0.3666\n",
      "Epoch 114/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5491 - accuracy: 0.4150 - val_loss: 0.6458 - val_accuracy: 0.3672\n",
      "Epoch 115/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5495 - accuracy: 0.4155 - val_loss: 0.6443 - val_accuracy: 0.3656\n",
      "Epoch 116/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.5469 - accuracy: 0.4174 - val_loss: 0.6507 - val_accuracy: 0.3722\n",
      "Epoch 117/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.5451 - accuracy: 0.4206 - val_loss: 0.6518 - val_accuracy: 0.3681\n",
      "Epoch 118/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5430 - accuracy: 0.4227 - val_loss: 0.6478 - val_accuracy: 0.3645\n",
      "Epoch 119/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5448 - accuracy: 0.4197 - val_loss: 0.6521 - val_accuracy: 0.3669\n",
      "Epoch 120/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.5435 - accuracy: 0.4198 - val_loss: 0.6500 - val_accuracy: 0.3686\n",
      "Epoch 121/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.5419 - accuracy: 0.4229 - val_loss: 0.6763 - val_accuracy: 0.3658\n",
      "Epoch 122/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.5444 - accuracy: 0.4191 - val_loss: 0.6580 - val_accuracy: 0.3611\n",
      "Epoch 123/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.5425 - accuracy: 0.4235 - val_loss: 0.6553 - val_accuracy: 0.3723\n",
      "Epoch 124/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.5406 - accuracy: 0.4259 - val_loss: 0.6467 - val_accuracy: 0.3659\n",
      "Epoch 125/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.5410 - accuracy: 0.4214 - val_loss: 0.6555 - val_accuracy: 0.3697\n",
      "Epoch 126/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5419 - accuracy: 0.4240 - val_loss: 0.6560 - val_accuracy: 0.3666\n",
      "Epoch 127/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5399 - accuracy: 0.4262 - val_loss: 0.6494 - val_accuracy: 0.3716\n",
      "Epoch 128/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.5395 - accuracy: 0.4283 - val_loss: 0.6474 - val_accuracy: 0.3682\n",
      "Epoch 129/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5399 - accuracy: 0.4268 - val_loss: 0.6481 - val_accuracy: 0.3645\n",
      "Epoch 130/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.5385 - accuracy: 0.4251 - val_loss: 0.6431 - val_accuracy: 0.3693\n",
      "Epoch 131/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5373 - accuracy: 0.4265 - val_loss: 0.6535 - val_accuracy: 0.3660\n",
      "Epoch 132/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5391 - accuracy: 0.4269 - val_loss: 0.6504 - val_accuracy: 0.3684\n",
      "Epoch 133/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5379 - accuracy: 0.4276 - val_loss: 0.6501 - val_accuracy: 0.3712\n",
      "Epoch 134/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5367 - accuracy: 0.4248 - val_loss: 0.6500 - val_accuracy: 0.3721\n",
      "Epoch 135/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.5346 - accuracy: 0.4286 - val_loss: 0.6498 - val_accuracy: 0.3686\n",
      "Epoch 136/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5347 - accuracy: 0.4273 - val_loss: 0.6493 - val_accuracy: 0.3687\n",
      "Epoch 137/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5344 - accuracy: 0.4324 - val_loss: 0.6482 - val_accuracy: 0.3733\n",
      "Epoch 138/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5341 - accuracy: 0.4322 - val_loss: 0.6548 - val_accuracy: 0.3674\n",
      "Epoch 139/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5371 - accuracy: 0.4281 - val_loss: 0.6424 - val_accuracy: 0.3656\n",
      "Epoch 140/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5335 - accuracy: 0.4285 - val_loss: 0.6549 - val_accuracy: 0.3697\n",
      "Epoch 141/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5333 - accuracy: 0.4349 - val_loss: 0.6544 - val_accuracy: 0.3707\n",
      "Epoch 142/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5342 - accuracy: 0.4305 - val_loss: 0.6586 - val_accuracy: 0.3684\n",
      "Epoch 143/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5319 - accuracy: 0.4355 - val_loss: 0.6531 - val_accuracy: 0.3755\n",
      "Epoch 144/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5338 - accuracy: 0.4313 - val_loss: 0.6527 - val_accuracy: 0.3663\n",
      "Epoch 145/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5298 - accuracy: 0.4356 - val_loss: 0.6541 - val_accuracy: 0.3701\n",
      "Epoch 146/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5313 - accuracy: 0.4333 - val_loss: 0.6498 - val_accuracy: 0.3702\n",
      "Epoch 147/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5301 - accuracy: 0.4374 - val_loss: 0.6544 - val_accuracy: 0.3724\n",
      "Epoch 148/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5300 - accuracy: 0.4368 - val_loss: 0.6567 - val_accuracy: 0.3727\n",
      "Epoch 149/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5301 - accuracy: 0.4363 - val_loss: 0.6508 - val_accuracy: 0.3701\n",
      "Epoch 150/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5298 - accuracy: 0.4309 - val_loss: 0.6554 - val_accuracy: 0.3681\n",
      "Epoch 151/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5262 - accuracy: 0.4389 - val_loss: 0.6570 - val_accuracy: 0.3738\n",
      "Epoch 152/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5283 - accuracy: 0.4374 - val_loss: 0.6626 - val_accuracy: 0.3688\n",
      "Epoch 153/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5259 - accuracy: 0.4375 - val_loss: 0.6577 - val_accuracy: 0.3705\n",
      "Epoch 154/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5274 - accuracy: 0.4349 - val_loss: 0.6514 - val_accuracy: 0.3679\n",
      "Epoch 155/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5250 - accuracy: 0.4394 - val_loss: 0.6591 - val_accuracy: 0.3703\n",
      "Epoch 156/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5238 - accuracy: 0.4395 - val_loss: 0.6482 - val_accuracy: 0.3698\n",
      "Epoch 157/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5292 - accuracy: 0.4301 - val_loss: 0.6497 - val_accuracy: 0.3694\n",
      "Epoch 158/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5253 - accuracy: 0.4384 - val_loss: 0.6549 - val_accuracy: 0.3738\n",
      "Epoch 159/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5244 - accuracy: 0.4387 - val_loss: 0.6507 - val_accuracy: 0.3705\n",
      "Epoch 160/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5207 - accuracy: 0.4434 - val_loss: 0.6577 - val_accuracy: 0.3747\n",
      "Epoch 161/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5219 - accuracy: 0.4406 - val_loss: 0.6556 - val_accuracy: 0.3715\n",
      "Epoch 162/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5233 - accuracy: 0.4423 - val_loss: 0.6550 - val_accuracy: 0.3691\n",
      "Epoch 163/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5240 - accuracy: 0.4380 - val_loss: 0.6545 - val_accuracy: 0.3687\n",
      "Epoch 164/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5210 - accuracy: 0.4417 - val_loss: 0.6486 - val_accuracy: 0.3695\n",
      "Epoch 165/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5217 - accuracy: 0.4401 - val_loss: 0.6594 - val_accuracy: 0.3709\n",
      "Epoch 166/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5205 - accuracy: 0.4439 - val_loss: 0.6585 - val_accuracy: 0.3762\n",
      "Epoch 167/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.5200 - accuracy: 0.4447 - val_loss: 0.6535 - val_accuracy: 0.3699\n",
      "Epoch 168/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5204 - accuracy: 0.4437 - val_loss: 0.6531 - val_accuracy: 0.3704\n",
      "Epoch 169/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.5178 - accuracy: 0.4458 - val_loss: 0.6761 - val_accuracy: 0.3701\n",
      "Epoch 170/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5218 - accuracy: 0.4428 - val_loss: 0.6609 - val_accuracy: 0.3721\n",
      "Epoch 171/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5252 - accuracy: 0.4389 - val_loss: 0.6582 - val_accuracy: 0.3727\n",
      "Epoch 172/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5210 - accuracy: 0.4398 - val_loss: 0.6521 - val_accuracy: 0.3697\n",
      "Epoch 173/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5225 - accuracy: 0.4393 - val_loss: 0.6612 - val_accuracy: 0.3695\n",
      "Epoch 174/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.5193 - accuracy: 0.4443 - val_loss: 0.6500 - val_accuracy: 0.3678\n",
      "Epoch 175/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5193 - accuracy: 0.4443 - val_loss: 0.6535 - val_accuracy: 0.3697\n",
      "Epoch 176/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5180 - accuracy: 0.4475 - val_loss: 0.6500 - val_accuracy: 0.3698\n",
      "Epoch 177/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5148 - accuracy: 0.4494 - val_loss: 0.6535 - val_accuracy: 0.3680\n",
      "Epoch 178/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5134 - accuracy: 0.4496 - val_loss: 0.6623 - val_accuracy: 0.3751\n",
      "Epoch 179/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5158 - accuracy: 0.4511 - val_loss: 0.6601 - val_accuracy: 0.3736\n",
      "Epoch 180/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5148 - accuracy: 0.4514 - val_loss: 0.6570 - val_accuracy: 0.3742\n",
      "Epoch 181/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5160 - accuracy: 0.4488 - val_loss: 0.6599 - val_accuracy: 0.3712\n",
      "Epoch 182/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5137 - accuracy: 0.4481 - val_loss: 0.6624 - val_accuracy: 0.3686\n",
      "Epoch 183/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5170 - accuracy: 0.4447 - val_loss: 0.6563 - val_accuracy: 0.3744\n",
      "Epoch 184/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5139 - accuracy: 0.4468 - val_loss: 0.6554 - val_accuracy: 0.3720\n",
      "Epoch 185/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5164 - accuracy: 0.4473 - val_loss: 0.6591 - val_accuracy: 0.3718\n",
      "Epoch 186/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5132 - accuracy: 0.4501 - val_loss: 0.6525 - val_accuracy: 0.3692\n",
      "Epoch 187/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5123 - accuracy: 0.4483 - val_loss: 0.6715 - val_accuracy: 0.3702\n",
      "Epoch 188/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5104 - accuracy: 0.4505 - val_loss: 0.6647 - val_accuracy: 0.3714\n",
      "Epoch 189/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5098 - accuracy: 0.4539 - val_loss: 0.6632 - val_accuracy: 0.3783\n",
      "Epoch 190/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5118 - accuracy: 0.4524 - val_loss: 0.6563 - val_accuracy: 0.3739\n",
      "Epoch 191/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5105 - accuracy: 0.4519 - val_loss: 0.6636 - val_accuracy: 0.3685\n",
      "Epoch 192/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5132 - accuracy: 0.4516 - val_loss: 0.6601 - val_accuracy: 0.3690\n",
      "Epoch 193/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5106 - accuracy: 0.4494 - val_loss: 0.6602 - val_accuracy: 0.3704\n",
      "Epoch 194/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5087 - accuracy: 0.4542 - val_loss: 0.6594 - val_accuracy: 0.3733\n",
      "Epoch 195/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5095 - accuracy: 0.4497 - val_loss: 0.6677 - val_accuracy: 0.3731\n",
      "Epoch 196/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5090 - accuracy: 0.4543 - val_loss: 0.6575 - val_accuracy: 0.3726\n",
      "Epoch 197/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5084 - accuracy: 0.4561 - val_loss: 0.6593 - val_accuracy: 0.3726\n",
      "Epoch 198/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5110 - accuracy: 0.4509 - val_loss: 0.6538 - val_accuracy: 0.3703\n",
      "Epoch 199/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5112 - accuracy: 0.4518 - val_loss: 0.6658 - val_accuracy: 0.3742\n",
      "Epoch 200/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5088 - accuracy: 0.4542 - val_loss: 0.6659 - val_accuracy: 0.3699\n",
      "Epoch 201/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5063 - accuracy: 0.4551 - val_loss: 0.6606 - val_accuracy: 0.3705\n",
      "Epoch 202/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5091 - accuracy: 0.4550 - val_loss: 0.6562 - val_accuracy: 0.3751\n",
      "Epoch 203/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5065 - accuracy: 0.4550 - val_loss: 0.6612 - val_accuracy: 0.3695\n",
      "Epoch 204/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5086 - accuracy: 0.4522 - val_loss: 0.6633 - val_accuracy: 0.3763\n",
      "Epoch 205/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5065 - accuracy: 0.4561 - val_loss: 0.6584 - val_accuracy: 0.3718\n",
      "Epoch 206/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5062 - accuracy: 0.4567 - val_loss: 0.6575 - val_accuracy: 0.3719\n",
      "Epoch 207/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5068 - accuracy: 0.4544 - val_loss: 0.6637 - val_accuracy: 0.3764\n",
      "Epoch 208/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5079 - accuracy: 0.4575 - val_loss: 0.6600 - val_accuracy: 0.3787\n",
      "Epoch 209/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5056 - accuracy: 0.4593 - val_loss: 0.6721 - val_accuracy: 0.3691\n",
      "Epoch 210/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5039 - accuracy: 0.4581 - val_loss: 0.6589 - val_accuracy: 0.3713\n",
      "Epoch 211/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5027 - accuracy: 0.4617 - val_loss: 0.6548 - val_accuracy: 0.3712\n",
      "Epoch 212/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5022 - accuracy: 0.4607 - val_loss: 0.6595 - val_accuracy: 0.3709\n",
      "Epoch 213/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5033 - accuracy: 0.4592 - val_loss: 0.6629 - val_accuracy: 0.3739\n",
      "Epoch 214/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5025 - accuracy: 0.4593 - val_loss: 0.6681 - val_accuracy: 0.3747\n",
      "Epoch 215/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.5028 - accuracy: 0.4634 - val_loss: 0.6642 - val_accuracy: 0.3775\n",
      "Epoch 216/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5029 - accuracy: 0.4616 - val_loss: 0.6646 - val_accuracy: 0.3717\n",
      "Epoch 217/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5020 - accuracy: 0.4626 - val_loss: 0.6609 - val_accuracy: 0.3717\n",
      "Epoch 218/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5000 - accuracy: 0.4669 - val_loss: 0.6637 - val_accuracy: 0.3731\n",
      "Epoch 219/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5018 - accuracy: 0.4605 - val_loss: 0.6736 - val_accuracy: 0.3738\n",
      "Epoch 220/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5035 - accuracy: 0.4610 - val_loss: 0.6612 - val_accuracy: 0.3733\n",
      "Epoch 221/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5024 - accuracy: 0.4607 - val_loss: 0.6627 - val_accuracy: 0.3708\n",
      "Epoch 222/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.5000 - accuracy: 0.4631 - val_loss: 0.6684 - val_accuracy: 0.3778\n",
      "Epoch 223/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5033 - accuracy: 0.4604 - val_loss: 0.6587 - val_accuracy: 0.3711\n",
      "Epoch 224/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5036 - accuracy: 0.4582 - val_loss: 0.6618 - val_accuracy: 0.3744\n",
      "Epoch 225/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.5028 - accuracy: 0.4612 - val_loss: 0.6629 - val_accuracy: 0.3743\n",
      "Epoch 226/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4998 - accuracy: 0.4636 - val_loss: 0.6598 - val_accuracy: 0.3730\n",
      "Epoch 227/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4997 - accuracy: 0.4659 - val_loss: 0.6585 - val_accuracy: 0.3739\n",
      "Epoch 228/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5009 - accuracy: 0.4621 - val_loss: 0.6565 - val_accuracy: 0.3725\n",
      "Epoch 229/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.5013 - accuracy: 0.4648 - val_loss: 0.6562 - val_accuracy: 0.3711\n",
      "Epoch 230/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4988 - accuracy: 0.4644 - val_loss: 0.6593 - val_accuracy: 0.3694\n",
      "Epoch 231/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.4985 - accuracy: 0.4647 - val_loss: 0.6537 - val_accuracy: 0.3740\n",
      "Epoch 232/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.4973 - accuracy: 0.4644 - val_loss: 0.6723 - val_accuracy: 0.3767\n",
      "Epoch 233/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.4982 - accuracy: 0.4697 - val_loss: 0.6687 - val_accuracy: 0.3692\n",
      "Epoch 234/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.5005 - accuracy: 0.4631 - val_loss: 0.6584 - val_accuracy: 0.3732\n",
      "Epoch 235/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.4973 - accuracy: 0.4700 - val_loss: 0.6581 - val_accuracy: 0.3724\n",
      "Epoch 236/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4985 - accuracy: 0.4632 - val_loss: 0.6551 - val_accuracy: 0.3721\n",
      "Epoch 237/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4942 - accuracy: 0.4672 - val_loss: 0.6709 - val_accuracy: 0.3747\n",
      "Epoch 238/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4979 - accuracy: 0.4690 - val_loss: 0.6603 - val_accuracy: 0.3691\n",
      "Epoch 239/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4982 - accuracy: 0.4674 - val_loss: 0.6642 - val_accuracy: 0.3767\n",
      "Epoch 240/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4947 - accuracy: 0.4684 - val_loss: 0.6579 - val_accuracy: 0.3702\n",
      "Epoch 241/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4935 - accuracy: 0.4694 - val_loss: 0.6690 - val_accuracy: 0.3750\n",
      "Epoch 242/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.4958 - accuracy: 0.4662 - val_loss: 0.6738 - val_accuracy: 0.3748\n",
      "Epoch 243/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4955 - accuracy: 0.4636 - val_loss: 0.6737 - val_accuracy: 0.3774\n",
      "Epoch 244/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4936 - accuracy: 0.4690 - val_loss: 0.6698 - val_accuracy: 0.3763\n",
      "Epoch 245/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.4975 - accuracy: 0.4646 - val_loss: 0.6695 - val_accuracy: 0.3751\n",
      "Epoch 246/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4921 - accuracy: 0.4735 - val_loss: 0.6585 - val_accuracy: 0.3754\n",
      "Epoch 247/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4901 - accuracy: 0.4718 - val_loss: 0.6696 - val_accuracy: 0.3788\n",
      "Epoch 248/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4951 - accuracy: 0.4690 - val_loss: 0.6660 - val_accuracy: 0.3805\n",
      "Epoch 249/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4896 - accuracy: 0.4766 - val_loss: 0.6793 - val_accuracy: 0.3762\n",
      "Epoch 250/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4911 - accuracy: 0.4747 - val_loss: 0.6628 - val_accuracy: 0.3753\n",
      "Epoch 251/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4921 - accuracy: 0.4694 - val_loss: 0.6691 - val_accuracy: 0.3785\n",
      "Epoch 252/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4951 - accuracy: 0.4683 - val_loss: 0.6684 - val_accuracy: 0.3747\n",
      "Epoch 253/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4927 - accuracy: 0.4703 - val_loss: 0.6709 - val_accuracy: 0.3738\n",
      "Epoch 254/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4894 - accuracy: 0.4732 - val_loss: 0.6703 - val_accuracy: 0.3785\n",
      "Epoch 255/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4922 - accuracy: 0.4712 - val_loss: 0.6671 - val_accuracy: 0.3781\n",
      "Epoch 256/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4912 - accuracy: 0.4707 - val_loss: 0.6681 - val_accuracy: 0.3715\n",
      "Epoch 257/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4924 - accuracy: 0.4661 - val_loss: 0.6703 - val_accuracy: 0.3758\n",
      "Epoch 258/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4870 - accuracy: 0.4759 - val_loss: 0.6828 - val_accuracy: 0.3805\n",
      "Epoch 259/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4855 - accuracy: 0.4775 - val_loss: 0.6690 - val_accuracy: 0.3751\n",
      "Epoch 260/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4894 - accuracy: 0.4717 - val_loss: 0.6747 - val_accuracy: 0.3750\n",
      "Epoch 261/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4908 - accuracy: 0.4712 - val_loss: 0.6754 - val_accuracy: 0.3771\n",
      "Epoch 262/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4903 - accuracy: 0.4745 - val_loss: 0.6704 - val_accuracy: 0.3759\n",
      "Epoch 263/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4894 - accuracy: 0.4736 - val_loss: 0.6688 - val_accuracy: 0.3746\n",
      "Epoch 264/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4889 - accuracy: 0.4715 - val_loss: 0.6660 - val_accuracy: 0.3714\n",
      "Epoch 265/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4857 - accuracy: 0.4755 - val_loss: 0.6680 - val_accuracy: 0.3727\n",
      "Epoch 266/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4825 - accuracy: 0.4803 - val_loss: 0.6770 - val_accuracy: 0.3736\n",
      "Epoch 267/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4878 - accuracy: 0.4745 - val_loss: 0.6785 - val_accuracy: 0.3778\n",
      "Epoch 268/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4904 - accuracy: 0.4717 - val_loss: 0.6680 - val_accuracy: 0.3755\n",
      "Epoch 269/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4847 - accuracy: 0.4755 - val_loss: 0.6715 - val_accuracy: 0.3760\n",
      "Epoch 270/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4833 - accuracy: 0.4777 - val_loss: 0.6867 - val_accuracy: 0.3780\n",
      "Epoch 271/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4857 - accuracy: 0.4760 - val_loss: 0.6665 - val_accuracy: 0.3749\n",
      "Epoch 272/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4834 - accuracy: 0.4762 - val_loss: 0.6736 - val_accuracy: 0.3756\n",
      "Epoch 273/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.4819 - accuracy: 0.4804 - val_loss: 0.6664 - val_accuracy: 0.3736\n",
      "Epoch 274/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4852 - accuracy: 0.4795 - val_loss: 0.6865 - val_accuracy: 0.3713\n",
      "Epoch 275/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4843 - accuracy: 0.4794 - val_loss: 0.6679 - val_accuracy: 0.3706\n",
      "Epoch 276/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.4852 - accuracy: 0.4766 - val_loss: 0.6718 - val_accuracy: 0.3749\n",
      "Epoch 277/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4843 - accuracy: 0.4782 - val_loss: 0.6677 - val_accuracy: 0.3737\n",
      "Epoch 278/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4837 - accuracy: 0.4776 - val_loss: 0.6691 - val_accuracy: 0.3735\n",
      "Epoch 279/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.4827 - accuracy: 0.4790 - val_loss: 0.6775 - val_accuracy: 0.3776\n",
      "Epoch 280/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4876 - accuracy: 0.4755 - val_loss: 0.6754 - val_accuracy: 0.3729\n",
      "Epoch 281/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4848 - accuracy: 0.4761 - val_loss: 0.6788 - val_accuracy: 0.3745\n",
      "Epoch 282/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4794 - accuracy: 0.4790 - val_loss: 0.6719 - val_accuracy: 0.3780\n",
      "Epoch 283/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4827 - accuracy: 0.4786 - val_loss: 0.6642 - val_accuracy: 0.3723\n",
      "Epoch 284/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4850 - accuracy: 0.4773 - val_loss: 0.6718 - val_accuracy: 0.3751\n",
      "Epoch 285/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4834 - accuracy: 0.4812 - val_loss: 0.6800 - val_accuracy: 0.3758\n",
      "Epoch 286/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4843 - accuracy: 0.4783 - val_loss: 0.6667 - val_accuracy: 0.3753\n",
      "Epoch 287/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4931 - accuracy: 0.4762 - val_loss: 0.6806 - val_accuracy: 0.3716\n",
      "Epoch 288/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4819 - accuracy: 0.4823 - val_loss: 0.6743 - val_accuracy: 0.3769\n",
      "Epoch 289/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4813 - accuracy: 0.4819 - val_loss: 0.6820 - val_accuracy: 0.3780\n",
      "Epoch 290/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4788 - accuracy: 0.4834 - val_loss: 0.6832 - val_accuracy: 0.3755\n",
      "Epoch 291/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4801 - accuracy: 0.4863 - val_loss: 0.6776 - val_accuracy: 0.3788\n",
      "Epoch 292/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4804 - accuracy: 0.4841 - val_loss: 0.6860 - val_accuracy: 0.3781\n",
      "Epoch 293/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4806 - accuracy: 0.4827 - val_loss: 0.6837 - val_accuracy: 0.3727\n",
      "Epoch 294/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4834 - accuracy: 0.4804 - val_loss: 0.6770 - val_accuracy: 0.3793\n",
      "Epoch 295/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4807 - accuracy: 0.4817 - val_loss: 0.6742 - val_accuracy: 0.3712\n",
      "Epoch 296/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4829 - accuracy: 0.4798 - val_loss: 0.6750 - val_accuracy: 0.3788\n",
      "Epoch 297/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.4805 - accuracy: 0.4840 - val_loss: 0.6779 - val_accuracy: 0.3753\n",
      "Epoch 298/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4774 - accuracy: 0.4850 - val_loss: 0.6814 - val_accuracy: 0.3784\n",
      "Epoch 299/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4798 - accuracy: 0.4823 - val_loss: 0.6722 - val_accuracy: 0.3753\n",
      "Epoch 300/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4803 - accuracy: 0.4859 - val_loss: 0.6732 - val_accuracy: 0.3785\n",
      "Epoch 301/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4770 - accuracy: 0.4832 - val_loss: 0.6753 - val_accuracy: 0.3798\n",
      "Epoch 302/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4766 - accuracy: 0.4866 - val_loss: 0.6805 - val_accuracy: 0.3770\n",
      "Epoch 303/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4737 - accuracy: 0.4918 - val_loss: 0.6847 - val_accuracy: 0.3753\n",
      "Epoch 304/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4782 - accuracy: 0.4841 - val_loss: 0.6867 - val_accuracy: 0.3803\n",
      "Epoch 305/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4789 - accuracy: 0.4830 - val_loss: 0.6823 - val_accuracy: 0.3743\n",
      "Epoch 306/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4753 - accuracy: 0.4859 - val_loss: 0.6751 - val_accuracy: 0.3829\n",
      "Epoch 307/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4759 - accuracy: 0.4891 - val_loss: 0.6781 - val_accuracy: 0.3799\n",
      "Epoch 308/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4803 - accuracy: 0.4842 - val_loss: 0.6745 - val_accuracy: 0.3742\n",
      "Epoch 309/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4774 - accuracy: 0.4844 - val_loss: 0.6800 - val_accuracy: 0.3764\n",
      "Epoch 310/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4767 - accuracy: 0.4871 - val_loss: 0.6832 - val_accuracy: 0.3808\n",
      "Epoch 311/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4773 - accuracy: 0.4828 - val_loss: 0.6799 - val_accuracy: 0.3752\n",
      "Epoch 312/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4803 - accuracy: 0.4834 - val_loss: 0.6793 - val_accuracy: 0.3760\n",
      "Epoch 313/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4779 - accuracy: 0.4839 - val_loss: 0.6650 - val_accuracy: 0.3745\n",
      "Epoch 314/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4810 - accuracy: 0.4795 - val_loss: 0.6786 - val_accuracy: 0.3751\n",
      "Epoch 315/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4772 - accuracy: 0.4813 - val_loss: 0.6779 - val_accuracy: 0.3729\n",
      "Epoch 316/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4725 - accuracy: 0.4891 - val_loss: 0.6752 - val_accuracy: 0.3748\n",
      "Epoch 317/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4732 - accuracy: 0.4889 - val_loss: 0.6712 - val_accuracy: 0.3781\n",
      "Epoch 318/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4728 - accuracy: 0.4894 - val_loss: 0.6816 - val_accuracy: 0.3772\n",
      "Epoch 319/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4713 - accuracy: 0.4905 - val_loss: 0.6814 - val_accuracy: 0.3824\n",
      "Epoch 320/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4778 - accuracy: 0.4876 - val_loss: 0.6781 - val_accuracy: 0.3760\n",
      "Epoch 321/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4779 - accuracy: 0.4893 - val_loss: 0.6764 - val_accuracy: 0.3770\n",
      "Epoch 322/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4748 - accuracy: 0.4894 - val_loss: 0.6800 - val_accuracy: 0.3764\n",
      "Epoch 323/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4738 - accuracy: 0.4880 - val_loss: 0.6884 - val_accuracy: 0.3796\n",
      "Epoch 324/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4756 - accuracy: 0.4893 - val_loss: 0.6842 - val_accuracy: 0.3797\n",
      "Epoch 325/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4705 - accuracy: 0.4920 - val_loss: 0.6726 - val_accuracy: 0.3759\n",
      "Epoch 326/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4712 - accuracy: 0.4936 - val_loss: 0.6822 - val_accuracy: 0.3778\n",
      "Epoch 327/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4775 - accuracy: 0.4867 - val_loss: 0.6814 - val_accuracy: 0.3773\n",
      "Epoch 328/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4741 - accuracy: 0.4880 - val_loss: 0.6724 - val_accuracy: 0.3736\n",
      "Epoch 329/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4738 - accuracy: 0.4858 - val_loss: 0.6804 - val_accuracy: 0.3758\n",
      "Epoch 330/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4729 - accuracy: 0.4896 - val_loss: 0.6765 - val_accuracy: 0.3775\n",
      "Epoch 331/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4731 - accuracy: 0.4930 - val_loss: 0.6765 - val_accuracy: 0.3745\n",
      "Epoch 332/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4757 - accuracy: 0.4863 - val_loss: 0.6727 - val_accuracy: 0.3739\n",
      "Epoch 333/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4728 - accuracy: 0.4892 - val_loss: 0.6735 - val_accuracy: 0.3780\n",
      "Epoch 334/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.4701 - accuracy: 0.4895 - val_loss: 0.6796 - val_accuracy: 0.3795\n",
      "Epoch 335/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4718 - accuracy: 0.4924 - val_loss: 0.6681 - val_accuracy: 0.3753\n",
      "Epoch 336/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4710 - accuracy: 0.4935 - val_loss: 0.6767 - val_accuracy: 0.3741\n",
      "Epoch 337/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4721 - accuracy: 0.4895 - val_loss: 0.6721 - val_accuracy: 0.3747\n",
      "Epoch 338/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4778 - accuracy: 0.4901 - val_loss: 0.6735 - val_accuracy: 0.3798\n",
      "Epoch 339/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4774 - accuracy: 0.4885 - val_loss: 0.6803 - val_accuracy: 0.3803\n",
      "Epoch 340/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4754 - accuracy: 0.4929 - val_loss: 0.6744 - val_accuracy: 0.3806\n",
      "Epoch 341/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4797 - accuracy: 0.4832 - val_loss: 0.6774 - val_accuracy: 0.3767\n",
      "Epoch 342/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4751 - accuracy: 0.4894 - val_loss: 0.6799 - val_accuracy: 0.3797\n",
      "Epoch 343/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4705 - accuracy: 0.4933 - val_loss: 0.6848 - val_accuracy: 0.3748\n",
      "Epoch 344/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4701 - accuracy: 0.4919 - val_loss: 0.6848 - val_accuracy: 0.3790\n",
      "Epoch 345/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4675 - accuracy: 0.4936 - val_loss: 0.6822 - val_accuracy: 0.3842\n",
      "Epoch 346/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4692 - accuracy: 0.4945 - val_loss: 0.6801 - val_accuracy: 0.3764\n",
      "Epoch 347/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4689 - accuracy: 0.4939 - val_loss: 0.6830 - val_accuracy: 0.3771\n",
      "Epoch 348/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4691 - accuracy: 0.4946 - val_loss: 0.6757 - val_accuracy: 0.3771\n",
      "Epoch 349/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4709 - accuracy: 0.4937 - val_loss: 0.6721 - val_accuracy: 0.3807\n",
      "Epoch 350/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4714 - accuracy: 0.4916 - val_loss: 0.6784 - val_accuracy: 0.3804\n",
      "Epoch 351/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4718 - accuracy: 0.4931 - val_loss: 0.6843 - val_accuracy: 0.3822\n",
      "Epoch 352/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4689 - accuracy: 0.4925 - val_loss: 0.6857 - val_accuracy: 0.3777\n",
      "Epoch 353/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4681 - accuracy: 0.4956 - val_loss: 0.6778 - val_accuracy: 0.3791\n",
      "Epoch 354/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4667 - accuracy: 0.4950 - val_loss: 0.6797 - val_accuracy: 0.3786\n",
      "Epoch 355/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4720 - accuracy: 0.4941 - val_loss: 0.6806 - val_accuracy: 0.3727\n",
      "Epoch 356/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4771 - accuracy: 0.4899 - val_loss: 0.6643 - val_accuracy: 0.3787\n",
      "Epoch 357/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4727 - accuracy: 0.4917 - val_loss: 0.6727 - val_accuracy: 0.3776\n",
      "Epoch 358/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4702 - accuracy: 0.4947 - val_loss: 0.6819 - val_accuracy: 0.3851\n",
      "Epoch 359/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4659 - accuracy: 0.4969 - val_loss: 0.6855 - val_accuracy: 0.3770\n",
      "Epoch 360/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4707 - accuracy: 0.4955 - val_loss: 0.6838 - val_accuracy: 0.3824\n",
      "Epoch 361/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4647 - accuracy: 0.5022 - val_loss: 0.6836 - val_accuracy: 0.3753\n",
      "Epoch 362/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4673 - accuracy: 0.4968 - val_loss: 0.6820 - val_accuracy: 0.3830\n",
      "Epoch 363/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4660 - accuracy: 0.4972 - val_loss: 0.6896 - val_accuracy: 0.3784\n",
      "Epoch 364/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4705 - accuracy: 0.4912 - val_loss: 0.6883 - val_accuracy: 0.3779\n",
      "Epoch 365/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.4669 - accuracy: 0.4952 - val_loss: 0.6949 - val_accuracy: 0.3712\n",
      "Epoch 366/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4636 - accuracy: 0.4985 - val_loss: 0.6876 - val_accuracy: 0.3750\n",
      "Epoch 367/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4648 - accuracy: 0.4969 - val_loss: 0.6793 - val_accuracy: 0.3760\n",
      "Epoch 368/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4657 - accuracy: 0.4924 - val_loss: 0.6870 - val_accuracy: 0.3788\n",
      "Epoch 369/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4631 - accuracy: 0.4953 - val_loss: 0.6809 - val_accuracy: 0.3788\n",
      "Epoch 370/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4625 - accuracy: 0.4979 - val_loss: 0.6969 - val_accuracy: 0.3821\n",
      "Epoch 371/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4665 - accuracy: 0.4989 - val_loss: 0.6810 - val_accuracy: 0.3771\n",
      "Epoch 372/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4677 - accuracy: 0.4917 - val_loss: 0.6925 - val_accuracy: 0.3819\n",
      "Epoch 373/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4696 - accuracy: 0.4958 - val_loss: 0.6812 - val_accuracy: 0.3794\n",
      "Epoch 374/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4668 - accuracy: 0.4968 - val_loss: 0.6954 - val_accuracy: 0.3805\n",
      "Epoch 375/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4619 - accuracy: 0.5033 - val_loss: 0.6906 - val_accuracy: 0.3792\n",
      "Epoch 376/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4628 - accuracy: 0.5012 - val_loss: 0.6875 - val_accuracy: 0.3812\n",
      "Epoch 377/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4628 - accuracy: 0.4973 - val_loss: 0.6802 - val_accuracy: 0.3782\n",
      "Epoch 378/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4642 - accuracy: 0.5001 - val_loss: 0.6828 - val_accuracy: 0.3824\n",
      "Epoch 379/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.4644 - accuracy: 0.4988 - val_loss: 0.6784 - val_accuracy: 0.3777\n",
      "Epoch 380/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4636 - accuracy: 0.4990 - val_loss: 0.6907 - val_accuracy: 0.3794\n",
      "Epoch 381/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.4622 - accuracy: 0.5019 - val_loss: 0.6832 - val_accuracy: 0.3830\n",
      "Epoch 382/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4652 - accuracy: 0.4960 - val_loss: 0.6817 - val_accuracy: 0.3814\n",
      "Epoch 383/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4637 - accuracy: 0.5006 - val_loss: 0.6828 - val_accuracy: 0.3807\n",
      "Epoch 384/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4610 - accuracy: 0.5034 - val_loss: 0.6787 - val_accuracy: 0.3804\n",
      "Epoch 385/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.4603 - accuracy: 0.5013 - val_loss: 0.6863 - val_accuracy: 0.3820\n",
      "Epoch 386/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4659 - accuracy: 0.4983 - val_loss: 0.6845 - val_accuracy: 0.3783\n",
      "Epoch 387/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4626 - accuracy: 0.5004 - val_loss: 0.6898 - val_accuracy: 0.3788\n",
      "Epoch 388/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4622 - accuracy: 0.4988 - val_loss: 0.6905 - val_accuracy: 0.3781\n",
      "Epoch 389/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4604 - accuracy: 0.5048 - val_loss: 0.6855 - val_accuracy: 0.3782\n",
      "Epoch 390/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4624 - accuracy: 0.5012 - val_loss: 0.6872 - val_accuracy: 0.3829\n",
      "Epoch 391/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4591 - accuracy: 0.5032 - val_loss: 0.6871 - val_accuracy: 0.3818\n",
      "Epoch 392/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4611 - accuracy: 0.5015 - val_loss: 0.6879 - val_accuracy: 0.3798\n",
      "Epoch 393/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4627 - accuracy: 0.5001 - val_loss: 0.6808 - val_accuracy: 0.3764\n",
      "Epoch 394/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4649 - accuracy: 0.4954 - val_loss: 0.6910 - val_accuracy: 0.3789\n",
      "Epoch 395/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4558 - accuracy: 0.5056 - val_loss: 0.6976 - val_accuracy: 0.3770\n",
      "Epoch 396/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4582 - accuracy: 0.5066 - val_loss: 0.6852 - val_accuracy: 0.3782\n",
      "Epoch 397/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.4593 - accuracy: 0.5030 - val_loss: 0.6933 - val_accuracy: 0.3818\n",
      "Epoch 398/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4613 - accuracy: 0.5033 - val_loss: 0.6854 - val_accuracy: 0.3776\n",
      "Epoch 399/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.4591 - accuracy: 0.5063 - val_loss: 0.6910 - val_accuracy: 0.3784\n",
      "Epoch 400/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4611 - accuracy: 0.5012 - val_loss: 0.6890 - val_accuracy: 0.3811\n",
      "Epoch 401/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4565 - accuracy: 0.5045 - val_loss: 0.6819 - val_accuracy: 0.3739\n",
      "Epoch 402/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4617 - accuracy: 0.5014 - val_loss: 0.6801 - val_accuracy: 0.3785\n",
      "Epoch 403/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4601 - accuracy: 0.4997 - val_loss: 0.6735 - val_accuracy: 0.3729\n",
      "Epoch 404/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4641 - accuracy: 0.4964 - val_loss: 0.6817 - val_accuracy: 0.3808\n",
      "Epoch 405/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4686 - accuracy: 0.4948 - val_loss: 0.6770 - val_accuracy: 0.3789\n",
      "Epoch 406/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.4630 - accuracy: 0.4977 - val_loss: 0.6836 - val_accuracy: 0.3774\n",
      "Epoch 407/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4600 - accuracy: 0.5002 - val_loss: 0.6873 - val_accuracy: 0.3773\n",
      "Epoch 408/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4563 - accuracy: 0.5063 - val_loss: 0.6786 - val_accuracy: 0.3753\n",
      "Epoch 409/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4606 - accuracy: 0.4956 - val_loss: 0.6940 - val_accuracy: 0.3734\n",
      "Epoch 410/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4584 - accuracy: 0.5043 - val_loss: 0.6833 - val_accuracy: 0.3788\n",
      "Epoch 411/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4546 - accuracy: 0.5060 - val_loss: 0.6934 - val_accuracy: 0.3759\n",
      "Epoch 412/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4623 - accuracy: 0.4997 - val_loss: 0.6894 - val_accuracy: 0.3791\n",
      "Epoch 413/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4573 - accuracy: 0.5062 - val_loss: 0.6968 - val_accuracy: 0.3766\n",
      "Epoch 414/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4553 - accuracy: 0.5062 - val_loss: 0.6873 - val_accuracy: 0.3808\n",
      "Epoch 415/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4574 - accuracy: 0.5054 - val_loss: 0.6945 - val_accuracy: 0.3805\n",
      "Epoch 416/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4584 - accuracy: 0.5036 - val_loss: 0.7017 - val_accuracy: 0.3812\n",
      "Epoch 417/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4636 - accuracy: 0.5012 - val_loss: 0.6828 - val_accuracy: 0.3791\n",
      "Epoch 418/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4573 - accuracy: 0.5044 - val_loss: 0.6845 - val_accuracy: 0.3822\n",
      "Epoch 419/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4603 - accuracy: 0.5020 - val_loss: 0.6830 - val_accuracy: 0.3761\n",
      "Epoch 420/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4577 - accuracy: 0.5048 - val_loss: 0.6869 - val_accuracy: 0.3782\n",
      "Epoch 421/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4518 - accuracy: 0.5107 - val_loss: 0.6896 - val_accuracy: 0.3799\n",
      "Epoch 422/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4534 - accuracy: 0.5100 - val_loss: 0.6927 - val_accuracy: 0.3782\n",
      "Epoch 423/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4582 - accuracy: 0.5045 - val_loss: 0.6884 - val_accuracy: 0.3809\n",
      "Epoch 424/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4564 - accuracy: 0.5069 - val_loss: 0.6782 - val_accuracy: 0.3782\n",
      "Epoch 425/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4609 - accuracy: 0.5031 - val_loss: 0.6895 - val_accuracy: 0.3752\n",
      "Epoch 426/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4543 - accuracy: 0.5076 - val_loss: 0.6854 - val_accuracy: 0.3774\n",
      "Epoch 427/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4557 - accuracy: 0.5073 - val_loss: 0.6912 - val_accuracy: 0.3770\n",
      "Epoch 428/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.4538 - accuracy: 0.5082 - val_loss: 0.6853 - val_accuracy: 0.3761\n",
      "Epoch 429/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4570 - accuracy: 0.5057 - val_loss: 0.6866 - val_accuracy: 0.3808\n",
      "Epoch 430/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.4547 - accuracy: 0.5066 - val_loss: 0.6844 - val_accuracy: 0.3863\n",
      "Epoch 431/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4550 - accuracy: 0.5086 - val_loss: 0.6879 - val_accuracy: 0.3825\n",
      "Epoch 432/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4569 - accuracy: 0.5055 - val_loss: 0.6860 - val_accuracy: 0.3780\n",
      "Epoch 433/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4545 - accuracy: 0.5066 - val_loss: 0.7036 - val_accuracy: 0.3783\n",
      "Epoch 434/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4575 - accuracy: 0.5059 - val_loss: 0.6811 - val_accuracy: 0.3803\n",
      "Epoch 435/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4522 - accuracy: 0.5090 - val_loss: 0.6922 - val_accuracy: 0.3767\n",
      "Epoch 436/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.4521 - accuracy: 0.5127 - val_loss: 0.6896 - val_accuracy: 0.3779\n",
      "Epoch 437/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4576 - accuracy: 0.5056 - val_loss: 0.6840 - val_accuracy: 0.3798\n",
      "Epoch 438/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4543 - accuracy: 0.5080 - val_loss: 0.6776 - val_accuracy: 0.3762\n",
      "Epoch 439/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4535 - accuracy: 0.5104 - val_loss: 0.6866 - val_accuracy: 0.3779\n",
      "Epoch 440/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4543 - accuracy: 0.5085 - val_loss: 0.6758 - val_accuracy: 0.3833\n",
      "Epoch 441/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4505 - accuracy: 0.5126 - val_loss: 0.6881 - val_accuracy: 0.3815\n",
      "Epoch 442/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4527 - accuracy: 0.5097 - val_loss: 0.7026 - val_accuracy: 0.3789\n",
      "Epoch 443/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.4548 - accuracy: 0.5085 - val_loss: 0.6873 - val_accuracy: 0.3759\n",
      "Epoch 444/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4532 - accuracy: 0.5061 - val_loss: 0.6942 - val_accuracy: 0.3778\n",
      "Epoch 445/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4527 - accuracy: 0.5122 - val_loss: 0.6943 - val_accuracy: 0.3808\n",
      "Epoch 446/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4513 - accuracy: 0.5134 - val_loss: 0.6798 - val_accuracy: 0.3745\n",
      "Epoch 447/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4527 - accuracy: 0.5082 - val_loss: 0.6926 - val_accuracy: 0.3811\n",
      "Epoch 448/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4489 - accuracy: 0.5123 - val_loss: 0.6929 - val_accuracy: 0.3793\n",
      "Epoch 449/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4516 - accuracy: 0.5139 - val_loss: 0.6861 - val_accuracy: 0.3807\n",
      "Epoch 450/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4522 - accuracy: 0.5061 - val_loss: 0.6911 - val_accuracy: 0.3825\n",
      "Epoch 451/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4502 - accuracy: 0.5106 - val_loss: 0.6862 - val_accuracy: 0.3774\n",
      "Epoch 452/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4516 - accuracy: 0.5102 - val_loss: 0.6832 - val_accuracy: 0.3798\n",
      "Epoch 453/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4514 - accuracy: 0.5074 - val_loss: 0.6943 - val_accuracy: 0.3817\n",
      "Epoch 454/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4530 - accuracy: 0.5110 - val_loss: 0.7014 - val_accuracy: 0.3844\n",
      "Epoch 455/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4512 - accuracy: 0.5060 - val_loss: 0.6844 - val_accuracy: 0.3790\n",
      "Epoch 456/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4559 - accuracy: 0.5075 - val_loss: 0.6978 - val_accuracy: 0.3851\n",
      "Epoch 457/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4511 - accuracy: 0.5114 - val_loss: 0.6850 - val_accuracy: 0.3822\n",
      "Epoch 458/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4522 - accuracy: 0.5090 - val_loss: 0.6941 - val_accuracy: 0.3804\n",
      "Epoch 459/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4492 - accuracy: 0.5116 - val_loss: 0.6966 - val_accuracy: 0.3798\n",
      "Epoch 460/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4498 - accuracy: 0.5113 - val_loss: 0.6944 - val_accuracy: 0.3822\n",
      "Epoch 461/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4525 - accuracy: 0.5098 - val_loss: 0.6900 - val_accuracy: 0.3769\n",
      "Epoch 462/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4512 - accuracy: 0.5090 - val_loss: 0.6942 - val_accuracy: 0.3783\n",
      "Epoch 463/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4539 - accuracy: 0.5078 - val_loss: 0.6853 - val_accuracy: 0.3790\n",
      "Epoch 464/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4519 - accuracy: 0.5083 - val_loss: 0.7025 - val_accuracy: 0.3809\n",
      "Epoch 465/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4492 - accuracy: 0.5131 - val_loss: 0.6947 - val_accuracy: 0.3837\n",
      "Epoch 466/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4478 - accuracy: 0.5161 - val_loss: 0.6903 - val_accuracy: 0.3827\n",
      "Epoch 467/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4510 - accuracy: 0.5121 - val_loss: 0.6924 - val_accuracy: 0.3828\n",
      "Epoch 468/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4496 - accuracy: 0.5156 - val_loss: 0.6977 - val_accuracy: 0.3828\n",
      "Epoch 469/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4500 - accuracy: 0.5175 - val_loss: 0.6912 - val_accuracy: 0.3807\n",
      "Epoch 470/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4506 - accuracy: 0.5118 - val_loss: 0.6959 - val_accuracy: 0.3793\n",
      "Epoch 471/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4542 - accuracy: 0.5095 - val_loss: 0.6948 - val_accuracy: 0.3803\n",
      "Epoch 472/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4537 - accuracy: 0.5103 - val_loss: 0.6915 - val_accuracy: 0.3794\n",
      "Epoch 473/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4489 - accuracy: 0.5140 - val_loss: 0.6908 - val_accuracy: 0.3811\n",
      "Epoch 474/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4493 - accuracy: 0.5150 - val_loss: 0.6819 - val_accuracy: 0.3786\n",
      "Epoch 475/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4487 - accuracy: 0.5133 - val_loss: 0.6899 - val_accuracy: 0.3836\n",
      "Epoch 476/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4502 - accuracy: 0.5167 - val_loss: 0.6838 - val_accuracy: 0.3817\n",
      "Epoch 477/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4476 - accuracy: 0.5173 - val_loss: 0.6993 - val_accuracy: 0.3798\n",
      "Epoch 478/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4529 - accuracy: 0.5121 - val_loss: 0.6986 - val_accuracy: 0.3811\n",
      "Epoch 479/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4475 - accuracy: 0.5137 - val_loss: 0.7018 - val_accuracy: 0.3763\n",
      "Epoch 480/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4524 - accuracy: 0.5095 - val_loss: 0.6920 - val_accuracy: 0.3816\n",
      "Epoch 481/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4455 - accuracy: 0.5134 - val_loss: 0.7056 - val_accuracy: 0.3837\n",
      "Epoch 482/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4489 - accuracy: 0.5118 - val_loss: 0.6960 - val_accuracy: 0.3802\n",
      "Epoch 483/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4483 - accuracy: 0.5153 - val_loss: 0.6971 - val_accuracy: 0.3787\n",
      "Epoch 484/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4486 - accuracy: 0.5136 - val_loss: 0.6994 - val_accuracy: 0.3798\n",
      "Epoch 485/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4458 - accuracy: 0.5185 - val_loss: 0.7013 - val_accuracy: 0.3839\n",
      "Epoch 486/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4456 - accuracy: 0.5201 - val_loss: 0.7014 - val_accuracy: 0.3859\n",
      "Epoch 487/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4499 - accuracy: 0.5130 - val_loss: 0.6925 - val_accuracy: 0.3762\n",
      "Epoch 488/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4477 - accuracy: 0.5161 - val_loss: 0.7132 - val_accuracy: 0.3779\n",
      "Epoch 489/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4420 - accuracy: 0.5218 - val_loss: 0.7045 - val_accuracy: 0.3859\n",
      "Epoch 490/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.4465 - accuracy: 0.5204 - val_loss: 0.6907 - val_accuracy: 0.3838\n",
      "Epoch 491/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4464 - accuracy: 0.5191 - val_loss: 0.6952 - val_accuracy: 0.3805\n",
      "Epoch 492/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4435 - accuracy: 0.5211 - val_loss: 0.6938 - val_accuracy: 0.3816\n",
      "Epoch 493/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4463 - accuracy: 0.5191 - val_loss: 0.6988 - val_accuracy: 0.3808\n",
      "Epoch 494/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4498 - accuracy: 0.5167 - val_loss: 0.6902 - val_accuracy: 0.3793\n",
      "Epoch 495/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4488 - accuracy: 0.5148 - val_loss: 0.6890 - val_accuracy: 0.3829\n",
      "Epoch 496/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4440 - accuracy: 0.5222 - val_loss: 0.7041 - val_accuracy: 0.3797\n",
      "Epoch 497/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4472 - accuracy: 0.5162 - val_loss: 0.7003 - val_accuracy: 0.3829\n",
      "Epoch 498/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4517 - accuracy: 0.5151 - val_loss: 0.6949 - val_accuracy: 0.3802\n",
      "Epoch 499/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4571 - accuracy: 0.5085 - val_loss: 0.6881 - val_accuracy: 0.3827\n",
      "Epoch 500/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.4487 - accuracy: 0.5156 - val_loss: 0.7037 - val_accuracy: 0.3806\n",
      "Epoch 501/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4605 - accuracy: 0.5062 - val_loss: 0.6794 - val_accuracy: 0.3801\n",
      "Epoch 502/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4477 - accuracy: 0.5168 - val_loss: 0.6977 - val_accuracy: 0.3813\n",
      "Epoch 503/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4463 - accuracy: 0.5177 - val_loss: 0.6905 - val_accuracy: 0.3820\n",
      "Epoch 504/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4437 - accuracy: 0.5209 - val_loss: 0.7052 - val_accuracy: 0.3846\n",
      "Epoch 505/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4407 - accuracy: 0.5186 - val_loss: 0.7014 - val_accuracy: 0.3825\n",
      "Epoch 506/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4486 - accuracy: 0.5160 - val_loss: 0.6979 - val_accuracy: 0.3859\n",
      "Epoch 507/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4443 - accuracy: 0.5186 - val_loss: 0.6932 - val_accuracy: 0.3798\n",
      "Epoch 508/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4432 - accuracy: 0.5211 - val_loss: 0.6996 - val_accuracy: 0.3786\n",
      "Epoch 509/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4458 - accuracy: 0.5183 - val_loss: 0.6944 - val_accuracy: 0.3810\n",
      "Epoch 510/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4452 - accuracy: 0.5178 - val_loss: 0.6971 - val_accuracy: 0.3761\n",
      "Epoch 511/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4422 - accuracy: 0.5238 - val_loss: 0.7035 - val_accuracy: 0.3768\n",
      "Epoch 512/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4408 - accuracy: 0.5240 - val_loss: 0.7002 - val_accuracy: 0.3799\n",
      "Epoch 513/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.4462 - accuracy: 0.5215 - val_loss: 0.7012 - val_accuracy: 0.3822\n",
      "Epoch 514/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4484 - accuracy: 0.5161 - val_loss: 0.7013 - val_accuracy: 0.3830\n",
      "Epoch 515/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4395 - accuracy: 0.5242 - val_loss: 0.7010 - val_accuracy: 0.3815\n",
      "Epoch 516/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4423 - accuracy: 0.5204 - val_loss: 0.6982 - val_accuracy: 0.3788\n",
      "Epoch 517/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4429 - accuracy: 0.5211 - val_loss: 0.6880 - val_accuracy: 0.3833\n",
      "Epoch 518/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4407 - accuracy: 0.5220 - val_loss: 0.7053 - val_accuracy: 0.3831\n",
      "Epoch 519/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4494 - accuracy: 0.5184 - val_loss: 0.6913 - val_accuracy: 0.3753\n",
      "Epoch 520/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4463 - accuracy: 0.5113 - val_loss: 0.6942 - val_accuracy: 0.3825\n",
      "Epoch 521/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4470 - accuracy: 0.5197 - val_loss: 0.6919 - val_accuracy: 0.3836\n",
      "Epoch 522/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4428 - accuracy: 0.5188 - val_loss: 0.6985 - val_accuracy: 0.3783\n",
      "Epoch 523/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4380 - accuracy: 0.5224 - val_loss: 0.7075 - val_accuracy: 0.3813\n",
      "Epoch 524/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4391 - accuracy: 0.5277 - val_loss: 0.7109 - val_accuracy: 0.3827\n",
      "Epoch 525/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4530 - accuracy: 0.5112 - val_loss: 0.6895 - val_accuracy: 0.3850\n",
      "Epoch 526/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4553 - accuracy: 0.5076 - val_loss: 0.6959 - val_accuracy: 0.3821\n",
      "Epoch 527/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4418 - accuracy: 0.5218 - val_loss: 0.6989 - val_accuracy: 0.3836\n",
      "Epoch 528/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4427 - accuracy: 0.5215 - val_loss: 0.7008 - val_accuracy: 0.3843\n",
      "Epoch 529/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4412 - accuracy: 0.5198 - val_loss: 0.6882 - val_accuracy: 0.3779\n",
      "Epoch 530/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4430 - accuracy: 0.5164 - val_loss: 0.6851 - val_accuracy: 0.3805\n",
      "Epoch 531/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4397 - accuracy: 0.5225 - val_loss: 0.6898 - val_accuracy: 0.3774\n",
      "Epoch 532/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4408 - accuracy: 0.5198 - val_loss: 0.7000 - val_accuracy: 0.3845\n",
      "Epoch 533/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4428 - accuracy: 0.5188 - val_loss: 0.6917 - val_accuracy: 0.3818\n",
      "Epoch 534/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4416 - accuracy: 0.5214 - val_loss: 0.6950 - val_accuracy: 0.3840\n",
      "Epoch 535/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4361 - accuracy: 0.5260 - val_loss: 0.6964 - val_accuracy: 0.3838\n",
      "Epoch 536/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4367 - accuracy: 0.5276 - val_loss: 0.7057 - val_accuracy: 0.3817\n",
      "Epoch 537/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4435 - accuracy: 0.5211 - val_loss: 0.7018 - val_accuracy: 0.3846\n",
      "Epoch 538/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4414 - accuracy: 0.5227 - val_loss: 0.6987 - val_accuracy: 0.3789\n",
      "Epoch 539/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4402 - accuracy: 0.5191 - val_loss: 0.6928 - val_accuracy: 0.3811\n",
      "Epoch 540/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4370 - accuracy: 0.5239 - val_loss: 0.7002 - val_accuracy: 0.3779\n",
      "Epoch 541/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.4378 - accuracy: 0.5217 - val_loss: 0.6950 - val_accuracy: 0.3791\n",
      "Epoch 542/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4357 - accuracy: 0.5265 - val_loss: 0.7103 - val_accuracy: 0.3801\n",
      "Epoch 543/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4419 - accuracy: 0.5181 - val_loss: 0.6868 - val_accuracy: 0.3824\n",
      "Epoch 544/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4379 - accuracy: 0.5250 - val_loss: 0.6943 - val_accuracy: 0.3811\n",
      "Epoch 545/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4433 - accuracy: 0.5204 - val_loss: 0.6913 - val_accuracy: 0.3818\n",
      "Epoch 546/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4370 - accuracy: 0.5240 - val_loss: 0.6948 - val_accuracy: 0.3793\n",
      "Epoch 547/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4379 - accuracy: 0.5248 - val_loss: 0.7045 - val_accuracy: 0.3823\n",
      "Epoch 548/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4379 - accuracy: 0.5259 - val_loss: 0.7008 - val_accuracy: 0.3855\n",
      "Epoch 549/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4424 - accuracy: 0.5210 - val_loss: 0.6997 - val_accuracy: 0.3837\n",
      "Epoch 550/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4387 - accuracy: 0.5220 - val_loss: 0.6971 - val_accuracy: 0.3840\n",
      "Epoch 551/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4419 - accuracy: 0.5229 - val_loss: 0.6974 - val_accuracy: 0.3807\n",
      "Epoch 552/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4407 - accuracy: 0.5240 - val_loss: 0.6923 - val_accuracy: 0.3815\n",
      "Epoch 553/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4370 - accuracy: 0.5281 - val_loss: 0.6976 - val_accuracy: 0.3826\n",
      "Epoch 554/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4353 - accuracy: 0.5280 - val_loss: 0.6906 - val_accuracy: 0.3777\n",
      "Epoch 555/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4391 - accuracy: 0.5221 - val_loss: 0.7020 - val_accuracy: 0.3856\n",
      "Epoch 556/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4388 - accuracy: 0.5232 - val_loss: 0.6998 - val_accuracy: 0.3829\n",
      "Epoch 557/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4363 - accuracy: 0.5245 - val_loss: 0.7083 - val_accuracy: 0.3811\n",
      "Epoch 558/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4401 - accuracy: 0.5215 - val_loss: 0.6970 - val_accuracy: 0.3794\n",
      "Epoch 559/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4374 - accuracy: 0.5233 - val_loss: 0.7079 - val_accuracy: 0.3847\n",
      "Epoch 560/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4354 - accuracy: 0.5309 - val_loss: 0.6886 - val_accuracy: 0.3837\n",
      "Epoch 561/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4397 - accuracy: 0.5278 - val_loss: 0.6995 - val_accuracy: 0.3816\n",
      "Epoch 562/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4366 - accuracy: 0.5267 - val_loss: 0.7092 - val_accuracy: 0.3792\n",
      "Epoch 563/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4367 - accuracy: 0.5270 - val_loss: 0.6982 - val_accuracy: 0.3847\n",
      "Epoch 564/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4385 - accuracy: 0.5243 - val_loss: 0.6967 - val_accuracy: 0.3859\n",
      "Epoch 565/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4337 - accuracy: 0.5287 - val_loss: 0.7061 - val_accuracy: 0.3905\n",
      "Epoch 566/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4362 - accuracy: 0.5232 - val_loss: 0.7051 - val_accuracy: 0.3793\n",
      "Epoch 567/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4361 - accuracy: 0.5253 - val_loss: 0.6861 - val_accuracy: 0.3828\n",
      "Epoch 568/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4393 - accuracy: 0.5209 - val_loss: 0.7021 - val_accuracy: 0.3867\n",
      "Epoch 569/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4334 - accuracy: 0.5278 - val_loss: 0.7018 - val_accuracy: 0.3808\n",
      "Epoch 570/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4356 - accuracy: 0.5275 - val_loss: 0.7055 - val_accuracy: 0.3792\n",
      "Epoch 571/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4370 - accuracy: 0.5250 - val_loss: 0.7082 - val_accuracy: 0.3820\n",
      "Epoch 572/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4380 - accuracy: 0.5234 - val_loss: 0.6980 - val_accuracy: 0.3829\n",
      "Epoch 573/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4387 - accuracy: 0.5233 - val_loss: 0.6950 - val_accuracy: 0.3824\n",
      "Epoch 574/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4337 - accuracy: 0.5245 - val_loss: 0.6907 - val_accuracy: 0.3825\n",
      "Epoch 575/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4348 - accuracy: 0.5279 - val_loss: 0.7083 - val_accuracy: 0.3839\n",
      "Epoch 576/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4385 - accuracy: 0.5240 - val_loss: 0.7091 - val_accuracy: 0.3839\n",
      "Epoch 577/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4394 - accuracy: 0.5252 - val_loss: 0.6922 - val_accuracy: 0.3795\n",
      "Epoch 578/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4350 - accuracy: 0.5272 - val_loss: 0.7008 - val_accuracy: 0.3859\n",
      "Epoch 579/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4370 - accuracy: 0.5302 - val_loss: 0.6990 - val_accuracy: 0.3849\n",
      "Epoch 580/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4331 - accuracy: 0.5300 - val_loss: 0.6943 - val_accuracy: 0.3809\n",
      "Epoch 581/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4385 - accuracy: 0.5237 - val_loss: 0.6911 - val_accuracy: 0.3809\n",
      "Epoch 582/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4360 - accuracy: 0.5273 - val_loss: 0.7083 - val_accuracy: 0.3830\n",
      "Epoch 583/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4349 - accuracy: 0.5288 - val_loss: 0.7086 - val_accuracy: 0.3815\n",
      "Epoch 584/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.4370 - accuracy: 0.5252 - val_loss: 0.6945 - val_accuracy: 0.3851\n",
      "Epoch 585/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4427 - accuracy: 0.5197 - val_loss: 0.6985 - val_accuracy: 0.3808\n",
      "Epoch 586/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4341 - accuracy: 0.5266 - val_loss: 0.7017 - val_accuracy: 0.3834\n",
      "Epoch 587/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4338 - accuracy: 0.5267 - val_loss: 0.6984 - val_accuracy: 0.3830\n",
      "Epoch 588/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.4361 - accuracy: 0.5241 - val_loss: 0.6994 - val_accuracy: 0.3836\n",
      "Epoch 589/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.4411 - accuracy: 0.5212 - val_loss: 0.7011 - val_accuracy: 0.3861\n",
      "Epoch 590/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4396 - accuracy: 0.5241 - val_loss: 0.6934 - val_accuracy: 0.3819\n",
      "Epoch 591/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.4363 - accuracy: 0.5251 - val_loss: 0.6897 - val_accuracy: 0.3842\n",
      "Epoch 592/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4323 - accuracy: 0.5304 - val_loss: 0.6934 - val_accuracy: 0.3808\n",
      "Epoch 593/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4382 - accuracy: 0.5248 - val_loss: 0.6933 - val_accuracy: 0.3876\n",
      "Epoch 594/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4390 - accuracy: 0.5236 - val_loss: 0.6937 - val_accuracy: 0.3820\n",
      "Epoch 595/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4343 - accuracy: 0.5293 - val_loss: 0.6961 - val_accuracy: 0.3816\n",
      "Epoch 596/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4339 - accuracy: 0.5309 - val_loss: 0.7140 - val_accuracy: 0.3872\n",
      "Epoch 597/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4361 - accuracy: 0.5285 - val_loss: 0.6928 - val_accuracy: 0.3779\n",
      "Epoch 598/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4349 - accuracy: 0.5250 - val_loss: 0.7035 - val_accuracy: 0.3829\n",
      "Epoch 599/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.4326 - accuracy: 0.5310 - val_loss: 0.6895 - val_accuracy: 0.3851\n",
      "Epoch 600/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4355 - accuracy: 0.5315 - val_loss: 0.6907 - val_accuracy: 0.3784\n",
      "Epoch 601/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4326 - accuracy: 0.5312 - val_loss: 0.7063 - val_accuracy: 0.3859\n",
      "Epoch 602/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4323 - accuracy: 0.5299 - val_loss: 0.7042 - val_accuracy: 0.3878\n",
      "Epoch 603/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4324 - accuracy: 0.5325 - val_loss: 0.6977 - val_accuracy: 0.3832\n",
      "Epoch 604/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4316 - accuracy: 0.5347 - val_loss: 0.6954 - val_accuracy: 0.3835\n",
      "Epoch 605/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4307 - accuracy: 0.5326 - val_loss: 0.7031 - val_accuracy: 0.3814\n",
      "Epoch 606/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4319 - accuracy: 0.5279 - val_loss: 0.6984 - val_accuracy: 0.3805\n",
      "Epoch 607/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4312 - accuracy: 0.5308 - val_loss: 0.7036 - val_accuracy: 0.3798\n",
      "Epoch 608/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4363 - accuracy: 0.5270 - val_loss: 0.7013 - val_accuracy: 0.3838\n",
      "Epoch 609/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4334 - accuracy: 0.5268 - val_loss: 0.6957 - val_accuracy: 0.3847\n",
      "Epoch 610/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4327 - accuracy: 0.5300 - val_loss: 0.6981 - val_accuracy: 0.3866\n",
      "Epoch 611/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4319 - accuracy: 0.5292 - val_loss: 0.7078 - val_accuracy: 0.3850\n",
      "Epoch 612/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4343 - accuracy: 0.5285 - val_loss: 0.6969 - val_accuracy: 0.3824\n",
      "Epoch 613/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4280 - accuracy: 0.5328 - val_loss: 0.6980 - val_accuracy: 0.3809\n",
      "Epoch 614/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4305 - accuracy: 0.5309 - val_loss: 0.7062 - val_accuracy: 0.3778\n",
      "Epoch 615/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4327 - accuracy: 0.5283 - val_loss: 0.7003 - val_accuracy: 0.3860\n",
      "Epoch 616/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4335 - accuracy: 0.5279 - val_loss: 0.6994 - val_accuracy: 0.3818\n",
      "Epoch 617/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4279 - accuracy: 0.5341 - val_loss: 0.7062 - val_accuracy: 0.3836\n",
      "Epoch 618/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4328 - accuracy: 0.5326 - val_loss: 0.6982 - val_accuracy: 0.3842\n",
      "Epoch 619/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4326 - accuracy: 0.5289 - val_loss: 0.7097 - val_accuracy: 0.3802\n",
      "Epoch 620/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4292 - accuracy: 0.5361 - val_loss: 0.7054 - val_accuracy: 0.3824\n",
      "Epoch 621/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4345 - accuracy: 0.5315 - val_loss: 0.6902 - val_accuracy: 0.3842\n",
      "Epoch 622/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4309 - accuracy: 0.5348 - val_loss: 0.6855 - val_accuracy: 0.3825\n",
      "Epoch 623/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4292 - accuracy: 0.5341 - val_loss: 0.7040 - val_accuracy: 0.3828\n",
      "Epoch 624/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4309 - accuracy: 0.5296 - val_loss: 0.6962 - val_accuracy: 0.3813\n",
      "Epoch 625/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4316 - accuracy: 0.5302 - val_loss: 0.7019 - val_accuracy: 0.3789\n",
      "Epoch 626/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4293 - accuracy: 0.5344 - val_loss: 0.7123 - val_accuracy: 0.3848\n",
      "Epoch 627/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4293 - accuracy: 0.5356 - val_loss: 0.7051 - val_accuracy: 0.3817\n",
      "Epoch 628/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4343 - accuracy: 0.5284 - val_loss: 0.7035 - val_accuracy: 0.3777\n",
      "Epoch 629/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4379 - accuracy: 0.5263 - val_loss: 0.6920 - val_accuracy: 0.3823\n",
      "Epoch 630/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.4318 - accuracy: 0.5337 - val_loss: 0.6972 - val_accuracy: 0.3821\n",
      "Epoch 631/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4301 - accuracy: 0.5351 - val_loss: 0.7024 - val_accuracy: 0.3849\n",
      "Epoch 632/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4265 - accuracy: 0.5364 - val_loss: 0.7121 - val_accuracy: 0.3788\n",
      "Epoch 633/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4248 - accuracy: 0.5415 - val_loss: 0.7199 - val_accuracy: 0.3836\n",
      "Epoch 634/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4275 - accuracy: 0.5370 - val_loss: 0.7096 - val_accuracy: 0.3839\n",
      "Epoch 635/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4302 - accuracy: 0.5342 - val_loss: 0.7029 - val_accuracy: 0.3837\n",
      "Epoch 636/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4299 - accuracy: 0.5359 - val_loss: 0.7146 - val_accuracy: 0.3870\n",
      "Epoch 637/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4277 - accuracy: 0.5343 - val_loss: 0.7013 - val_accuracy: 0.3836\n",
      "Epoch 638/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4325 - accuracy: 0.5337 - val_loss: 0.6937 - val_accuracy: 0.3839\n",
      "Epoch 639/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.4329 - accuracy: 0.5355 - val_loss: 0.7011 - val_accuracy: 0.3825\n",
      "Epoch 640/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4300 - accuracy: 0.5317 - val_loss: 0.7035 - val_accuracy: 0.3811\n",
      "Epoch 641/2500\n",
      "32958/32958 [==============================] - 2s 58us/step - loss: 0.4317 - accuracy: 0.5330 - val_loss: 0.7078 - val_accuracy: 0.3821\n",
      "Epoch 642/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4304 - accuracy: 0.5304 - val_loss: 0.7106 - val_accuracy: 0.3836\n",
      "Epoch 643/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4334 - accuracy: 0.5296 - val_loss: 0.7020 - val_accuracy: 0.3788\n",
      "Epoch 644/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4286 - accuracy: 0.5360 - val_loss: 0.7055 - val_accuracy: 0.3795\n",
      "Epoch 645/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4260 - accuracy: 0.5363 - val_loss: 0.7138 - val_accuracy: 0.3849\n",
      "Epoch 646/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4283 - accuracy: 0.5344 - val_loss: 0.7123 - val_accuracy: 0.3779\n",
      "Epoch 647/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4273 - accuracy: 0.5352 - val_loss: 0.7024 - val_accuracy: 0.3794\n",
      "Epoch 648/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4289 - accuracy: 0.5331 - val_loss: 0.7038 - val_accuracy: 0.3828\n",
      "Epoch 649/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4276 - accuracy: 0.5356 - val_loss: 0.6943 - val_accuracy: 0.3866\n",
      "Epoch 650/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4242 - accuracy: 0.5370 - val_loss: 0.7059 - val_accuracy: 0.3791 0s - loss: 0.4\n",
      "Epoch 651/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4268 - accuracy: 0.5340 - val_loss: 0.7155 - val_accuracy: 0.3866\n",
      "Epoch 652/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4231 - accuracy: 0.5371 - val_loss: 0.7010 - val_accuracy: 0.3820\n",
      "Epoch 653/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4283 - accuracy: 0.5336 - val_loss: 0.6962 - val_accuracy: 0.3844\n",
      "Epoch 654/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4304 - accuracy: 0.5347 - val_loss: 0.6987 - val_accuracy: 0.3869\n",
      "Epoch 655/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4387 - accuracy: 0.5239 - val_loss: 0.6943 - val_accuracy: 0.3814\n",
      "Epoch 656/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4273 - accuracy: 0.5345 - val_loss: 0.6915 - val_accuracy: 0.3804\n",
      "Epoch 657/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4309 - accuracy: 0.5282 - val_loss: 0.6969 - val_accuracy: 0.3832\n",
      "Epoch 658/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4270 - accuracy: 0.5351 - val_loss: 0.7008 - val_accuracy: 0.3842\n",
      "Epoch 659/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4303 - accuracy: 0.5300 - val_loss: 0.7082 - val_accuracy: 0.3871\n",
      "Epoch 660/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4323 - accuracy: 0.5313 - val_loss: 0.7018 - val_accuracy: 0.3864\n",
      "Epoch 661/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4268 - accuracy: 0.5360 - val_loss: 0.7037 - val_accuracy: 0.3849\n",
      "Epoch 662/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4256 - accuracy: 0.5372 - val_loss: 0.7113 - val_accuracy: 0.3826\n",
      "Epoch 663/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4263 - accuracy: 0.5363 - val_loss: 0.6958 - val_accuracy: 0.3814\n",
      "Epoch 664/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4284 - accuracy: 0.5325 - val_loss: 0.7089 - val_accuracy: 0.3869\n",
      "Epoch 665/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4309 - accuracy: 0.5313 - val_loss: 0.6987 - val_accuracy: 0.3808\n",
      "Epoch 666/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4276 - accuracy: 0.5346 - val_loss: 0.6967 - val_accuracy: 0.3800\n",
      "Epoch 667/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4265 - accuracy: 0.5411 - val_loss: 0.6951 - val_accuracy: 0.3811\n",
      "Epoch 668/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4277 - accuracy: 0.5372 - val_loss: 0.7027 - val_accuracy: 0.3839\n",
      "Epoch 669/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4278 - accuracy: 0.5353 - val_loss: 0.7012 - val_accuracy: 0.3834\n",
      "Epoch 670/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4277 - accuracy: 0.5370 - val_loss: 0.7047 - val_accuracy: 0.3825\n",
      "Epoch 671/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4260 - accuracy: 0.5374 - val_loss: 0.6983 - val_accuracy: 0.3824\n",
      "Epoch 672/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4259 - accuracy: 0.5374 - val_loss: 0.7156 - val_accuracy: 0.3808\n",
      "Epoch 673/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4238 - accuracy: 0.5380 - val_loss: 0.7044 - val_accuracy: 0.3791\n",
      "Epoch 674/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.4239 - accuracy: 0.5383 - val_loss: 0.7038 - val_accuracy: 0.3845\n",
      "Epoch 675/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4226 - accuracy: 0.5426 - val_loss: 0.7091 - val_accuracy: 0.3863\n",
      "Epoch 676/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4228 - accuracy: 0.5424 - val_loss: 0.7127 - val_accuracy: 0.3866\n",
      "Epoch 677/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4248 - accuracy: 0.5401 - val_loss: 0.7044 - val_accuracy: 0.3847\n",
      "Epoch 678/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4189 - accuracy: 0.5448 - val_loss: 0.7063 - val_accuracy: 0.3844\n",
      "Epoch 679/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4301 - accuracy: 0.5349 - val_loss: 0.6959 - val_accuracy: 0.3790\n",
      "Epoch 680/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4253 - accuracy: 0.5407 - val_loss: 0.6950 - val_accuracy: 0.3832\n",
      "Epoch 681/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4262 - accuracy: 0.5405 - val_loss: 0.7012 - val_accuracy: 0.3819\n",
      "Epoch 682/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4287 - accuracy: 0.5344 - val_loss: 0.7081 - val_accuracy: 0.3836\n",
      "Epoch 683/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4271 - accuracy: 0.5354 - val_loss: 0.6924 - val_accuracy: 0.3841\n",
      "Epoch 684/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4264 - accuracy: 0.5347 - val_loss: 0.7022 - val_accuracy: 0.3860\n",
      "Epoch 685/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4284 - accuracy: 0.5332 - val_loss: 0.7074 - val_accuracy: 0.3829\n",
      "Epoch 686/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4249 - accuracy: 0.5393 - val_loss: 0.6976 - val_accuracy: 0.3839\n",
      "Epoch 687/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4309 - accuracy: 0.5301 - val_loss: 0.7061 - val_accuracy: 0.3855\n",
      "Epoch 688/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.4233 - accuracy: 0.5372 - val_loss: 0.7108 - val_accuracy: 0.3858\n",
      "Epoch 689/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4235 - accuracy: 0.5398 - val_loss: 0.7006 - val_accuracy: 0.3823\n",
      "Epoch 690/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4256 - accuracy: 0.5369 - val_loss: 0.7090 - val_accuracy: 0.3794\n",
      "Epoch 691/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4307 - accuracy: 0.5341 - val_loss: 0.6932 - val_accuracy: 0.3803\n",
      "Epoch 692/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4261 - accuracy: 0.5350 - val_loss: 0.7031 - val_accuracy: 0.3836\n",
      "Epoch 693/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4262 - accuracy: 0.5346 - val_loss: 0.7024 - val_accuracy: 0.3834\n",
      "Epoch 694/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.4242 - accuracy: 0.5384 - val_loss: 0.7020 - val_accuracy: 0.3808\n",
      "Epoch 695/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4214 - accuracy: 0.5392 - val_loss: 0.7080 - val_accuracy: 0.3824\n",
      "Epoch 696/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4248 - accuracy: 0.5377 - val_loss: 0.7003 - val_accuracy: 0.3807\n",
      "Epoch 697/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4221 - accuracy: 0.5405 - val_loss: 0.7198 - val_accuracy: 0.3844\n",
      "Epoch 698/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4242 - accuracy: 0.5366 - val_loss: 0.7178 - val_accuracy: 0.3863\n",
      "Epoch 699/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4197 - accuracy: 0.5448 - val_loss: 0.7032 - val_accuracy: 0.3837\n",
      "Epoch 700/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4247 - accuracy: 0.5379 - val_loss: 0.7075 - val_accuracy: 0.3844\n",
      "Epoch 701/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4230 - accuracy: 0.5411 - val_loss: 0.7092 - val_accuracy: 0.3861\n",
      "Epoch 702/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4282 - accuracy: 0.5354 - val_loss: 0.6928 - val_accuracy: 0.3836\n",
      "Epoch 703/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4239 - accuracy: 0.5378 - val_loss: 0.7103 - val_accuracy: 0.3857\n",
      "Epoch 704/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4247 - accuracy: 0.5402 - val_loss: 0.7094 - val_accuracy: 0.3788\n",
      "Epoch 705/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.4254 - accuracy: 0.5375 - val_loss: 0.7046 - val_accuracy: 0.3854\n",
      "Epoch 706/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4245 - accuracy: 0.5343 - val_loss: 0.7011 - val_accuracy: 0.3815\n",
      "Epoch 707/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4233 - accuracy: 0.5336 - val_loss: 0.7016 - val_accuracy: 0.3824\n",
      "Epoch 708/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4193 - accuracy: 0.5405 - val_loss: 0.6988 - val_accuracy: 0.3829\n",
      "Epoch 709/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4231 - accuracy: 0.5388 - val_loss: 0.7068 - val_accuracy: 0.3813\n",
      "Epoch 710/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.4241 - accuracy: 0.5395 - val_loss: 0.6935 - val_accuracy: 0.3821\n",
      "Epoch 711/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.4311 - accuracy: 0.5286 - val_loss: 0.6920 - val_accuracy: 0.3793\n",
      "Epoch 712/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4287 - accuracy: 0.5330 - val_loss: 0.6922 - val_accuracy: 0.3826\n",
      "Epoch 713/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4263 - accuracy: 0.5379 - val_loss: 0.7022 - val_accuracy: 0.3839\n",
      "Epoch 714/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4342 - accuracy: 0.5298 - val_loss: 0.7030 - val_accuracy: 0.3845\n",
      "Epoch 715/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4233 - accuracy: 0.5383 - val_loss: 0.6986 - val_accuracy: 0.3822\n",
      "Epoch 716/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4253 - accuracy: 0.5379 - val_loss: 0.7035 - val_accuracy: 0.3835\n",
      "Epoch 717/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4200 - accuracy: 0.5455 - val_loss: 0.7100 - val_accuracy: 0.3881\n",
      "Epoch 718/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4219 - accuracy: 0.5383 - val_loss: 0.7081 - val_accuracy: 0.3822\n",
      "Epoch 719/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4179 - accuracy: 0.5429 - val_loss: 0.7112 - val_accuracy: 0.3840\n",
      "Epoch 720/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4188 - accuracy: 0.5424 - val_loss: 0.7057 - val_accuracy: 0.3839\n",
      "Epoch 721/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4204 - accuracy: 0.5422 - val_loss: 0.7010 - val_accuracy: 0.3832\n",
      "Epoch 722/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4190 - accuracy: 0.5445 - val_loss: 0.7121 - val_accuracy: 0.3832\n",
      "Epoch 723/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4239 - accuracy: 0.5405 - val_loss: 0.7127 - val_accuracy: 0.3844\n",
      "Epoch 724/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.4242 - accuracy: 0.5404 - val_loss: 0.7042 - val_accuracy: 0.3798\n",
      "Epoch 725/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4248 - accuracy: 0.5355 - val_loss: 0.7077 - val_accuracy: 0.3812\n",
      "Epoch 726/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4263 - accuracy: 0.5349 - val_loss: 0.6970 - val_accuracy: 0.3827\n",
      "Epoch 727/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4225 - accuracy: 0.5352 - val_loss: 0.7114 - val_accuracy: 0.3790\n",
      "Epoch 728/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4174 - accuracy: 0.5442 - val_loss: 0.7153 - val_accuracy: 0.3855\n",
      "Epoch 729/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4180 - accuracy: 0.5452 - val_loss: 0.7000 - val_accuracy: 0.3788\n",
      "Epoch 730/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4212 - accuracy: 0.5420 - val_loss: 0.7082 - val_accuracy: 0.3839\n",
      "Epoch 731/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4164 - accuracy: 0.5460 - val_loss: 0.6967 - val_accuracy: 0.3856\n",
      "Epoch 732/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4243 - accuracy: 0.5401 - val_loss: 0.7070 - val_accuracy: 0.3792\n",
      "Epoch 733/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4230 - accuracy: 0.5420 - val_loss: 0.7108 - val_accuracy: 0.3814\n",
      "Epoch 734/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4171 - accuracy: 0.5481 - val_loss: 0.7193 - val_accuracy: 0.3829\n",
      "Epoch 735/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4193 - accuracy: 0.5441 - val_loss: 0.7041 - val_accuracy: 0.3801\n",
      "Epoch 736/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4181 - accuracy: 0.5429 - val_loss: 0.7073 - val_accuracy: 0.3840\n",
      "Epoch 737/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4199 - accuracy: 0.5458 - val_loss: 0.7024 - val_accuracy: 0.3846\n",
      "Epoch 738/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4180 - accuracy: 0.5504 - val_loss: 0.7060 - val_accuracy: 0.3833\n",
      "Epoch 739/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4214 - accuracy: 0.5426 - val_loss: 0.7048 - val_accuracy: 0.3839\n",
      "Epoch 740/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4226 - accuracy: 0.5435 - val_loss: 0.7096 - val_accuracy: 0.3791\n",
      "Epoch 741/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4262 - accuracy: 0.5365 - val_loss: 0.7120 - val_accuracy: 0.3818\n",
      "Epoch 742/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4186 - accuracy: 0.5448 - val_loss: 0.6980 - val_accuracy: 0.3816\n",
      "Epoch 743/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4188 - accuracy: 0.5416 - val_loss: 0.7080 - val_accuracy: 0.3830\n",
      "Epoch 744/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4208 - accuracy: 0.5432 - val_loss: 0.7015 - val_accuracy: 0.3837\n",
      "Epoch 745/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4171 - accuracy: 0.5464 - val_loss: 0.7113 - val_accuracy: 0.3851\n",
      "Epoch 746/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4191 - accuracy: 0.5418 - val_loss: 0.7101 - val_accuracy: 0.3829\n",
      "Epoch 747/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4259 - accuracy: 0.5366 - val_loss: 0.7000 - val_accuracy: 0.3845\n",
      "Epoch 748/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4175 - accuracy: 0.5449 - val_loss: 0.7017 - val_accuracy: 0.3848\n",
      "Epoch 749/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4176 - accuracy: 0.5428 - val_loss: 0.7114 - val_accuracy: 0.3867\n",
      "Epoch 750/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4161 - accuracy: 0.5490 - val_loss: 0.7015 - val_accuracy: 0.3866\n",
      "Epoch 751/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4164 - accuracy: 0.5452 - val_loss: 0.7198 - val_accuracy: 0.3852\n",
      "Epoch 752/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4197 - accuracy: 0.5438 - val_loss: 0.7024 - val_accuracy: 0.3867\n",
      "Epoch 753/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4197 - accuracy: 0.5412 - val_loss: 0.7069 - val_accuracy: 0.3866\n",
      "Epoch 754/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4184 - accuracy: 0.5438 - val_loss: 0.7135 - val_accuracy: 0.3858\n",
      "Epoch 755/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4173 - accuracy: 0.5468 - val_loss: 0.7116 - val_accuracy: 0.3865\n",
      "Epoch 756/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4170 - accuracy: 0.5469 - val_loss: 0.7086 - val_accuracy: 0.3809\n",
      "Epoch 757/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4189 - accuracy: 0.5423 - val_loss: 0.7076 - val_accuracy: 0.3859\n",
      "Epoch 758/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.4161 - accuracy: 0.5467 - val_loss: 0.7018 - val_accuracy: 0.3849\n",
      "Epoch 759/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4193 - accuracy: 0.5402 - val_loss: 0.6942 - val_accuracy: 0.3826\n",
      "Epoch 760/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4173 - accuracy: 0.5435 - val_loss: 0.6991 - val_accuracy: 0.3824\n",
      "Epoch 761/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4172 - accuracy: 0.5424 - val_loss: 0.7162 - val_accuracy: 0.3848\n",
      "Epoch 762/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4162 - accuracy: 0.5410 - val_loss: 0.6967 - val_accuracy: 0.3819\n",
      "Epoch 763/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4149 - accuracy: 0.5447 - val_loss: 0.7163 - val_accuracy: 0.3849\n",
      "Epoch 764/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4194 - accuracy: 0.5429 - val_loss: 0.6984 - val_accuracy: 0.3834\n",
      "Epoch 765/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4188 - accuracy: 0.5399 - val_loss: 0.7114 - val_accuracy: 0.3858\n",
      "Epoch 766/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4170 - accuracy: 0.5428 - val_loss: 0.7120 - val_accuracy: 0.3845\n",
      "Epoch 767/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4169 - accuracy: 0.5432 - val_loss: 0.7058 - val_accuracy: 0.3832\n",
      "Epoch 768/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4171 - accuracy: 0.5407 - val_loss: 0.7057 - val_accuracy: 0.3810\n",
      "Epoch 769/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4177 - accuracy: 0.5427 - val_loss: 0.7167 - val_accuracy: 0.3868\n",
      "Epoch 770/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4123 - accuracy: 0.5493 - val_loss: 0.7124 - val_accuracy: 0.3887\n",
      "Epoch 771/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4175 - accuracy: 0.5445 - val_loss: 0.7208 - val_accuracy: 0.3831\n",
      "Epoch 772/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4165 - accuracy: 0.5438 - val_loss: 0.7062 - val_accuracy: 0.3877\n",
      "Epoch 773/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4219 - accuracy: 0.5428 - val_loss: 0.7087 - val_accuracy: 0.3815\n",
      "Epoch 774/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4178 - accuracy: 0.5453 - val_loss: 0.7044 - val_accuracy: 0.3827\n",
      "Epoch 775/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4152 - accuracy: 0.5470 - val_loss: 0.7179 - val_accuracy: 0.3834\n",
      "Epoch 776/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4165 - accuracy: 0.5422 - val_loss: 0.7145 - val_accuracy: 0.3840\n",
      "Epoch 777/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4172 - accuracy: 0.5435 - val_loss: 0.6998 - val_accuracy: 0.3829\n",
      "Epoch 778/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4125 - accuracy: 0.5502 - val_loss: 0.7234 - val_accuracy: 0.3857\n",
      "Epoch 779/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.4135 - accuracy: 0.5467 - val_loss: 0.7126 - val_accuracy: 0.3772\n",
      "Epoch 780/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.4130 - accuracy: 0.5439 - val_loss: 0.7113 - val_accuracy: 0.3826\n",
      "Epoch 781/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.4179 - accuracy: 0.5421 - val_loss: 0.7002 - val_accuracy: 0.3831\n",
      "Epoch 782/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4146 - accuracy: 0.5466 - val_loss: 0.7013 - val_accuracy: 0.3819\n",
      "Epoch 783/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4203 - accuracy: 0.5430 - val_loss: 0.7103 - val_accuracy: 0.3838\n",
      "Epoch 784/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4213 - accuracy: 0.5405 - val_loss: 0.7040 - val_accuracy: 0.3844\n",
      "Epoch 785/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4169 - accuracy: 0.5483 - val_loss: 0.7104 - val_accuracy: 0.3802\n",
      "Epoch 786/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4165 - accuracy: 0.5460 - val_loss: 0.7035 - val_accuracy: 0.3826\n",
      "Epoch 787/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4171 - accuracy: 0.5434 - val_loss: 0.7382 - val_accuracy: 0.3867\n",
      "Epoch 788/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4182 - accuracy: 0.5444 - val_loss: 0.7209 - val_accuracy: 0.3818\n",
      "Epoch 789/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4174 - accuracy: 0.5472 - val_loss: 0.7211 - val_accuracy: 0.3834\n",
      "Epoch 790/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.4223 - accuracy: 0.5412 - val_loss: 0.7100 - val_accuracy: 0.3849\n",
      "Epoch 791/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4180 - accuracy: 0.5405 - val_loss: 0.7110 - val_accuracy: 0.3788\n",
      "Epoch 792/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4171 - accuracy: 0.5443 - val_loss: 0.7187 - val_accuracy: 0.3831\n",
      "Epoch 793/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4197 - accuracy: 0.5424 - val_loss: 0.7089 - val_accuracy: 0.3825\n",
      "Epoch 794/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4149 - accuracy: 0.5489 - val_loss: 0.7202 - val_accuracy: 0.3900\n",
      "Epoch 795/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4109 - accuracy: 0.5507 - val_loss: 0.7085 - val_accuracy: 0.3835\n",
      "Epoch 796/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4120 - accuracy: 0.5539 - val_loss: 0.7126 - val_accuracy: 0.3869\n",
      "Epoch 797/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4148 - accuracy: 0.5473 - val_loss: 0.7118 - val_accuracy: 0.3832\n",
      "Epoch 798/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4168 - accuracy: 0.5455 - val_loss: 0.7194 - val_accuracy: 0.3887\n",
      "Epoch 799/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4169 - accuracy: 0.5454 - val_loss: 0.7051 - val_accuracy: 0.3835\n",
      "Epoch 800/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4167 - accuracy: 0.5437 - val_loss: 0.7118 - val_accuracy: 0.3879\n",
      "Epoch 801/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4147 - accuracy: 0.5466 - val_loss: 0.7194 - val_accuracy: 0.3831\n",
      "Epoch 802/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4160 - accuracy: 0.5466 - val_loss: 0.7219 - val_accuracy: 0.3854\n",
      "Epoch 803/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4127 - accuracy: 0.5487 - val_loss: 0.7127 - val_accuracy: 0.3824\n",
      "Epoch 804/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4189 - accuracy: 0.5405 - val_loss: 0.7097 - val_accuracy: 0.3854\n",
      "Epoch 805/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4148 - accuracy: 0.5478 - val_loss: 0.7114 - val_accuracy: 0.3892\n",
      "Epoch 806/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4149 - accuracy: 0.5493 - val_loss: 0.7107 - val_accuracy: 0.3869\n",
      "Epoch 807/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4196 - accuracy: 0.5443 - val_loss: 0.7071 - val_accuracy: 0.3816\n",
      "Epoch 808/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4200 - accuracy: 0.5416 - val_loss: 0.7078 - val_accuracy: 0.3858\n",
      "Epoch 809/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4149 - accuracy: 0.5442 - val_loss: 0.7098 - val_accuracy: 0.3843\n",
      "Epoch 810/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4154 - accuracy: 0.5445 - val_loss: 0.7178 - val_accuracy: 0.3830\n",
      "Epoch 811/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.4208 - accuracy: 0.5374 - val_loss: 0.7083 - val_accuracy: 0.3847\n",
      "Epoch 812/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4165 - accuracy: 0.5457 - val_loss: 0.7153 - val_accuracy: 0.3815\n",
      "Epoch 813/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4198 - accuracy: 0.5440 - val_loss: 0.6994 - val_accuracy: 0.3806\n",
      "Epoch 814/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4193 - accuracy: 0.5396 - val_loss: 0.7103 - val_accuracy: 0.3810\n",
      "Epoch 815/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4159 - accuracy: 0.5460 - val_loss: 0.7098 - val_accuracy: 0.3850\n",
      "Epoch 816/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4130 - accuracy: 0.5495 - val_loss: 0.7106 - val_accuracy: 0.3850\n",
      "Epoch 817/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4136 - accuracy: 0.5472 - val_loss: 0.7159 - val_accuracy: 0.3849\n",
      "Epoch 818/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4110 - accuracy: 0.5523 - val_loss: 0.7110 - val_accuracy: 0.3849\n",
      "Epoch 819/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4145 - accuracy: 0.5469 - val_loss: 0.7062 - val_accuracy: 0.3866\n",
      "Epoch 820/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4114 - accuracy: 0.5502 - val_loss: 0.7175 - val_accuracy: 0.3852\n",
      "Epoch 821/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4099 - accuracy: 0.5519 - val_loss: 0.7109 - val_accuracy: 0.3868\n",
      "Epoch 822/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4115 - accuracy: 0.5538 - val_loss: 0.7097 - val_accuracy: 0.3852\n",
      "Epoch 823/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4138 - accuracy: 0.5542 - val_loss: 0.7075 - val_accuracy: 0.3852\n",
      "Epoch 824/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4139 - accuracy: 0.5449 - val_loss: 0.7165 - val_accuracy: 0.3881\n",
      "Epoch 825/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4126 - accuracy: 0.5511 - val_loss: 0.7174 - val_accuracy: 0.3855\n",
      "Epoch 826/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4160 - accuracy: 0.5506 - val_loss: 0.7079 - val_accuracy: 0.3857\n",
      "Epoch 827/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4136 - accuracy: 0.5512 - val_loss: 0.7151 - val_accuracy: 0.3880\n",
      "Epoch 828/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4137 - accuracy: 0.5479 - val_loss: 0.7237 - val_accuracy: 0.3891\n",
      "Epoch 829/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4278 - accuracy: 0.5357 - val_loss: 0.6995 - val_accuracy: 0.3818\n",
      "Epoch 830/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4175 - accuracy: 0.5456 - val_loss: 0.6984 - val_accuracy: 0.3861\n",
      "Epoch 831/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4143 - accuracy: 0.5509 - val_loss: 0.7157 - val_accuracy: 0.3889\n",
      "Epoch 832/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4141 - accuracy: 0.5494 - val_loss: 0.7080 - val_accuracy: 0.3886\n",
      "Epoch 833/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4154 - accuracy: 0.5488 - val_loss: 0.7045 - val_accuracy: 0.3827\n",
      "Epoch 834/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4162 - accuracy: 0.5482 - val_loss: 0.7078 - val_accuracy: 0.3813\n",
      "Epoch 835/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4121 - accuracy: 0.5520 - val_loss: 0.7019 - val_accuracy: 0.3829\n",
      "Epoch 836/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4102 - accuracy: 0.5500 - val_loss: 0.7141 - val_accuracy: 0.3837\n",
      "Epoch 837/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4101 - accuracy: 0.5542 - val_loss: 0.7151 - val_accuracy: 0.3860\n",
      "Epoch 838/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4138 - accuracy: 0.5474 - val_loss: 0.7181 - val_accuracy: 0.3858\n",
      "Epoch 839/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4171 - accuracy: 0.5518 - val_loss: 0.7011 - val_accuracy: 0.3837\n",
      "Epoch 840/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4173 - accuracy: 0.5495 - val_loss: 0.7049 - val_accuracy: 0.3829\n",
      "Epoch 841/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4153 - accuracy: 0.5468 - val_loss: 0.7144 - val_accuracy: 0.3843\n",
      "Epoch 842/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4215 - accuracy: 0.5432 - val_loss: 0.7111 - val_accuracy: 0.3879\n",
      "Epoch 843/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4237 - accuracy: 0.5407 - val_loss: 0.7195 - val_accuracy: 0.3887\n",
      "Epoch 844/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4112 - accuracy: 0.5507 - val_loss: 0.7149 - val_accuracy: 0.3876\n",
      "Epoch 845/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4114 - accuracy: 0.5523 - val_loss: 0.7099 - val_accuracy: 0.3859\n",
      "Epoch 846/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4109 - accuracy: 0.5536 - val_loss: 0.7098 - val_accuracy: 0.3892\n",
      "Epoch 847/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.4132 - accuracy: 0.5495 - val_loss: 0.7063 - val_accuracy: 0.3861\n",
      "Epoch 848/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4105 - accuracy: 0.5538 - val_loss: 0.7177 - val_accuracy: 0.3879\n",
      "Epoch 849/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4099 - accuracy: 0.5522 - val_loss: 0.7185 - val_accuracy: 0.3855\n",
      "Epoch 850/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4063 - accuracy: 0.5546 - val_loss: 0.7145 - val_accuracy: 0.3858\n",
      "Epoch 851/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4130 - accuracy: 0.5483 - val_loss: 0.7101 - val_accuracy: 0.3834\n",
      "Epoch 852/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.4129 - accuracy: 0.5507 - val_loss: 0.7118 - val_accuracy: 0.3834\n",
      "Epoch 853/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4121 - accuracy: 0.5501 - val_loss: 0.7063 - val_accuracy: 0.3824\n",
      "Epoch 854/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4126 - accuracy: 0.5506 - val_loss: 0.7081 - val_accuracy: 0.3849\n",
      "Epoch 855/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4072 - accuracy: 0.5559 - val_loss: 0.7238 - val_accuracy: 0.3889\n",
      "Epoch 856/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4126 - accuracy: 0.5504 - val_loss: 0.7013 - val_accuracy: 0.3859\n",
      "Epoch 857/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4116 - accuracy: 0.5501 - val_loss: 0.7102 - val_accuracy: 0.3880\n",
      "Epoch 858/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4183 - accuracy: 0.5425 - val_loss: 0.6955 - val_accuracy: 0.3839\n",
      "Epoch 859/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4133 - accuracy: 0.5472 - val_loss: 0.7205 - val_accuracy: 0.3867\n",
      "Epoch 860/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4111 - accuracy: 0.5492 - val_loss: 0.7105 - val_accuracy: 0.3858\n",
      "Epoch 861/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4137 - accuracy: 0.5496 - val_loss: 0.7008 - val_accuracy: 0.3853\n",
      "Epoch 862/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4117 - accuracy: 0.5500 - val_loss: 0.7194 - val_accuracy: 0.3856\n",
      "Epoch 863/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4135 - accuracy: 0.5476 - val_loss: 0.7103 - val_accuracy: 0.3841\n",
      "Epoch 864/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4146 - accuracy: 0.5462 - val_loss: 0.7128 - val_accuracy: 0.3851\n",
      "Epoch 865/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4092 - accuracy: 0.5511 - val_loss: 0.7182 - val_accuracy: 0.3875\n",
      "Epoch 866/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4059 - accuracy: 0.5570 - val_loss: 0.7097 - val_accuracy: 0.3864\n",
      "Epoch 867/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4145 - accuracy: 0.5472 - val_loss: 0.7192 - val_accuracy: 0.3868\n",
      "Epoch 868/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4105 - accuracy: 0.5518 - val_loss: 0.7145 - val_accuracy: 0.3866\n",
      "Epoch 869/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4071 - accuracy: 0.5533 - val_loss: 0.7202 - val_accuracy: 0.3862\n",
      "Epoch 870/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4078 - accuracy: 0.5516 - val_loss: 0.7227 - val_accuracy: 0.3845\n",
      "Epoch 871/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4076 - accuracy: 0.5572 - val_loss: 0.7182 - val_accuracy: 0.3839\n",
      "Epoch 872/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4073 - accuracy: 0.5586 - val_loss: 0.7300 - val_accuracy: 0.3902\n",
      "Epoch 873/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4071 - accuracy: 0.5548 - val_loss: 0.7158 - val_accuracy: 0.3859\n",
      "Epoch 874/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.4104 - accuracy: 0.5529 - val_loss: 0.7159 - val_accuracy: 0.3867\n",
      "Epoch 875/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4098 - accuracy: 0.5548 - val_loss: 0.7181 - val_accuracy: 0.3842\n",
      "Epoch 876/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.4097 - accuracy: 0.5517 - val_loss: 0.7224 - val_accuracy: 0.3820\n",
      "Epoch 877/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4147 - accuracy: 0.5498 - val_loss: 0.7214 - val_accuracy: 0.3898\n",
      "Epoch 878/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4111 - accuracy: 0.5511 - val_loss: 0.7019 - val_accuracy: 0.3859\n",
      "Epoch 879/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4120 - accuracy: 0.5483 - val_loss: 0.7066 - val_accuracy: 0.3833\n",
      "Epoch 880/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4075 - accuracy: 0.5576 - val_loss: 0.7154 - val_accuracy: 0.3818\n",
      "Epoch 881/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4078 - accuracy: 0.5537 - val_loss: 0.7102 - val_accuracy: 0.3845\n",
      "Epoch 882/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.4111 - accuracy: 0.5526 - val_loss: 0.7170 - val_accuracy: 0.3863\n",
      "Epoch 883/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.4110 - accuracy: 0.5516 - val_loss: 0.7172 - val_accuracy: 0.3871\n",
      "Epoch 884/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4039 - accuracy: 0.5582 - val_loss: 0.7120 - val_accuracy: 0.3844\n",
      "Epoch 885/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4075 - accuracy: 0.5560 - val_loss: 0.7252 - val_accuracy: 0.3879\n",
      "Epoch 886/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4066 - accuracy: 0.5576 - val_loss: 0.7130 - val_accuracy: 0.3842\n",
      "Epoch 887/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4112 - accuracy: 0.5516 - val_loss: 0.7223 - val_accuracy: 0.3884\n",
      "Epoch 888/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4067 - accuracy: 0.5589 - val_loss: 0.7220 - val_accuracy: 0.3853\n",
      "Epoch 889/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4120 - accuracy: 0.5543 - val_loss: 0.7104 - val_accuracy: 0.3820\n",
      "Epoch 890/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4097 - accuracy: 0.5525 - val_loss: 0.7172 - val_accuracy: 0.3858\n",
      "Epoch 891/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4087 - accuracy: 0.5566 - val_loss: 0.7149 - val_accuracy: 0.3842\n",
      "Epoch 892/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4097 - accuracy: 0.5526 - val_loss: 0.7165 - val_accuracy: 0.3850\n",
      "Epoch 893/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4068 - accuracy: 0.5568 - val_loss: 0.7274 - val_accuracy: 0.3847\n",
      "Epoch 894/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4092 - accuracy: 0.5550 - val_loss: 0.7067 - val_accuracy: 0.3811\n",
      "Epoch 895/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4069 - accuracy: 0.5552 - val_loss: 0.7267 - val_accuracy: 0.3895\n",
      "Epoch 896/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4086 - accuracy: 0.5545 - val_loss: 0.7131 - val_accuracy: 0.3838\n",
      "Epoch 897/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4071 - accuracy: 0.5545 - val_loss: 0.7124 - val_accuracy: 0.3859\n",
      "Epoch 898/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4064 - accuracy: 0.5578 - val_loss: 0.7091 - val_accuracy: 0.3820\n",
      "Epoch 899/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4109 - accuracy: 0.5516 - val_loss: 0.7144 - val_accuracy: 0.3833\n",
      "Epoch 900/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4045 - accuracy: 0.5565 - val_loss: 0.7080 - val_accuracy: 0.3771\n",
      "Epoch 901/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4035 - accuracy: 0.5586 - val_loss: 0.7168 - val_accuracy: 0.3842\n",
      "Epoch 902/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4034 - accuracy: 0.5611 - val_loss: 0.7169 - val_accuracy: 0.3875\n",
      "Epoch 903/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4084 - accuracy: 0.5548 - val_loss: 0.7172 - val_accuracy: 0.3849\n",
      "Epoch 904/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4118 - accuracy: 0.5549 - val_loss: 0.7122 - val_accuracy: 0.3809\n",
      "Epoch 905/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4046 - accuracy: 0.5591 - val_loss: 0.7138 - val_accuracy: 0.3854\n",
      "Epoch 906/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4078 - accuracy: 0.5587 - val_loss: 0.7175 - val_accuracy: 0.3861\n",
      "Epoch 907/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4066 - accuracy: 0.5612 - val_loss: 0.7208 - val_accuracy: 0.3818\n",
      "Epoch 908/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4082 - accuracy: 0.5537 - val_loss: 0.7255 - val_accuracy: 0.3877\n",
      "Epoch 909/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4032 - accuracy: 0.5631 - val_loss: 0.7263 - val_accuracy: 0.3859\n",
      "Epoch 910/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4080 - accuracy: 0.5580 - val_loss: 0.7375 - val_accuracy: 0.3884\n",
      "Epoch 911/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4082 - accuracy: 0.5552 - val_loss: 0.7253 - val_accuracy: 0.3849\n",
      "Epoch 912/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4065 - accuracy: 0.5587 - val_loss: 0.7125 - val_accuracy: 0.3865\n",
      "Epoch 913/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4107 - accuracy: 0.5579 - val_loss: 0.7106 - val_accuracy: 0.3881\n",
      "Epoch 914/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4041 - accuracy: 0.5567 - val_loss: 0.7275 - val_accuracy: 0.3854\n",
      "Epoch 915/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4064 - accuracy: 0.5585 - val_loss: 0.7159 - val_accuracy: 0.3889\n",
      "Epoch 916/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4031 - accuracy: 0.5573 - val_loss: 0.7204 - val_accuracy: 0.3858\n",
      "Epoch 917/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4051 - accuracy: 0.5596 - val_loss: 0.7189 - val_accuracy: 0.3826\n",
      "Epoch 918/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4043 - accuracy: 0.5613 - val_loss: 0.7147 - val_accuracy: 0.3817\n",
      "Epoch 919/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4042 - accuracy: 0.5598 - val_loss: 0.7171 - val_accuracy: 0.3828\n",
      "Epoch 920/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4051 - accuracy: 0.5596 - val_loss: 0.7264 - val_accuracy: 0.3915\n",
      "Epoch 921/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4036 - accuracy: 0.5587 - val_loss: 0.7217 - val_accuracy: 0.3873\n",
      "Epoch 922/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.4049 - accuracy: 0.5586 - val_loss: 0.7144 - val_accuracy: 0.3895\n",
      "Epoch 923/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4082 - accuracy: 0.5579 - val_loss: 0.7053 - val_accuracy: 0.3831\n",
      "Epoch 924/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4058 - accuracy: 0.5549 - val_loss: 0.7207 - val_accuracy: 0.3847\n",
      "Epoch 925/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4075 - accuracy: 0.5550 - val_loss: 0.7208 - val_accuracy: 0.3884\n",
      "Epoch 926/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4145 - accuracy: 0.5516 - val_loss: 0.7099 - val_accuracy: 0.3834\n",
      "Epoch 927/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4037 - accuracy: 0.5572 - val_loss: 0.7119 - val_accuracy: 0.3857\n",
      "Epoch 928/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4028 - accuracy: 0.5572 - val_loss: 0.7208 - val_accuracy: 0.3915\n",
      "Epoch 929/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4011 - accuracy: 0.5634 - val_loss: 0.7196 - val_accuracy: 0.3869\n",
      "Epoch 930/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4013 - accuracy: 0.5623 - val_loss: 0.7290 - val_accuracy: 0.3934\n",
      "Epoch 931/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4066 - accuracy: 0.5600 - val_loss: 0.7302 - val_accuracy: 0.3898\n",
      "Epoch 932/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4041 - accuracy: 0.5609 - val_loss: 0.7221 - val_accuracy: 0.3869\n",
      "Epoch 933/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3989 - accuracy: 0.5629 - val_loss: 0.7302 - val_accuracy: 0.3901\n",
      "Epoch 934/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4041 - accuracy: 0.5564 - val_loss: 0.7153 - val_accuracy: 0.3855\n",
      "Epoch 935/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4046 - accuracy: 0.5582 - val_loss: 0.7290 - val_accuracy: 0.3874\n",
      "Epoch 936/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4046 - accuracy: 0.5581 - val_loss: 0.7173 - val_accuracy: 0.3881\n",
      "Epoch 937/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4057 - accuracy: 0.5570 - val_loss: 0.7160 - val_accuracy: 0.3818\n",
      "Epoch 938/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4073 - accuracy: 0.5579 - val_loss: 0.7205 - val_accuracy: 0.3858\n",
      "Epoch 939/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4056 - accuracy: 0.5565 - val_loss: 0.7144 - val_accuracy: 0.3818\n",
      "Epoch 940/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4028 - accuracy: 0.5602 - val_loss: 0.7113 - val_accuracy: 0.3837\n",
      "Epoch 941/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4036 - accuracy: 0.5640 - val_loss: 0.7109 - val_accuracy: 0.3815\n",
      "Epoch 942/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4019 - accuracy: 0.5607 - val_loss: 0.7197 - val_accuracy: 0.3859\n",
      "Epoch 943/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4069 - accuracy: 0.5574 - val_loss: 0.7171 - val_accuracy: 0.3879\n",
      "Epoch 944/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4009 - accuracy: 0.5636 - val_loss: 0.7282 - val_accuracy: 0.3866\n",
      "Epoch 945/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4025 - accuracy: 0.5623 - val_loss: 0.7188 - val_accuracy: 0.3901\n",
      "Epoch 946/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4070 - accuracy: 0.5575 - val_loss: 0.7234 - val_accuracy: 0.3846\n",
      "Epoch 947/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4094 - accuracy: 0.5578 - val_loss: 0.7176 - val_accuracy: 0.3848\n",
      "Epoch 948/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4029 - accuracy: 0.5608 - val_loss: 0.7128 - val_accuracy: 0.3859\n",
      "Epoch 949/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4014 - accuracy: 0.5600 - val_loss: 0.7111 - val_accuracy: 0.3869\n",
      "Epoch 950/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3999 - accuracy: 0.5616 - val_loss: 0.7262 - val_accuracy: 0.3896\n",
      "Epoch 951/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3993 - accuracy: 0.5642 - val_loss: 0.7108 - val_accuracy: 0.3903\n",
      "Epoch 952/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4021 - accuracy: 0.5597 - val_loss: 0.7185 - val_accuracy: 0.3884\n",
      "Epoch 953/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4121 - accuracy: 0.5485 - val_loss: 0.7278 - val_accuracy: 0.3869\n",
      "Epoch 954/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4031 - accuracy: 0.5582 - val_loss: 0.7149 - val_accuracy: 0.3866\n",
      "Epoch 955/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4038 - accuracy: 0.5585 - val_loss: 0.7253 - val_accuracy: 0.3872\n",
      "Epoch 956/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4079 - accuracy: 0.5590 - val_loss: 0.7029 - val_accuracy: 0.3820\n",
      "Epoch 957/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4042 - accuracy: 0.5546 - val_loss: 0.7039 - val_accuracy: 0.3862\n",
      "Epoch 958/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4036 - accuracy: 0.5573 - val_loss: 0.7090 - val_accuracy: 0.3865\n",
      "Epoch 959/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4024 - accuracy: 0.5614 - val_loss: 0.7150 - val_accuracy: 0.3893\n",
      "Epoch 960/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4050 - accuracy: 0.5580 - val_loss: 0.7311 - val_accuracy: 0.3901\n",
      "Epoch 961/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4051 - accuracy: 0.5590 - val_loss: 0.7177 - val_accuracy: 0.3816\n",
      "Epoch 962/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4080 - accuracy: 0.5556 - val_loss: 0.7207 - val_accuracy: 0.3875\n",
      "Epoch 963/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4050 - accuracy: 0.5553 - val_loss: 0.7215 - val_accuracy: 0.3855\n",
      "Epoch 964/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4028 - accuracy: 0.5575 - val_loss: 0.7072 - val_accuracy: 0.3838\n",
      "Epoch 965/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.4029 - accuracy: 0.5561 - val_loss: 0.7100 - val_accuracy: 0.3867\n",
      "Epoch 966/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4023 - accuracy: 0.5610 - val_loss: 0.7108 - val_accuracy: 0.3905\n",
      "Epoch 967/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4044 - accuracy: 0.5592 - val_loss: 0.7129 - val_accuracy: 0.3859\n",
      "Epoch 968/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4064 - accuracy: 0.5573 - val_loss: 0.7233 - val_accuracy: 0.3870\n",
      "Epoch 969/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4053 - accuracy: 0.5566 - val_loss: 0.7226 - val_accuracy: 0.3878\n",
      "Epoch 970/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4058 - accuracy: 0.5593 - val_loss: 0.7181 - val_accuracy: 0.3844\n",
      "Epoch 971/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4097 - accuracy: 0.5553 - val_loss: 0.7280 - val_accuracy: 0.3854\n",
      "Epoch 972/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4039 - accuracy: 0.5613 - val_loss: 0.7189 - val_accuracy: 0.3880\n",
      "Epoch 973/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4034 - accuracy: 0.5566 - val_loss: 0.7232 - val_accuracy: 0.3860\n",
      "Epoch 974/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4074 - accuracy: 0.5551 - val_loss: 0.7209 - val_accuracy: 0.3851\n",
      "Epoch 975/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4020 - accuracy: 0.5610 - val_loss: 0.7173 - val_accuracy: 0.3855\n",
      "Epoch 976/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4030 - accuracy: 0.5622 - val_loss: 0.7115 - val_accuracy: 0.3879\n",
      "Epoch 977/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4062 - accuracy: 0.5562 - val_loss: 0.7067 - val_accuracy: 0.3876\n",
      "Epoch 978/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4081 - accuracy: 0.5524 - val_loss: 0.7122 - val_accuracy: 0.3810\n",
      "Epoch 979/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4019 - accuracy: 0.5620 - val_loss: 0.7221 - val_accuracy: 0.3861\n",
      "Epoch 980/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4027 - accuracy: 0.5568 - val_loss: 0.7243 - val_accuracy: 0.3871\n",
      "Epoch 981/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4040 - accuracy: 0.5603 - val_loss: 0.7311 - val_accuracy: 0.3857\n",
      "Epoch 982/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4039 - accuracy: 0.5579 - val_loss: 0.7176 - val_accuracy: 0.3831\n",
      "Epoch 983/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4023 - accuracy: 0.5583 - val_loss: 0.7140 - val_accuracy: 0.3877\n",
      "Epoch 984/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3999 - accuracy: 0.5633 - val_loss: 0.7155 - val_accuracy: 0.3884\n",
      "Epoch 985/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4064 - accuracy: 0.5573 - val_loss: 0.7109 - val_accuracy: 0.3841\n",
      "Epoch 986/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4033 - accuracy: 0.5609 - val_loss: 0.7330 - val_accuracy: 0.3902\n",
      "Epoch 987/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4061 - accuracy: 0.5573 - val_loss: 0.7200 - val_accuracy: 0.3896\n",
      "Epoch 988/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4055 - accuracy: 0.5605 - val_loss: 0.7149 - val_accuracy: 0.3878\n",
      "Epoch 989/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4000 - accuracy: 0.5676 - val_loss: 0.7249 - val_accuracy: 0.3869\n",
      "Epoch 990/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4027 - accuracy: 0.5602 - val_loss: 0.7282 - val_accuracy: 0.3878\n",
      "Epoch 991/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4015 - accuracy: 0.5614 - val_loss: 0.7222 - val_accuracy: 0.3859\n",
      "Epoch 992/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4017 - accuracy: 0.5603 - val_loss: 0.7266 - val_accuracy: 0.3849\n",
      "Epoch 993/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4030 - accuracy: 0.5579 - val_loss: 0.7187 - val_accuracy: 0.3798\n",
      "Epoch 994/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3997 - accuracy: 0.5596 - val_loss: 0.7230 - val_accuracy: 0.3880\n",
      "Epoch 995/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4074 - accuracy: 0.5572 - val_loss: 0.7158 - val_accuracy: 0.3857\n",
      "Epoch 996/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4016 - accuracy: 0.5600 - val_loss: 0.7184 - val_accuracy: 0.3872\n",
      "Epoch 997/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3997 - accuracy: 0.5625 - val_loss: 0.7239 - val_accuracy: 0.3890\n",
      "Epoch 998/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4033 - accuracy: 0.5565 - val_loss: 0.7175 - val_accuracy: 0.3905\n",
      "Epoch 999/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4024 - accuracy: 0.5631 - val_loss: 0.7246 - val_accuracy: 0.3924\n",
      "Epoch 1000/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3999 - accuracy: 0.5618 - val_loss: 0.7360 - val_accuracy: 0.3913\n",
      "Epoch 1001/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3994 - accuracy: 0.5661 - val_loss: 0.7172 - val_accuracy: 0.3900\n",
      "Epoch 1002/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4043 - accuracy: 0.5600 - val_loss: 0.7300 - val_accuracy: 0.3869\n",
      "Epoch 1003/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4013 - accuracy: 0.5615 - val_loss: 0.7236 - val_accuracy: 0.3856\n",
      "Epoch 1004/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3990 - accuracy: 0.5656 - val_loss: 0.7228 - val_accuracy: 0.3888\n",
      "Epoch 1005/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4006 - accuracy: 0.5617 - val_loss: 0.7286 - val_accuracy: 0.3886\n",
      "Epoch 1006/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3988 - accuracy: 0.5662 - val_loss: 0.7300 - val_accuracy: 0.3940\n",
      "Epoch 1007/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4014 - accuracy: 0.5586 - val_loss: 0.7291 - val_accuracy: 0.3853\n",
      "Epoch 1008/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3996 - accuracy: 0.5623 - val_loss: 0.7226 - val_accuracy: 0.3859\n",
      "Epoch 1009/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4058 - accuracy: 0.5571 - val_loss: 0.7230 - val_accuracy: 0.3915\n",
      "Epoch 1010/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4056 - accuracy: 0.5599 - val_loss: 0.7180 - val_accuracy: 0.3888\n",
      "Epoch 1011/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4039 - accuracy: 0.5617 - val_loss: 0.7346 - val_accuracy: 0.3948\n",
      "Epoch 1012/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4005 - accuracy: 0.5653 - val_loss: 0.7124 - val_accuracy: 0.3868\n",
      "Epoch 1013/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4019 - accuracy: 0.5630 - val_loss: 0.7204 - val_accuracy: 0.3853\n",
      "Epoch 1014/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4065 - accuracy: 0.5582 - val_loss: 0.7215 - val_accuracy: 0.3856\n",
      "Epoch 1015/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4040 - accuracy: 0.5614 - val_loss: 0.7120 - val_accuracy: 0.3868\n",
      "Epoch 1016/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4060 - accuracy: 0.5576 - val_loss: 0.7131 - val_accuracy: 0.3815\n",
      "Epoch 1017/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4025 - accuracy: 0.5617 - val_loss: 0.7240 - val_accuracy: 0.3910\n",
      "Epoch 1018/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4075 - accuracy: 0.5590 - val_loss: 0.7156 - val_accuracy: 0.3829\n",
      "Epoch 1019/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4003 - accuracy: 0.5624 - val_loss: 0.7119 - val_accuracy: 0.3849\n",
      "Epoch 1020/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3987 - accuracy: 0.5639 - val_loss: 0.7117 - val_accuracy: 0.3859\n",
      "Epoch 1021/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3963 - accuracy: 0.5681 - val_loss: 0.7218 - val_accuracy: 0.3905\n",
      "Epoch 1022/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3976 - accuracy: 0.5672 - val_loss: 0.7315 - val_accuracy: 0.3899\n",
      "Epoch 1023/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4040 - accuracy: 0.5611 - val_loss: 0.7155 - val_accuracy: 0.3816\n",
      "Epoch 1024/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4014 - accuracy: 0.5576 - val_loss: 0.7222 - val_accuracy: 0.3851\n",
      "Epoch 1025/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4004 - accuracy: 0.5626 - val_loss: 0.7265 - val_accuracy: 0.3882\n",
      "Epoch 1026/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4058 - accuracy: 0.5583 - val_loss: 0.7193 - val_accuracy: 0.3849\n",
      "Epoch 1027/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4019 - accuracy: 0.5635 - val_loss: 0.7203 - val_accuracy: 0.3874\n",
      "Epoch 1028/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4012 - accuracy: 0.5621 - val_loss: 0.7078 - val_accuracy: 0.3823\n",
      "Epoch 1029/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3984 - accuracy: 0.5646 - val_loss: 0.7229 - val_accuracy: 0.3859\n",
      "Epoch 1030/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4023 - accuracy: 0.5586 - val_loss: 0.7233 - val_accuracy: 0.3861\n",
      "Epoch 1031/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4014 - accuracy: 0.5626 - val_loss: 0.7182 - val_accuracy: 0.3848\n",
      "Epoch 1032/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3970 - accuracy: 0.5646 - val_loss: 0.7228 - val_accuracy: 0.3905\n",
      "Epoch 1033/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4026 - accuracy: 0.5618 - val_loss: 0.7364 - val_accuracy: 0.3841\n",
      "Epoch 1034/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4004 - accuracy: 0.5611 - val_loss: 0.7266 - val_accuracy: 0.3909\n",
      "Epoch 1035/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4028 - accuracy: 0.5632 - val_loss: 0.7237 - val_accuracy: 0.3866\n",
      "Epoch 1036/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3958 - accuracy: 0.5672 - val_loss: 0.7244 - val_accuracy: 0.3898\n",
      "Epoch 1037/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4038 - accuracy: 0.5600 - val_loss: 0.7202 - val_accuracy: 0.3876\n",
      "Epoch 1038/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4069 - accuracy: 0.5560 - val_loss: 0.7154 - val_accuracy: 0.3870\n",
      "Epoch 1039/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4061 - accuracy: 0.5613 - val_loss: 0.7119 - val_accuracy: 0.3859\n",
      "Epoch 1040/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4032 - accuracy: 0.5597 - val_loss: 0.7269 - val_accuracy: 0.3839\n",
      "Epoch 1041/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4044 - accuracy: 0.5588 - val_loss: 0.7148 - val_accuracy: 0.3851\n",
      "Epoch 1042/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4002 - accuracy: 0.5620 - val_loss: 0.7493 - val_accuracy: 0.3869\n",
      "Epoch 1043/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4063 - accuracy: 0.5579 - val_loss: 0.7228 - val_accuracy: 0.3809\n",
      "Epoch 1044/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4110 - accuracy: 0.5546 - val_loss: 0.7129 - val_accuracy: 0.3834\n",
      "Epoch 1045/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4042 - accuracy: 0.5591 - val_loss: 0.7258 - val_accuracy: 0.3873\n",
      "Epoch 1046/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4075 - accuracy: 0.5609 - val_loss: 0.7237 - val_accuracy: 0.3875\n",
      "Epoch 1047/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4006 - accuracy: 0.5636 - val_loss: 0.7261 - val_accuracy: 0.3857\n",
      "Epoch 1048/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3993 - accuracy: 0.5634 - val_loss: 0.7176 - val_accuracy: 0.3839\n",
      "Epoch 1049/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4059 - accuracy: 0.5590 - val_loss: 0.7179 - val_accuracy: 0.3836\n",
      "Epoch 1050/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4041 - accuracy: 0.5610 - val_loss: 0.7266 - val_accuracy: 0.3869\n",
      "Epoch 1051/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4023 - accuracy: 0.5638 - val_loss: 0.7175 - val_accuracy: 0.3888\n",
      "Epoch 1052/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4026 - accuracy: 0.5629 - val_loss: 0.7250 - val_accuracy: 0.3902\n",
      "Epoch 1053/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3959 - accuracy: 0.5669 - val_loss: 0.7178 - val_accuracy: 0.3856\n",
      "Epoch 1054/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3963 - accuracy: 0.5685 - val_loss: 0.7230 - val_accuracy: 0.3839\n",
      "Epoch 1055/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3973 - accuracy: 0.5656 - val_loss: 0.7356 - val_accuracy: 0.3865\n",
      "Epoch 1056/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4011 - accuracy: 0.5618 - val_loss: 0.7218 - val_accuracy: 0.3865\n",
      "Epoch 1057/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4004 - accuracy: 0.5631 - val_loss: 0.7272 - val_accuracy: 0.3858\n",
      "Epoch 1058/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4015 - accuracy: 0.5621 - val_loss: 0.7143 - val_accuracy: 0.3839\n",
      "Epoch 1059/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4000 - accuracy: 0.5617 - val_loss: 0.7211 - val_accuracy: 0.3859\n",
      "Epoch 1060/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4021 - accuracy: 0.5609 - val_loss: 0.7222 - val_accuracy: 0.3873\n",
      "Epoch 1061/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4024 - accuracy: 0.5612 - val_loss: 0.7121 - val_accuracy: 0.3841\n",
      "Epoch 1062/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3976 - accuracy: 0.5593 - val_loss: 0.7299 - val_accuracy: 0.3885\n",
      "Epoch 1063/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4031 - accuracy: 0.5610 - val_loss: 0.7219 - val_accuracy: 0.3844\n",
      "Epoch 1064/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3989 - accuracy: 0.5653 - val_loss: 0.7218 - val_accuracy: 0.3883\n",
      "Epoch 1065/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3992 - accuracy: 0.5645 - val_loss: 0.7244 - val_accuracy: 0.3926\n",
      "Epoch 1066/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3974 - accuracy: 0.5676 - val_loss: 0.7244 - val_accuracy: 0.3861\n",
      "Epoch 1067/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3947 - accuracy: 0.5648 - val_loss: 0.7231 - val_accuracy: 0.3847\n",
      "Epoch 1068/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3935 - accuracy: 0.5672 - val_loss: 0.7249 - val_accuracy: 0.3895\n",
      "Epoch 1069/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4001 - accuracy: 0.5629 - val_loss: 0.7333 - val_accuracy: 0.3873\n",
      "Epoch 1070/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3961 - accuracy: 0.5647 - val_loss: 0.7297 - val_accuracy: 0.3850\n",
      "Epoch 1071/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3969 - accuracy: 0.5635 - val_loss: 0.7280 - val_accuracy: 0.3843\n",
      "Epoch 1072/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4026 - accuracy: 0.5564 - val_loss: 0.7231 - val_accuracy: 0.3849\n",
      "Epoch 1073/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4028 - accuracy: 0.5609 - val_loss: 0.7216 - val_accuracy: 0.3790\n",
      "Epoch 1074/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3969 - accuracy: 0.5681 - val_loss: 0.7086 - val_accuracy: 0.3781\n",
      "Epoch 1075/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4007 - accuracy: 0.5628 - val_loss: 0.7345 - val_accuracy: 0.3836\n",
      "Epoch 1076/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3950 - accuracy: 0.5672 - val_loss: 0.7224 - val_accuracy: 0.3874\n",
      "Epoch 1077/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4012 - accuracy: 0.5603 - val_loss: 0.7365 - val_accuracy: 0.3873\n",
      "Epoch 1078/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3951 - accuracy: 0.5675 - val_loss: 0.7286 - val_accuracy: 0.3872\n",
      "Epoch 1079/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3973 - accuracy: 0.5644 - val_loss: 0.7340 - val_accuracy: 0.3865\n",
      "Epoch 1080/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4026 - accuracy: 0.5587 - val_loss: 0.7211 - val_accuracy: 0.3859\n",
      "Epoch 1081/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3962 - accuracy: 0.5649 - val_loss: 0.7247 - val_accuracy: 0.3879\n",
      "Epoch 1082/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3965 - accuracy: 0.5611 - val_loss: 0.7376 - val_accuracy: 0.3875\n",
      "Epoch 1083/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4001 - accuracy: 0.5627 - val_loss: 0.7336 - val_accuracy: 0.3868\n",
      "Epoch 1084/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4025 - accuracy: 0.5617 - val_loss: 0.7223 - val_accuracy: 0.3840\n",
      "Epoch 1085/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3968 - accuracy: 0.5672 - val_loss: 0.7268 - val_accuracy: 0.3857\n",
      "Epoch 1086/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3960 - accuracy: 0.5603 - val_loss: 0.7318 - val_accuracy: 0.3878\n",
      "Epoch 1087/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3946 - accuracy: 0.5669 - val_loss: 0.7194 - val_accuracy: 0.3869\n",
      "Epoch 1088/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.4034 - accuracy: 0.5597 - val_loss: 0.7246 - val_accuracy: 0.3877\n",
      "Epoch 1089/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3993 - accuracy: 0.5642 - val_loss: 0.7208 - val_accuracy: 0.3910\n",
      "Epoch 1090/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3957 - accuracy: 0.5648 - val_loss: 0.7362 - val_accuracy: 0.3905\n",
      "Epoch 1091/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4039 - accuracy: 0.5587 - val_loss: 0.7250 - val_accuracy: 0.3887\n",
      "Epoch 1092/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3916 - accuracy: 0.5688 - val_loss: 0.7347 - val_accuracy: 0.3885\n",
      "Epoch 1093/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3980 - accuracy: 0.5644 - val_loss: 0.7273 - val_accuracy: 0.3898\n",
      "Epoch 1094/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4148 - accuracy: 0.5496 - val_loss: 0.7125 - val_accuracy: 0.3857\n",
      "Epoch 1095/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4044 - accuracy: 0.5562 - val_loss: 0.7287 - val_accuracy: 0.3884\n",
      "Epoch 1096/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4083 - accuracy: 0.5579 - val_loss: 0.7217 - val_accuracy: 0.3900\n",
      "Epoch 1097/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3968 - accuracy: 0.5641 - val_loss: 0.7290 - val_accuracy: 0.3879\n",
      "Epoch 1098/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3980 - accuracy: 0.5642 - val_loss: 0.7332 - val_accuracy: 0.3902\n",
      "Epoch 1099/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3965 - accuracy: 0.5662 - val_loss: 0.7199 - val_accuracy: 0.3844\n",
      "Epoch 1100/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4001 - accuracy: 0.5600 - val_loss: 0.7223 - val_accuracy: 0.3878\n",
      "Epoch 1101/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3952 - accuracy: 0.5653 - val_loss: 0.7319 - val_accuracy: 0.3849\n",
      "Epoch 1102/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4010 - accuracy: 0.5647 - val_loss: 0.6966 - val_accuracy: 0.3858\n",
      "Epoch 1103/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4048 - accuracy: 0.5582 - val_loss: 0.7290 - val_accuracy: 0.3875\n",
      "Epoch 1104/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3925 - accuracy: 0.5695 - val_loss: 0.7036 - val_accuracy: 0.3820\n",
      "Epoch 1105/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3943 - accuracy: 0.5651 - val_loss: 0.7272 - val_accuracy: 0.3900\n",
      "Epoch 1106/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3940 - accuracy: 0.5690 - val_loss: 0.7217 - val_accuracy: 0.3863\n",
      "Epoch 1107/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3946 - accuracy: 0.5681 - val_loss: 0.7120 - val_accuracy: 0.3836\n",
      "Epoch 1108/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3977 - accuracy: 0.5667 - val_loss: 0.7292 - val_accuracy: 0.3904\n",
      "Epoch 1109/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3936 - accuracy: 0.5685 - val_loss: 0.7175 - val_accuracy: 0.3886\n",
      "Epoch 1110/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3952 - accuracy: 0.5730 - val_loss: 0.7377 - val_accuracy: 0.3881\n",
      "Epoch 1111/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3965 - accuracy: 0.5684 - val_loss: 0.7326 - val_accuracy: 0.3879\n",
      "Epoch 1112/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3950 - accuracy: 0.5679 - val_loss: 0.7237 - val_accuracy: 0.3879\n",
      "Epoch 1113/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3975 - accuracy: 0.5637 - val_loss: 0.7136 - val_accuracy: 0.3879\n",
      "Epoch 1114/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3984 - accuracy: 0.5658 - val_loss: 0.7194 - val_accuracy: 0.3884\n",
      "Epoch 1115/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3960 - accuracy: 0.5711 - val_loss: 0.7176 - val_accuracy: 0.3857\n",
      "Epoch 1116/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3958 - accuracy: 0.5684 - val_loss: 0.7205 - val_accuracy: 0.3890\n",
      "Epoch 1117/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3979 - accuracy: 0.5654 - val_loss: 0.7331 - val_accuracy: 0.3885\n",
      "Epoch 1118/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4043 - accuracy: 0.5580 - val_loss: 0.7297 - val_accuracy: 0.3877\n",
      "Epoch 1119/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3966 - accuracy: 0.5638 - val_loss: 0.7400 - val_accuracy: 0.3885\n",
      "Epoch 1120/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3946 - accuracy: 0.5631 - val_loss: 0.7328 - val_accuracy: 0.3862\n",
      "Epoch 1121/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3962 - accuracy: 0.5663 - val_loss: 0.7224 - val_accuracy: 0.3864\n",
      "Epoch 1122/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3962 - accuracy: 0.5661 - val_loss: 0.7365 - val_accuracy: 0.3879\n",
      "Epoch 1123/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3953 - accuracy: 0.5671 - val_loss: 0.7301 - val_accuracy: 0.3876\n",
      "Epoch 1124/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3934 - accuracy: 0.5683 - val_loss: 0.7417 - val_accuracy: 0.3937\n",
      "Epoch 1125/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3948 - accuracy: 0.5716 - val_loss: 0.7347 - val_accuracy: 0.3900\n",
      "Epoch 1126/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3910 - accuracy: 0.5736 - val_loss: 0.7437 - val_accuracy: 0.3868\n",
      "Epoch 1127/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3931 - accuracy: 0.5716 - val_loss: 0.7205 - val_accuracy: 0.3855\n",
      "Epoch 1128/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3983 - accuracy: 0.5659 - val_loss: 0.7399 - val_accuracy: 0.3872\n",
      "Epoch 1129/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3936 - accuracy: 0.5693 - val_loss: 0.7349 - val_accuracy: 0.3881\n",
      "Epoch 1130/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3908 - accuracy: 0.5752 - val_loss: 0.7317 - val_accuracy: 0.3892\n",
      "Epoch 1131/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3938 - accuracy: 0.5749 - val_loss: 0.7273 - val_accuracy: 0.3864\n",
      "Epoch 1132/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3907 - accuracy: 0.5706 - val_loss: 0.7419 - val_accuracy: 0.3873\n",
      "Epoch 1133/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3934 - accuracy: 0.5692 - val_loss: 0.7347 - val_accuracy: 0.3873\n",
      "Epoch 1134/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3938 - accuracy: 0.5721 - val_loss: 0.7345 - val_accuracy: 0.3822\n",
      "Epoch 1135/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3932 - accuracy: 0.5695 - val_loss: 0.7285 - val_accuracy: 0.3863\n",
      "Epoch 1136/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3911 - accuracy: 0.5718 - val_loss: 0.7223 - val_accuracy: 0.3838\n",
      "Epoch 1137/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3978 - accuracy: 0.5672 - val_loss: 0.7178 - val_accuracy: 0.3837\n",
      "Epoch 1138/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4025 - accuracy: 0.5595 - val_loss: 0.7297 - val_accuracy: 0.3851\n",
      "Epoch 1139/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3965 - accuracy: 0.5654 - val_loss: 0.7215 - val_accuracy: 0.3849\n",
      "Epoch 1140/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3995 - accuracy: 0.5645 - val_loss: 0.7214 - val_accuracy: 0.3854\n",
      "Epoch 1141/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3966 - accuracy: 0.5670 - val_loss: 0.7289 - val_accuracy: 0.3836\n",
      "Epoch 1142/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3966 - accuracy: 0.5677 - val_loss: 0.7268 - val_accuracy: 0.3897\n",
      "Epoch 1143/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3937 - accuracy: 0.5695 - val_loss: 0.7292 - val_accuracy: 0.3869\n",
      "Epoch 1144/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3900 - accuracy: 0.5731 - val_loss: 0.7306 - val_accuracy: 0.3846\n",
      "Epoch 1145/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3906 - accuracy: 0.5714 - val_loss: 0.7361 - val_accuracy: 0.3871\n",
      "Epoch 1146/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3960 - accuracy: 0.5688 - val_loss: 0.7282 - val_accuracy: 0.3826\n",
      "Epoch 1147/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3931 - accuracy: 0.5699 - val_loss: 0.7293 - val_accuracy: 0.3841\n",
      "Epoch 1148/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3959 - accuracy: 0.5687 - val_loss: 0.7308 - val_accuracy: 0.3832\n",
      "Epoch 1149/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3910 - accuracy: 0.5711 - val_loss: 0.7269 - val_accuracy: 0.3839\n",
      "Epoch 1150/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3960 - accuracy: 0.5675 - val_loss: 0.7268 - val_accuracy: 0.3830\n",
      "Epoch 1151/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3971 - accuracy: 0.5637 - val_loss: 0.7406 - val_accuracy: 0.3868\n",
      "Epoch 1152/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3926 - accuracy: 0.5706 - val_loss: 0.7214 - val_accuracy: 0.3847\n",
      "Epoch 1153/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3873 - accuracy: 0.5718 - val_loss: 0.7406 - val_accuracy: 0.3865\n",
      "Epoch 1154/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3976 - accuracy: 0.5685 - val_loss: 0.7056 - val_accuracy: 0.3825\n",
      "Epoch 1155/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3943 - accuracy: 0.5700 - val_loss: 0.7146 - val_accuracy: 0.3837\n",
      "Epoch 1156/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4015 - accuracy: 0.5636 - val_loss: 0.7113 - val_accuracy: 0.3856\n",
      "Epoch 1157/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3943 - accuracy: 0.5685 - val_loss: 0.7224 - val_accuracy: 0.3851\n",
      "Epoch 1158/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3924 - accuracy: 0.5743 - val_loss: 0.7271 - val_accuracy: 0.3890\n",
      "Epoch 1159/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3879 - accuracy: 0.5729 - val_loss: 0.7289 - val_accuracy: 0.3891\n",
      "Epoch 1160/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3933 - accuracy: 0.5714 - val_loss: 0.7240 - val_accuracy: 0.3905\n",
      "Epoch 1161/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3961 - accuracy: 0.5686 - val_loss: 0.7314 - val_accuracy: 0.3858\n",
      "Epoch 1162/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3969 - accuracy: 0.5676 - val_loss: 0.7355 - val_accuracy: 0.3830\n",
      "Epoch 1163/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3943 - accuracy: 0.5690 - val_loss: 0.7206 - val_accuracy: 0.3868\n",
      "Epoch 1164/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3873 - accuracy: 0.5752 - val_loss: 0.7414 - val_accuracy: 0.3872\n",
      "Epoch 1165/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3946 - accuracy: 0.5690 - val_loss: 0.7354 - val_accuracy: 0.3900\n",
      "Epoch 1166/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3946 - accuracy: 0.5705 - val_loss: 0.7370 - val_accuracy: 0.3900\n",
      "Epoch 1167/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4028 - accuracy: 0.5612 - val_loss: 0.7292 - val_accuracy: 0.3882\n",
      "Epoch 1168/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3973 - accuracy: 0.5697 - val_loss: 0.7164 - val_accuracy: 0.3900\n",
      "Epoch 1169/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3891 - accuracy: 0.5747 - val_loss: 0.7254 - val_accuracy: 0.3846\n",
      "Epoch 1170/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3964 - accuracy: 0.5645 - val_loss: 0.7310 - val_accuracy: 0.3868\n",
      "Epoch 1171/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3930 - accuracy: 0.5697 - val_loss: 0.7117 - val_accuracy: 0.3858\n",
      "Epoch 1172/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3945 - accuracy: 0.5642 - val_loss: 0.7270 - val_accuracy: 0.3829\n",
      "Epoch 1173/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3963 - accuracy: 0.5635 - val_loss: 0.7118 - val_accuracy: 0.3843\n",
      "Epoch 1174/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3987 - accuracy: 0.5604 - val_loss: 0.7102 - val_accuracy: 0.3859\n",
      "Epoch 1175/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4014 - accuracy: 0.5650 - val_loss: 0.7128 - val_accuracy: 0.3826\n",
      "Epoch 1176/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4026 - accuracy: 0.5596 - val_loss: 0.7329 - val_accuracy: 0.3866\n",
      "Epoch 1177/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3927 - accuracy: 0.5717 - val_loss: 0.7270 - val_accuracy: 0.3839\n",
      "Epoch 1178/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3974 - accuracy: 0.5687 - val_loss: 0.7278 - val_accuracy: 0.3855\n",
      "Epoch 1179/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3908 - accuracy: 0.5709 - val_loss: 0.7225 - val_accuracy: 0.3860\n",
      "Epoch 1180/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3929 - accuracy: 0.5698 - val_loss: 0.7218 - val_accuracy: 0.3878\n",
      "Epoch 1181/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3974 - accuracy: 0.5630 - val_loss: 0.7223 - val_accuracy: 0.3896\n",
      "Epoch 1182/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3911 - accuracy: 0.5725 - val_loss: 0.7333 - val_accuracy: 0.3842\n",
      "Epoch 1183/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3917 - accuracy: 0.5688 - val_loss: 0.7326 - val_accuracy: 0.3856\n",
      "Epoch 1184/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3928 - accuracy: 0.5677 - val_loss: 0.7323 - val_accuracy: 0.3896\n",
      "Epoch 1185/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3866 - accuracy: 0.5727 - val_loss: 0.7328 - val_accuracy: 0.3875\n",
      "Epoch 1186/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3864 - accuracy: 0.5751 - val_loss: 0.7279 - val_accuracy: 0.3812\n",
      "Epoch 1187/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3904 - accuracy: 0.5757 - val_loss: 0.7265 - val_accuracy: 0.3912\n",
      "Epoch 1188/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3900 - accuracy: 0.5703 - val_loss: 0.7327 - val_accuracy: 0.3880\n",
      "Epoch 1189/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3998 - accuracy: 0.5651 - val_loss: 0.7180 - val_accuracy: 0.3879\n",
      "Epoch 1190/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3957 - accuracy: 0.5679 - val_loss: 0.7295 - val_accuracy: 0.3850\n",
      "Epoch 1191/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.4020 - accuracy: 0.5637 - val_loss: 0.7343 - val_accuracy: 0.3852\n",
      "Epoch 1192/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3939 - accuracy: 0.5665 - val_loss: 0.7379 - val_accuracy: 0.3836\n",
      "Epoch 1193/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3918 - accuracy: 0.5720 - val_loss: 0.7338 - val_accuracy: 0.3905\n",
      "Epoch 1194/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3982 - accuracy: 0.5627 - val_loss: 0.7253 - val_accuracy: 0.3859\n",
      "Epoch 1195/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3913 - accuracy: 0.5703 - val_loss: 0.7244 - val_accuracy: 0.3887\n",
      "Epoch 1196/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3953 - accuracy: 0.5635 - val_loss: 0.7338 - val_accuracy: 0.3845\n",
      "Epoch 1197/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3938 - accuracy: 0.5712 - val_loss: 0.7283 - val_accuracy: 0.3871\n",
      "Epoch 1198/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3928 - accuracy: 0.5681 - val_loss: 0.7459 - val_accuracy: 0.3855\n",
      "Epoch 1199/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3955 - accuracy: 0.5653 - val_loss: 0.7280 - val_accuracy: 0.3875\n",
      "Epoch 1200/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3949 - accuracy: 0.5680 - val_loss: 0.7250 - val_accuracy: 0.3892\n",
      "Epoch 1201/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3913 - accuracy: 0.5703 - val_loss: 0.7212 - val_accuracy: 0.3868\n",
      "Epoch 1202/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3877 - accuracy: 0.5726 - val_loss: 0.7400 - val_accuracy: 0.3881\n",
      "Epoch 1203/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3877 - accuracy: 0.5731 - val_loss: 0.7244 - val_accuracy: 0.3853\n",
      "Epoch 1204/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3897 - accuracy: 0.5734 - val_loss: 0.7248 - val_accuracy: 0.3875\n",
      "Epoch 1205/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3932 - accuracy: 0.5678 - val_loss: 0.7095 - val_accuracy: 0.3859\n",
      "Epoch 1206/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3906 - accuracy: 0.5701 - val_loss: 0.7383 - val_accuracy: 0.3856\n",
      "Epoch 1207/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3969 - accuracy: 0.5668 - val_loss: 0.7218 - val_accuracy: 0.3853\n",
      "Epoch 1208/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3961 - accuracy: 0.5689 - val_loss: 0.7295 - val_accuracy: 0.3848\n",
      "Epoch 1209/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3916 - accuracy: 0.5731 - val_loss: 0.7247 - val_accuracy: 0.3887\n",
      "Epoch 1210/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3912 - accuracy: 0.5730 - val_loss: 0.7339 - val_accuracy: 0.3867\n",
      "Epoch 1211/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3936 - accuracy: 0.5669 - val_loss: 0.7317 - val_accuracy: 0.3858\n",
      "Epoch 1212/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3928 - accuracy: 0.5680 - val_loss: 0.7339 - val_accuracy: 0.3873\n",
      "Epoch 1213/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3902 - accuracy: 0.5754 - val_loss: 0.7298 - val_accuracy: 0.3875\n",
      "Epoch 1214/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4052 - accuracy: 0.5584 - val_loss: 0.7296 - val_accuracy: 0.3834\n",
      "Epoch 1215/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3917 - accuracy: 0.5697 - val_loss: 0.7496 - val_accuracy: 0.3877\n",
      "Epoch 1216/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3910 - accuracy: 0.5727 - val_loss: 0.7374 - val_accuracy: 0.3897\n",
      "Epoch 1217/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3865 - accuracy: 0.5766 - val_loss: 0.7426 - val_accuracy: 0.3906\n",
      "Epoch 1218/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4001 - accuracy: 0.5637 - val_loss: 0.7257 - val_accuracy: 0.3901\n",
      "Epoch 1219/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3889 - accuracy: 0.5728 - val_loss: 0.7304 - val_accuracy: 0.3856\n",
      "Epoch 1220/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3934 - accuracy: 0.5675 - val_loss: 0.7425 - val_accuracy: 0.3898\n",
      "Epoch 1221/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3920 - accuracy: 0.5704 - val_loss: 0.7379 - val_accuracy: 0.3869\n",
      "Epoch 1222/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3904 - accuracy: 0.5752 - val_loss: 0.7317 - val_accuracy: 0.3820\n",
      "Epoch 1223/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3908 - accuracy: 0.5709 - val_loss: 0.7343 - val_accuracy: 0.3879\n",
      "Epoch 1224/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3929 - accuracy: 0.5688 - val_loss: 0.7337 - val_accuracy: 0.3916\n",
      "Epoch 1225/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3869 - accuracy: 0.5806 - val_loss: 0.7392 - val_accuracy: 0.3899\n",
      "Epoch 1226/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3863 - accuracy: 0.5756 - val_loss: 0.7343 - val_accuracy: 0.3864\n",
      "Epoch 1227/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3929 - accuracy: 0.5699 - val_loss: 0.7333 - val_accuracy: 0.3859\n",
      "Epoch 1228/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3878 - accuracy: 0.5758 - val_loss: 0.7386 - val_accuracy: 0.3883\n",
      "Epoch 1229/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3886 - accuracy: 0.5729 - val_loss: 0.7546 - val_accuracy: 0.3874\n",
      "Epoch 1230/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3852 - accuracy: 0.5784 - val_loss: 0.7427 - val_accuracy: 0.3874\n",
      "Epoch 1231/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3903 - accuracy: 0.5694 - val_loss: 0.7416 - val_accuracy: 0.3895\n",
      "Epoch 1232/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3954 - accuracy: 0.5674 - val_loss: 0.7399 - val_accuracy: 0.3922\n",
      "Epoch 1233/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3883 - accuracy: 0.5766 - val_loss: 0.7558 - val_accuracy: 0.3928\n",
      "Epoch 1234/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3873 - accuracy: 0.5765 - val_loss: 0.7470 - val_accuracy: 0.3859\n",
      "Epoch 1235/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3912 - accuracy: 0.5710 - val_loss: 0.7490 - val_accuracy: 0.3868\n",
      "Epoch 1236/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3908 - accuracy: 0.5719 - val_loss: 0.7436 - val_accuracy: 0.3844\n",
      "Epoch 1237/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3878 - accuracy: 0.5759 - val_loss: 0.7303 - val_accuracy: 0.3906\n",
      "Epoch 1238/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3922 - accuracy: 0.5744 - val_loss: 0.7358 - val_accuracy: 0.3885\n",
      "Epoch 1239/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3941 - accuracy: 0.5705 - val_loss: 0.7275 - val_accuracy: 0.3891\n",
      "Epoch 1240/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3923 - accuracy: 0.5692 - val_loss: 0.7412 - val_accuracy: 0.3890\n",
      "Epoch 1241/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3938 - accuracy: 0.5689 - val_loss: 0.7380 - val_accuracy: 0.3905\n",
      "Epoch 1242/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3935 - accuracy: 0.5691 - val_loss: 0.7351 - val_accuracy: 0.3864\n",
      "Epoch 1243/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3881 - accuracy: 0.5718 - val_loss: 0.7348 - val_accuracy: 0.3899\n",
      "Epoch 1244/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3974 - accuracy: 0.5682 - val_loss: 0.7300 - val_accuracy: 0.3849\n",
      "Epoch 1245/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3905 - accuracy: 0.5726 - val_loss: 0.7326 - val_accuracy: 0.3936\n",
      "Epoch 1246/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3872 - accuracy: 0.5761 - val_loss: 0.7410 - val_accuracy: 0.3898\n",
      "Epoch 1247/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3890 - accuracy: 0.5734 - val_loss: 0.7307 - val_accuracy: 0.3876\n",
      "Epoch 1248/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3925 - accuracy: 0.5724 - val_loss: 0.7290 - val_accuracy: 0.3877\n",
      "Epoch 1249/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3915 - accuracy: 0.5721 - val_loss: 0.7253 - val_accuracy: 0.3852\n",
      "Epoch 1250/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3920 - accuracy: 0.5716 - val_loss: 0.7309 - val_accuracy: 0.3909\n",
      "Epoch 1251/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3918 - accuracy: 0.5716 - val_loss: 0.7330 - val_accuracy: 0.3902\n",
      "Epoch 1252/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3877 - accuracy: 0.5744 - val_loss: 0.7335 - val_accuracy: 0.3898\n",
      "Epoch 1253/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3912 - accuracy: 0.5724 - val_loss: 0.7342 - val_accuracy: 0.3881\n",
      "Epoch 1254/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3913 - accuracy: 0.5728 - val_loss: 0.7369 - val_accuracy: 0.3910\n",
      "Epoch 1255/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3873 - accuracy: 0.5755 - val_loss: 0.7322 - val_accuracy: 0.3901\n",
      "Epoch 1256/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3850 - accuracy: 0.5761 - val_loss: 0.7410 - val_accuracy: 0.3889\n",
      "Epoch 1257/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3910 - accuracy: 0.5726 - val_loss: 0.7334 - val_accuracy: 0.3889\n",
      "Epoch 1258/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3863 - accuracy: 0.5775 - val_loss: 0.7330 - val_accuracy: 0.3879\n",
      "Epoch 1259/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3925 - accuracy: 0.5729 - val_loss: 0.7400 - val_accuracy: 0.3885\n",
      "Epoch 1260/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3926 - accuracy: 0.5711 - val_loss: 0.7266 - val_accuracy: 0.3863\n",
      "Epoch 1261/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3885 - accuracy: 0.5745 - val_loss: 0.7376 - val_accuracy: 0.3930\n",
      "Epoch 1262/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3926 - accuracy: 0.5729 - val_loss: 0.7282 - val_accuracy: 0.3933\n",
      "Epoch 1263/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3898 - accuracy: 0.5730 - val_loss: 0.7299 - val_accuracy: 0.3886\n",
      "Epoch 1264/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4046 - accuracy: 0.5639 - val_loss: 0.7298 - val_accuracy: 0.3902\n",
      "Epoch 1265/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3948 - accuracy: 0.5681 - val_loss: 0.7214 - val_accuracy: 0.3851\n",
      "Epoch 1266/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3911 - accuracy: 0.5673 - val_loss: 0.7315 - val_accuracy: 0.3814\n",
      "Epoch 1267/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3869 - accuracy: 0.5757 - val_loss: 0.7316 - val_accuracy: 0.3867\n",
      "Epoch 1268/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3859 - accuracy: 0.5771 - val_loss: 0.7440 - val_accuracy: 0.3910\n",
      "Epoch 1269/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3939 - accuracy: 0.5698 - val_loss: 0.7369 - val_accuracy: 0.3876\n",
      "Epoch 1270/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3929 - accuracy: 0.5715 - val_loss: 0.7263 - val_accuracy: 0.3825\n",
      "Epoch 1271/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3942 - accuracy: 0.5678 - val_loss: 0.7288 - val_accuracy: 0.3942\n",
      "Epoch 1272/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3909 - accuracy: 0.5707 - val_loss: 0.7275 - val_accuracy: 0.3854\n",
      "Epoch 1273/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3919 - accuracy: 0.5712 - val_loss: 0.7283 - val_accuracy: 0.3830\n",
      "Epoch 1274/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3906 - accuracy: 0.5759 - val_loss: 0.7314 - val_accuracy: 0.3888\n",
      "Epoch 1275/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3881 - accuracy: 0.5745 - val_loss: 0.7398 - val_accuracy: 0.3940\n",
      "Epoch 1276/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3892 - accuracy: 0.5775 - val_loss: 0.7411 - val_accuracy: 0.3876\n",
      "Epoch 1277/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3880 - accuracy: 0.5768 - val_loss: 0.7366 - val_accuracy: 0.3859\n",
      "Epoch 1278/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3895 - accuracy: 0.5740 - val_loss: 0.7382 - val_accuracy: 0.3885\n",
      "Epoch 1279/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3858 - accuracy: 0.5759 - val_loss: 0.7335 - val_accuracy: 0.3872\n",
      "Epoch 1280/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3886 - accuracy: 0.5743 - val_loss: 0.7300 - val_accuracy: 0.3859\n",
      "Epoch 1281/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3929 - accuracy: 0.5704 - val_loss: 0.7275 - val_accuracy: 0.3876\n",
      "Epoch 1282/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3922 - accuracy: 0.5732 - val_loss: 0.7339 - val_accuracy: 0.3872\n",
      "Epoch 1283/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3867 - accuracy: 0.5772 - val_loss: 0.7295 - val_accuracy: 0.3904\n",
      "Epoch 1284/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3944 - accuracy: 0.5698 - val_loss: 0.7312 - val_accuracy: 0.3850\n",
      "Epoch 1285/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3916 - accuracy: 0.5722 - val_loss: 0.7296 - val_accuracy: 0.3881\n",
      "Epoch 1286/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3903 - accuracy: 0.5701 - val_loss: 0.7407 - val_accuracy: 0.3895\n",
      "Epoch 1287/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3916 - accuracy: 0.5706 - val_loss: 0.7478 - val_accuracy: 0.3952\n",
      "Epoch 1288/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3885 - accuracy: 0.5711 - val_loss: 0.7395 - val_accuracy: 0.3914\n",
      "Epoch 1289/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3890 - accuracy: 0.5719 - val_loss: 0.7301 - val_accuracy: 0.3939\n",
      "Epoch 1290/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3879 - accuracy: 0.5742 - val_loss: 0.7329 - val_accuracy: 0.3865\n",
      "Epoch 1291/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3882 - accuracy: 0.5723 - val_loss: 0.7343 - val_accuracy: 0.3884\n",
      "Epoch 1292/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3982 - accuracy: 0.5652 - val_loss: 0.7146 - val_accuracy: 0.3900\n",
      "Epoch 1293/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3948 - accuracy: 0.5693 - val_loss: 0.7239 - val_accuracy: 0.3887\n",
      "Epoch 1294/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3971 - accuracy: 0.5690 - val_loss: 0.7115 - val_accuracy: 0.3840\n",
      "Epoch 1295/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4127 - accuracy: 0.5503 - val_loss: 0.7262 - val_accuracy: 0.3885\n",
      "Epoch 1296/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3935 - accuracy: 0.5701 - val_loss: 0.7214 - val_accuracy: 0.3876\n",
      "Epoch 1297/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3941 - accuracy: 0.5699 - val_loss: 0.7532 - val_accuracy: 0.3909\n",
      "Epoch 1298/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3952 - accuracy: 0.5691 - val_loss: 0.7341 - val_accuracy: 0.3865\n",
      "Epoch 1299/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4051 - accuracy: 0.5603 - val_loss: 0.7141 - val_accuracy: 0.3860\n",
      "Epoch 1300/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3987 - accuracy: 0.5656 - val_loss: 0.7149 - val_accuracy: 0.3879\n",
      "Epoch 1301/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3914 - accuracy: 0.5684 - val_loss: 0.7429 - val_accuracy: 0.3884\n",
      "Epoch 1302/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3969 - accuracy: 0.5694 - val_loss: 0.7287 - val_accuracy: 0.3842\n",
      "Epoch 1303/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3902 - accuracy: 0.5716 - val_loss: 0.7260 - val_accuracy: 0.3849\n",
      "Epoch 1304/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3860 - accuracy: 0.5771 - val_loss: 0.7555 - val_accuracy: 0.3889\n",
      "Epoch 1305/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3852 - accuracy: 0.5799 - val_loss: 0.7356 - val_accuracy: 0.3867\n",
      "Epoch 1306/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3913 - accuracy: 0.5733 - val_loss: 0.7209 - val_accuracy: 0.3859\n",
      "Epoch 1307/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3932 - accuracy: 0.5712 - val_loss: 0.7234 - val_accuracy: 0.3859\n",
      "Epoch 1308/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3976 - accuracy: 0.5678 - val_loss: 0.7218 - val_accuracy: 0.3885\n",
      "Epoch 1309/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3881 - accuracy: 0.5737 - val_loss: 0.7422 - val_accuracy: 0.3882\n",
      "Epoch 1310/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3979 - accuracy: 0.5694 - val_loss: 0.7259 - val_accuracy: 0.3869\n",
      "Epoch 1311/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3903 - accuracy: 0.5744 - val_loss: 0.7345 - val_accuracy: 0.3904\n",
      "Epoch 1312/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3932 - accuracy: 0.5708 - val_loss: 0.7206 - val_accuracy: 0.3894\n",
      "Epoch 1313/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3975 - accuracy: 0.5661 - val_loss: 0.7395 - val_accuracy: 0.3869\n",
      "Epoch 1314/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3855 - accuracy: 0.5745 - val_loss: 0.7314 - val_accuracy: 0.3858\n",
      "Epoch 1315/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3907 - accuracy: 0.5741 - val_loss: 0.7189 - val_accuracy: 0.3871\n",
      "Epoch 1316/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3970 - accuracy: 0.5703 - val_loss: 0.7378 - val_accuracy: 0.3869\n",
      "Epoch 1317/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3969 - accuracy: 0.5667 - val_loss: 0.7443 - val_accuracy: 0.3875\n",
      "Epoch 1318/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3852 - accuracy: 0.5796 - val_loss: 0.7333 - val_accuracy: 0.3888\n",
      "Epoch 1319/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3832 - accuracy: 0.5793 - val_loss: 0.7464 - val_accuracy: 0.3862\n",
      "Epoch 1320/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3878 - accuracy: 0.5770 - val_loss: 0.7265 - val_accuracy: 0.3858\n",
      "Epoch 1321/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3941 - accuracy: 0.5686 - val_loss: 0.7211 - val_accuracy: 0.3841\n",
      "Epoch 1322/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3968 - accuracy: 0.5643 - val_loss: 0.7359 - val_accuracy: 0.3831\n",
      "Epoch 1323/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3921 - accuracy: 0.5684 - val_loss: 0.7312 - val_accuracy: 0.3844\n",
      "Epoch 1324/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3875 - accuracy: 0.5756 - val_loss: 0.7446 - val_accuracy: 0.3891\n",
      "Epoch 1325/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3866 - accuracy: 0.5784 - val_loss: 0.7360 - val_accuracy: 0.3869\n",
      "Epoch 1326/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3868 - accuracy: 0.5758 - val_loss: 0.7376 - val_accuracy: 0.3901\n",
      "Epoch 1327/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3908 - accuracy: 0.5719 - val_loss: 0.7310 - val_accuracy: 0.3896\n",
      "Epoch 1328/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3856 - accuracy: 0.5747 - val_loss: 0.7458 - val_accuracy: 0.3918\n",
      "Epoch 1329/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3885 - accuracy: 0.5718 - val_loss: 0.7353 - val_accuracy: 0.3878\n",
      "Epoch 1330/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3840 - accuracy: 0.5770 - val_loss: 0.7396 - val_accuracy: 0.3886\n",
      "Epoch 1331/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3811 - accuracy: 0.5776 - val_loss: 0.7314 - val_accuracy: 0.3840\n",
      "Epoch 1332/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3807 - accuracy: 0.5805 - val_loss: 0.7361 - val_accuracy: 0.3882\n",
      "Epoch 1333/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3861 - accuracy: 0.5752 - val_loss: 0.7403 - val_accuracy: 0.3892\n",
      "Epoch 1334/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3846 - accuracy: 0.5788 - val_loss: 0.7464 - val_accuracy: 0.3895\n",
      "Epoch 1335/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3900 - accuracy: 0.5756 - val_loss: 0.7325 - val_accuracy: 0.3852\n",
      "Epoch 1336/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3871 - accuracy: 0.5728 - val_loss: 0.7372 - val_accuracy: 0.3886\n",
      "Epoch 1337/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.3918 - accuracy: 0.5707 - val_loss: 0.7282 - val_accuracy: 0.3881\n",
      "Epoch 1338/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3856 - accuracy: 0.5769 - val_loss: 0.7277 - val_accuracy: 0.3850\n",
      "Epoch 1339/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3847 - accuracy: 0.5756 - val_loss: 0.7403 - val_accuracy: 0.3891\n",
      "Epoch 1340/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3944 - accuracy: 0.5650 - val_loss: 0.7319 - val_accuracy: 0.3862\n",
      "Epoch 1341/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3849 - accuracy: 0.5728 - val_loss: 0.7461 - val_accuracy: 0.3880\n",
      "Epoch 1342/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3911 - accuracy: 0.5744 - val_loss: 0.7371 - val_accuracy: 0.3892\n",
      "Epoch 1343/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3915 - accuracy: 0.5710 - val_loss: 0.7575 - val_accuracy: 0.3898\n",
      "Epoch 1344/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3864 - accuracy: 0.5748 - val_loss: 0.7375 - val_accuracy: 0.3902\n",
      "Epoch 1345/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3885 - accuracy: 0.5740 - val_loss: 0.7450 - val_accuracy: 0.3894\n",
      "Epoch 1346/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3896 - accuracy: 0.5779 - val_loss: 0.7439 - val_accuracy: 0.3936\n",
      "Epoch 1347/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3862 - accuracy: 0.5779 - val_loss: 0.7446 - val_accuracy: 0.3871\n",
      "Epoch 1348/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3868 - accuracy: 0.5727 - val_loss: 0.7583 - val_accuracy: 0.3876\n",
      "Epoch 1349/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3916 - accuracy: 0.5759 - val_loss: 0.7205 - val_accuracy: 0.3889\n",
      "Epoch 1350/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3872 - accuracy: 0.5764 - val_loss: 0.7359 - val_accuracy: 0.3870\n",
      "Epoch 1351/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3865 - accuracy: 0.5768 - val_loss: 0.7490 - val_accuracy: 0.3891\n",
      "Epoch 1352/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3867 - accuracy: 0.5757 - val_loss: 0.7369 - val_accuracy: 0.3874\n",
      "Epoch 1353/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3842 - accuracy: 0.5795 - val_loss: 0.7433 - val_accuracy: 0.3928\n",
      "Epoch 1354/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3827 - accuracy: 0.5843 - val_loss: 0.7541 - val_accuracy: 0.3910\n",
      "Epoch 1355/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3889 - accuracy: 0.5768 - val_loss: 0.7445 - val_accuracy: 0.3888\n",
      "Epoch 1356/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3852 - accuracy: 0.5797 - val_loss: 0.7378 - val_accuracy: 0.3869\n",
      "Epoch 1357/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3813 - accuracy: 0.5818 - val_loss: 0.7428 - val_accuracy: 0.3875\n",
      "Epoch 1358/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3912 - accuracy: 0.5702 - val_loss: 0.7321 - val_accuracy: 0.3836\n",
      "Epoch 1359/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3831 - accuracy: 0.5775 - val_loss: 0.7529 - val_accuracy: 0.3849\n",
      "Epoch 1360/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3842 - accuracy: 0.5780 - val_loss: 0.7424 - val_accuracy: 0.3881\n",
      "Epoch 1361/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3781 - accuracy: 0.5859 - val_loss: 0.7412 - val_accuracy: 0.3916\n",
      "Epoch 1362/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3846 - accuracy: 0.5761 - val_loss: 0.7352 - val_accuracy: 0.3859\n",
      "Epoch 1363/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3892 - accuracy: 0.5684 - val_loss: 0.7542 - val_accuracy: 0.3887\n",
      "Epoch 1364/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3837 - accuracy: 0.5758 - val_loss: 0.7408 - val_accuracy: 0.3899\n",
      "Epoch 1365/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3857 - accuracy: 0.5740 - val_loss: 0.7264 - val_accuracy: 0.3854\n",
      "Epoch 1366/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3897 - accuracy: 0.5731 - val_loss: 0.7289 - val_accuracy: 0.3841\n",
      "Epoch 1367/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3928 - accuracy: 0.5705 - val_loss: 0.7331 - val_accuracy: 0.3878\n",
      "Epoch 1368/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3874 - accuracy: 0.5730 - val_loss: 0.7410 - val_accuracy: 0.3863\n",
      "Epoch 1369/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3904 - accuracy: 0.5789 - val_loss: 0.7227 - val_accuracy: 0.3880\n",
      "Epoch 1370/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3901 - accuracy: 0.5716 - val_loss: 0.7184 - val_accuracy: 0.3839\n",
      "Epoch 1371/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3909 - accuracy: 0.5723 - val_loss: 0.7232 - val_accuracy: 0.3880\n",
      "Epoch 1372/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3919 - accuracy: 0.5720 - val_loss: 0.7260 - val_accuracy: 0.3854\n",
      "Epoch 1373/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4019 - accuracy: 0.5617 - val_loss: 0.7397 - val_accuracy: 0.3875\n",
      "Epoch 1374/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3885 - accuracy: 0.5749 - val_loss: 0.7425 - val_accuracy: 0.3893\n",
      "Epoch 1375/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3935 - accuracy: 0.5710 - val_loss: 0.7334 - val_accuracy: 0.3859\n",
      "Epoch 1376/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3858 - accuracy: 0.5763 - val_loss: 0.7462 - val_accuracy: 0.3921\n",
      "Epoch 1377/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3849 - accuracy: 0.5815 - val_loss: 0.7326 - val_accuracy: 0.3876\n",
      "Epoch 1378/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3884 - accuracy: 0.5765 - val_loss: 0.7461 - val_accuracy: 0.3892\n",
      "Epoch 1379/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3879 - accuracy: 0.5746 - val_loss: 0.7442 - val_accuracy: 0.3841\n",
      "Epoch 1380/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3847 - accuracy: 0.5763 - val_loss: 0.7395 - val_accuracy: 0.3868\n",
      "Epoch 1381/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3818 - accuracy: 0.5797 - val_loss: 0.7465 - val_accuracy: 0.3894\n",
      "Epoch 1382/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3829 - accuracy: 0.5829 - val_loss: 0.7527 - val_accuracy: 0.3923\n",
      "Epoch 1383/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3815 - accuracy: 0.5830 - val_loss: 0.7518 - val_accuracy: 0.3894\n",
      "Epoch 1384/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3815 - accuracy: 0.5842 - val_loss: 0.7462 - val_accuracy: 0.3904\n",
      "Epoch 1385/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3842 - accuracy: 0.5791 - val_loss: 0.7344 - val_accuracy: 0.3880\n",
      "Epoch 1386/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3864 - accuracy: 0.5761 - val_loss: 0.7490 - val_accuracy: 0.3900\n",
      "Epoch 1387/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3804 - accuracy: 0.5828 - val_loss: 0.7465 - val_accuracy: 0.3908\n",
      "Epoch 1388/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3829 - accuracy: 0.5808 - val_loss: 0.7348 - val_accuracy: 0.3853\n",
      "Epoch 1389/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3832 - accuracy: 0.5812 - val_loss: 0.7502 - val_accuracy: 0.3891\n",
      "Epoch 1390/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3866 - accuracy: 0.5776 - val_loss: 0.7342 - val_accuracy: 0.3900\n",
      "Epoch 1391/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3841 - accuracy: 0.5803 - val_loss: 0.7374 - val_accuracy: 0.3879\n",
      "Epoch 1392/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3832 - accuracy: 0.5804 - val_loss: 0.7459 - val_accuracy: 0.3869\n",
      "Epoch 1393/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3836 - accuracy: 0.5813 - val_loss: 0.7435 - val_accuracy: 0.3862\n",
      "Epoch 1394/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3823 - accuracy: 0.5784 - val_loss: 0.7469 - val_accuracy: 0.3904\n",
      "Epoch 1395/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3863 - accuracy: 0.5750 - val_loss: 0.7339 - val_accuracy: 0.3901\n",
      "Epoch 1396/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3824 - accuracy: 0.5822 - val_loss: 0.7524 - val_accuracy: 0.3919\n",
      "Epoch 1397/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3811 - accuracy: 0.5835 - val_loss: 0.7401 - val_accuracy: 0.3844\n",
      "Epoch 1398/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3895 - accuracy: 0.5757 - val_loss: 0.7149 - val_accuracy: 0.3871\n",
      "Epoch 1399/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3826 - accuracy: 0.5802 - val_loss: 0.7383 - val_accuracy: 0.3899\n",
      "Epoch 1400/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3804 - accuracy: 0.5848 - val_loss: 0.7494 - val_accuracy: 0.3867\n",
      "Epoch 1401/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3932 - accuracy: 0.5701 - val_loss: 0.7382 - val_accuracy: 0.3910\n",
      "Epoch 1402/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3880 - accuracy: 0.5742 - val_loss: 0.7462 - val_accuracy: 0.3894\n",
      "Epoch 1403/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3858 - accuracy: 0.5786 - val_loss: 0.7392 - val_accuracy: 0.3859\n",
      "Epoch 1404/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3909 - accuracy: 0.5766 - val_loss: 0.7385 - val_accuracy: 0.3879\n",
      "Epoch 1405/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3849 - accuracy: 0.5779 - val_loss: 0.7552 - val_accuracy: 0.3895\n",
      "Epoch 1406/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3901 - accuracy: 0.5735 - val_loss: 0.7262 - val_accuracy: 0.3853\n",
      "Epoch 1407/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3901 - accuracy: 0.5757 - val_loss: 0.7387 - val_accuracy: 0.3887\n",
      "Epoch 1408/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3867 - accuracy: 0.5761 - val_loss: 0.7546 - val_accuracy: 0.3901\n",
      "Epoch 1409/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3858 - accuracy: 0.5792 - val_loss: 0.7371 - val_accuracy: 0.3854\n",
      "Epoch 1410/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3912 - accuracy: 0.5730 - val_loss: 0.7440 - val_accuracy: 0.3873\n",
      "Epoch 1411/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3873 - accuracy: 0.5742 - val_loss: 0.7370 - val_accuracy: 0.3905\n",
      "Epoch 1412/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3917 - accuracy: 0.5769 - val_loss: 0.7343 - val_accuracy: 0.3880\n",
      "Epoch 1413/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3878 - accuracy: 0.5786 - val_loss: 0.7375 - val_accuracy: 0.3868\n",
      "Epoch 1414/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3908 - accuracy: 0.5712 - val_loss: 0.7405 - val_accuracy: 0.3907\n",
      "Epoch 1415/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3936 - accuracy: 0.5726 - val_loss: 0.7287 - val_accuracy: 0.3837\n",
      "Epoch 1416/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3895 - accuracy: 0.5732 - val_loss: 0.7417 - val_accuracy: 0.3880\n",
      "Epoch 1417/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3800 - accuracy: 0.5813 - val_loss: 0.7413 - val_accuracy: 0.3917\n",
      "Epoch 1418/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3844 - accuracy: 0.5800 - val_loss: 0.7494 - val_accuracy: 0.3872\n",
      "Epoch 1419/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3927 - accuracy: 0.5709 - val_loss: 0.7297 - val_accuracy: 0.3854\n",
      "Epoch 1420/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3860 - accuracy: 0.5765 - val_loss: 0.7533 - val_accuracy: 0.3886\n",
      "Epoch 1421/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3885 - accuracy: 0.5771 - val_loss: 0.7436 - val_accuracy: 0.3896\n",
      "Epoch 1422/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4038 - accuracy: 0.5590 - val_loss: 0.7437 - val_accuracy: 0.3899\n",
      "Epoch 1423/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3828 - accuracy: 0.5795 - val_loss: 0.7467 - val_accuracy: 0.3846\n",
      "Epoch 1424/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3785 - accuracy: 0.5845 - val_loss: 0.7422 - val_accuracy: 0.3847\n",
      "Epoch 1425/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3837 - accuracy: 0.5772 - val_loss: 0.7340 - val_accuracy: 0.3867\n",
      "Epoch 1426/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3823 - accuracy: 0.5806 - val_loss: 0.7350 - val_accuracy: 0.3867\n",
      "Epoch 1427/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3904 - accuracy: 0.5753 - val_loss: 0.7252 - val_accuracy: 0.3885\n",
      "Epoch 1428/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3874 - accuracy: 0.5753 - val_loss: 0.7527 - val_accuracy: 0.3945\n",
      "Epoch 1429/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3857 - accuracy: 0.5749 - val_loss: 0.7355 - val_accuracy: 0.3889\n",
      "Epoch 1430/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3868 - accuracy: 0.5758 - val_loss: 0.7355 - val_accuracy: 0.3858\n",
      "Epoch 1431/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3855 - accuracy: 0.5759 - val_loss: 0.7340 - val_accuracy: 0.3901\n",
      "Epoch 1432/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3840 - accuracy: 0.5774 - val_loss: 0.7378 - val_accuracy: 0.3890\n",
      "Epoch 1433/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3845 - accuracy: 0.5782 - val_loss: 0.7604 - val_accuracy: 0.3904\n",
      "Epoch 1434/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3862 - accuracy: 0.5754 - val_loss: 0.7438 - val_accuracy: 0.3888\n",
      "Epoch 1435/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3893 - accuracy: 0.5714 - val_loss: 0.7405 - val_accuracy: 0.3876\n",
      "Epoch 1436/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3840 - accuracy: 0.5762 - val_loss: 0.7333 - val_accuracy: 0.3879\n",
      "Epoch 1437/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3790 - accuracy: 0.5823 - val_loss: 0.7463 - val_accuracy: 0.3897\n",
      "Epoch 1438/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3815 - accuracy: 0.5807 - val_loss: 0.7313 - val_accuracy: 0.3878\n",
      "Epoch 1439/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3835 - accuracy: 0.5784 - val_loss: 0.7346 - val_accuracy: 0.3874\n",
      "Epoch 1440/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3818 - accuracy: 0.5779 - val_loss: 0.7503 - val_accuracy: 0.3882\n",
      "Epoch 1441/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3817 - accuracy: 0.5823 - val_loss: 0.7344 - val_accuracy: 0.3877\n",
      "Epoch 1442/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3793 - accuracy: 0.5840 - val_loss: 0.7428 - val_accuracy: 0.3872\n",
      "Epoch 1443/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3883 - accuracy: 0.5770 - val_loss: 0.7432 - val_accuracy: 0.3894\n",
      "Epoch 1444/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3852 - accuracy: 0.5784 - val_loss: 0.7316 - val_accuracy: 0.3879\n",
      "Epoch 1445/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3865 - accuracy: 0.5755 - val_loss: 0.7551 - val_accuracy: 0.3913\n",
      "Epoch 1446/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3883 - accuracy: 0.5753 - val_loss: 0.7448 - val_accuracy: 0.3898\n",
      "Epoch 1447/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3944 - accuracy: 0.5702 - val_loss: 0.7287 - val_accuracy: 0.3890\n",
      "Epoch 1448/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3813 - accuracy: 0.5800 - val_loss: 0.7431 - val_accuracy: 0.3872\n",
      "Epoch 1449/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3815 - accuracy: 0.5796 - val_loss: 0.7401 - val_accuracy: 0.3914\n",
      "Epoch 1450/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3848 - accuracy: 0.5788 - val_loss: 0.7335 - val_accuracy: 0.3869\n",
      "Epoch 1451/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3778 - accuracy: 0.5856 - val_loss: 0.7528 - val_accuracy: 0.3909\n",
      "Epoch 1452/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3911 - accuracy: 0.5711 - val_loss: 0.7368 - val_accuracy: 0.3932\n",
      "Epoch 1453/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3853 - accuracy: 0.5760 - val_loss: 0.7447 - val_accuracy: 0.3883\n",
      "Epoch 1454/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3872 - accuracy: 0.5779 - val_loss: 0.7368 - val_accuracy: 0.3902\n",
      "Epoch 1455/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3875 - accuracy: 0.5749 - val_loss: 0.7404 - val_accuracy: 0.3893\n",
      "Epoch 1456/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3852 - accuracy: 0.5777 - val_loss: 0.7335 - val_accuracy: 0.3852\n",
      "Epoch 1457/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3803 - accuracy: 0.5828 - val_loss: 0.7424 - val_accuracy: 0.3873\n",
      "Epoch 1458/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3847 - accuracy: 0.5786 - val_loss: 0.7605 - val_accuracy: 0.3904\n",
      "Epoch 1459/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3828 - accuracy: 0.5794 - val_loss: 0.7464 - val_accuracy: 0.3919\n",
      "Epoch 1460/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3816 - accuracy: 0.5790 - val_loss: 0.7455 - val_accuracy: 0.3888\n",
      "Epoch 1461/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3802 - accuracy: 0.5837 - val_loss: 0.7421 - val_accuracy: 0.3890\n",
      "Epoch 1462/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3863 - accuracy: 0.5798 - val_loss: 0.7284 - val_accuracy: 0.3895\n",
      "Epoch 1463/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3833 - accuracy: 0.5809 - val_loss: 0.7391 - val_accuracy: 0.3912\n",
      "Epoch 1464/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3829 - accuracy: 0.5792 - val_loss: 0.7419 - val_accuracy: 0.3885\n",
      "Epoch 1465/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3840 - accuracy: 0.5785 - val_loss: 0.7394 - val_accuracy: 0.3886\n",
      "Epoch 1466/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3850 - accuracy: 0.5757 - val_loss: 0.7604 - val_accuracy: 0.3932\n",
      "Epoch 1467/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3918 - accuracy: 0.5690 - val_loss: 0.7335 - val_accuracy: 0.3916\n",
      "Epoch 1468/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3806 - accuracy: 0.5812 - val_loss: 0.7593 - val_accuracy: 0.3920\n",
      "Epoch 1469/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3839 - accuracy: 0.5798 - val_loss: 0.7409 - val_accuracy: 0.3890\n",
      "Epoch 1470/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3849 - accuracy: 0.5748 - val_loss: 0.7408 - val_accuracy: 0.3844\n",
      "Epoch 1471/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3908 - accuracy: 0.5709 - val_loss: 0.7430 - val_accuracy: 0.3876\n",
      "Epoch 1472/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3789 - accuracy: 0.5838 - val_loss: 0.7473 - val_accuracy: 0.3869\n",
      "Epoch 1473/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3834 - accuracy: 0.5800 - val_loss: 0.7481 - val_accuracy: 0.3867\n",
      "Epoch 1474/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3851 - accuracy: 0.5781 - val_loss: 0.7344 - val_accuracy: 0.3863\n",
      "Epoch 1475/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3839 - accuracy: 0.5761 - val_loss: 0.7464 - val_accuracy: 0.3879\n",
      "Epoch 1476/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3813 - accuracy: 0.5836 - val_loss: 0.7491 - val_accuracy: 0.3909\n",
      "Epoch 1477/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3786 - accuracy: 0.5854 - val_loss: 0.7539 - val_accuracy: 0.3883\n",
      "Epoch 1478/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3818 - accuracy: 0.5789 - val_loss: 0.7417 - val_accuracy: 0.3859\n",
      "Epoch 1479/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3850 - accuracy: 0.5810 - val_loss: 0.7439 - val_accuracy: 0.3879\n",
      "Epoch 1480/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3827 - accuracy: 0.5793 - val_loss: 0.7424 - val_accuracy: 0.3889\n",
      "Epoch 1481/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3769 - accuracy: 0.5838 - val_loss: 0.7515 - val_accuracy: 0.3882\n",
      "Epoch 1482/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3805 - accuracy: 0.5782 - val_loss: 0.7519 - val_accuracy: 0.3923\n",
      "Epoch 1483/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3814 - accuracy: 0.5812 - val_loss: 0.7558 - val_accuracy: 0.3910\n",
      "Epoch 1484/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3815 - accuracy: 0.5814 - val_loss: 0.7455 - val_accuracy: 0.3914\n",
      "Epoch 1485/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3851 - accuracy: 0.5762 - val_loss: 0.7424 - val_accuracy: 0.3864\n",
      "Epoch 1486/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3802 - accuracy: 0.5803 - val_loss: 0.7451 - val_accuracy: 0.3941\n",
      "Epoch 1487/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3849 - accuracy: 0.5790 - val_loss: 0.7467 - val_accuracy: 0.3879\n",
      "Epoch 1488/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3831 - accuracy: 0.5800 - val_loss: 0.7501 - val_accuracy: 0.3890\n",
      "Epoch 1489/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3818 - accuracy: 0.5802 - val_loss: 0.7369 - val_accuracy: 0.3909\n",
      "Epoch 1490/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3791 - accuracy: 0.5846 - val_loss: 0.7592 - val_accuracy: 0.3940\n",
      "Epoch 1491/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3800 - accuracy: 0.5854 - val_loss: 0.7356 - val_accuracy: 0.3911\n",
      "Epoch 1492/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3824 - accuracy: 0.5833 - val_loss: 0.7356 - val_accuracy: 0.3872\n",
      "Epoch 1493/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3809 - accuracy: 0.5814 - val_loss: 0.7354 - val_accuracy: 0.3897\n",
      "Epoch 1494/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3741 - accuracy: 0.5865 - val_loss: 0.7474 - val_accuracy: 0.3903\n",
      "Epoch 1495/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3771 - accuracy: 0.5865 - val_loss: 0.7448 - val_accuracy: 0.3920\n",
      "Epoch 1496/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3822 - accuracy: 0.5813 - val_loss: 0.7366 - val_accuracy: 0.3897\n",
      "Epoch 1497/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3801 - accuracy: 0.5782 - val_loss: 0.7567 - val_accuracy: 0.3909\n",
      "Epoch 1498/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3768 - accuracy: 0.5860 - val_loss: 0.7616 - val_accuracy: 0.3937\n",
      "Epoch 1499/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3759 - accuracy: 0.5845 - val_loss: 0.7494 - val_accuracy: 0.3890\n",
      "Epoch 1500/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3796 - accuracy: 0.5803 - val_loss: 0.7414 - val_accuracy: 0.3890\n",
      "Epoch 1501/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3780 - accuracy: 0.5840 - val_loss: 0.7423 - val_accuracy: 0.3903\n",
      "Epoch 1502/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3824 - accuracy: 0.5814 - val_loss: 0.7432 - val_accuracy: 0.3900\n",
      "Epoch 1503/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3788 - accuracy: 0.5867 - val_loss: 0.7517 - val_accuracy: 0.3910\n",
      "Epoch 1504/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3806 - accuracy: 0.5855 - val_loss: 0.7489 - val_accuracy: 0.3915\n",
      "Epoch 1505/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3776 - accuracy: 0.5859 - val_loss: 0.7593 - val_accuracy: 0.3942\n",
      "Epoch 1506/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3786 - accuracy: 0.5825 - val_loss: 0.7669 - val_accuracy: 0.3920\n",
      "Epoch 1507/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3831 - accuracy: 0.5806 - val_loss: 0.7560 - val_accuracy: 0.3911\n",
      "Epoch 1508/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3811 - accuracy: 0.5819 - val_loss: 0.7460 - val_accuracy: 0.3866\n",
      "Epoch 1509/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3743 - accuracy: 0.5877 - val_loss: 0.7537 - val_accuracy: 0.3899\n",
      "Epoch 1510/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3815 - accuracy: 0.5804 - val_loss: 0.7515 - val_accuracy: 0.3860\n",
      "Epoch 1511/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3844 - accuracy: 0.5810 - val_loss: 0.7512 - val_accuracy: 0.3880\n",
      "Epoch 1512/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3812 - accuracy: 0.5808 - val_loss: 0.7533 - val_accuracy: 0.3918\n",
      "Epoch 1513/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3857 - accuracy: 0.5788 - val_loss: 0.7572 - val_accuracy: 0.3883\n",
      "Epoch 1514/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3817 - accuracy: 0.5800 - val_loss: 0.7581 - val_accuracy: 0.3913\n",
      "Epoch 1515/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3759 - accuracy: 0.5848 - val_loss: 0.7417 - val_accuracy: 0.3882\n",
      "Epoch 1516/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3833 - accuracy: 0.5762 - val_loss: 0.7648 - val_accuracy: 0.3880\n",
      "Epoch 1517/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3807 - accuracy: 0.5817 - val_loss: 0.7519 - val_accuracy: 0.3920\n",
      "Epoch 1518/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3758 - accuracy: 0.5856 - val_loss: 0.7508 - val_accuracy: 0.3890\n",
      "Epoch 1519/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3788 - accuracy: 0.5835 - val_loss: 0.7557 - val_accuracy: 0.3916\n",
      "Epoch 1520/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3792 - accuracy: 0.5844 - val_loss: 0.7531 - val_accuracy: 0.3937\n",
      "Epoch 1521/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3777 - accuracy: 0.5848 - val_loss: 0.7563 - val_accuracy: 0.3905\n",
      "Epoch 1522/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3809 - accuracy: 0.5813 - val_loss: 0.7475 - val_accuracy: 0.3883\n",
      "Epoch 1523/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3815 - accuracy: 0.5822 - val_loss: 0.7459 - val_accuracy: 0.3842\n",
      "Epoch 1524/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3803 - accuracy: 0.5827 - val_loss: 0.7425 - val_accuracy: 0.3854\n",
      "Epoch 1525/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3843 - accuracy: 0.5761 - val_loss: 0.7471 - val_accuracy: 0.3923\n",
      "Epoch 1526/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3779 - accuracy: 0.5871 - val_loss: 0.7654 - val_accuracy: 0.3873\n",
      "Epoch 1527/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3765 - accuracy: 0.5856 - val_loss: 0.7558 - val_accuracy: 0.3915\n",
      "Epoch 1528/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3758 - accuracy: 0.5880 - val_loss: 0.7390 - val_accuracy: 0.3904\n",
      "Epoch 1529/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3801 - accuracy: 0.5844 - val_loss: 0.7515 - val_accuracy: 0.3921\n",
      "Epoch 1530/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3818 - accuracy: 0.5791 - val_loss: 0.7471 - val_accuracy: 0.3893\n",
      "Epoch 1531/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3736 - accuracy: 0.5845 - val_loss: 0.7620 - val_accuracy: 0.3878\n",
      "Epoch 1532/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3925 - accuracy: 0.5701 - val_loss: 0.7521 - val_accuracy: 0.3886\n",
      "Epoch 1533/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3843 - accuracy: 0.5802 - val_loss: 0.7507 - val_accuracy: 0.3897\n",
      "Epoch 1534/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3874 - accuracy: 0.5775 - val_loss: 0.7395 - val_accuracy: 0.3872\n",
      "Epoch 1535/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3840 - accuracy: 0.5805 - val_loss: 0.7298 - val_accuracy: 0.3908\n",
      "Epoch 1536/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3787 - accuracy: 0.5825 - val_loss: 0.7463 - val_accuracy: 0.3900\n",
      "Epoch 1537/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3805 - accuracy: 0.5834 - val_loss: 0.7472 - val_accuracy: 0.3912\n",
      "Epoch 1538/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3911 - accuracy: 0.5709 - val_loss: 0.7439 - val_accuracy: 0.3900\n",
      "Epoch 1539/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3817 - accuracy: 0.5827 - val_loss: 0.7419 - val_accuracy: 0.3900\n",
      "Epoch 1540/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4028 - accuracy: 0.5646 - val_loss: 0.7193 - val_accuracy: 0.3845\n",
      "Epoch 1541/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3950 - accuracy: 0.5671 - val_loss: 0.7342 - val_accuracy: 0.3887\n",
      "Epoch 1542/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3813 - accuracy: 0.5801 - val_loss: 0.7463 - val_accuracy: 0.3893\n",
      "Epoch 1543/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3802 - accuracy: 0.5857 - val_loss: 0.7564 - val_accuracy: 0.3898\n",
      "Epoch 1544/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3790 - accuracy: 0.5841 - val_loss: 0.7511 - val_accuracy: 0.3901\n",
      "Epoch 1545/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3801 - accuracy: 0.5823 - val_loss: 0.7236 - val_accuracy: 0.3865\n",
      "Epoch 1546/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3800 - accuracy: 0.5833 - val_loss: 0.7517 - val_accuracy: 0.3904\n",
      "Epoch 1547/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3752 - accuracy: 0.5895 - val_loss: 0.7562 - val_accuracy: 0.3914\n",
      "Epoch 1548/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3806 - accuracy: 0.5825 - val_loss: 0.7362 - val_accuracy: 0.3882\n",
      "Epoch 1549/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3747 - accuracy: 0.5857 - val_loss: 0.7531 - val_accuracy: 0.3897\n",
      "Epoch 1550/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3775 - accuracy: 0.5852 - val_loss: 0.7429 - val_accuracy: 0.3899\n",
      "Epoch 1551/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3765 - accuracy: 0.5863 - val_loss: 0.7419 - val_accuracy: 0.3912\n",
      "Epoch 1552/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3770 - accuracy: 0.5876 - val_loss: 0.7392 - val_accuracy: 0.3900\n",
      "Epoch 1553/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3817 - accuracy: 0.5817 - val_loss: 0.7332 - val_accuracy: 0.3890\n",
      "Epoch 1554/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3849 - accuracy: 0.5796 - val_loss: 0.7471 - val_accuracy: 0.3859\n",
      "Epoch 1555/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3722 - accuracy: 0.5923 - val_loss: 0.7330 - val_accuracy: 0.3845\n",
      "Epoch 1556/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3735 - accuracy: 0.5884 - val_loss: 0.7433 - val_accuracy: 0.3874\n",
      "Epoch 1557/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3759 - accuracy: 0.5866 - val_loss: 0.7453 - val_accuracy: 0.3892\n",
      "Epoch 1558/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3817 - accuracy: 0.5815 - val_loss: 0.7415 - val_accuracy: 0.3846\n",
      "Epoch 1559/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3734 - accuracy: 0.5859 - val_loss: 0.7556 - val_accuracy: 0.3909\n",
      "Epoch 1560/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3747 - accuracy: 0.5886 - val_loss: 0.7462 - val_accuracy: 0.3890\n",
      "Epoch 1561/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3752 - accuracy: 0.5865 - val_loss: 0.7419 - val_accuracy: 0.3859\n",
      "Epoch 1562/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3764 - accuracy: 0.5864 - val_loss: 0.7502 - val_accuracy: 0.3889\n",
      "Epoch 1563/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3755 - accuracy: 0.5880 - val_loss: 0.7542 - val_accuracy: 0.3881\n",
      "Epoch 1564/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3762 - accuracy: 0.5879 - val_loss: 0.7498 - val_accuracy: 0.3915\n",
      "Epoch 1565/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3758 - accuracy: 0.5877 - val_loss: 0.7505 - val_accuracy: 0.3881\n",
      "Epoch 1566/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3742 - accuracy: 0.5891 - val_loss: 0.7382 - val_accuracy: 0.3919\n",
      "Epoch 1567/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3777 - accuracy: 0.5854 - val_loss: 0.7323 - val_accuracy: 0.3883\n",
      "Epoch 1568/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3774 - accuracy: 0.5824 - val_loss: 0.7372 - val_accuracy: 0.3869\n",
      "Epoch 1569/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3817 - accuracy: 0.5786 - val_loss: 0.7481 - val_accuracy: 0.3870\n",
      "Epoch 1570/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3792 - accuracy: 0.5811 - val_loss: 0.7527 - val_accuracy: 0.3867\n",
      "Epoch 1571/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3812 - accuracy: 0.5803 - val_loss: 0.7374 - val_accuracy: 0.3863\n",
      "Epoch 1572/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3832 - accuracy: 0.5771 - val_loss: 0.7396 - val_accuracy: 0.3897\n",
      "Epoch 1573/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3777 - accuracy: 0.5856 - val_loss: 0.7474 - val_accuracy: 0.3866\n",
      "Epoch 1574/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3782 - accuracy: 0.5843 - val_loss: 0.7511 - val_accuracy: 0.3935\n",
      "Epoch 1575/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3794 - accuracy: 0.5856 - val_loss: 0.7518 - val_accuracy: 0.3879\n",
      "Epoch 1576/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3793 - accuracy: 0.5840 - val_loss: 0.7478 - val_accuracy: 0.3858\n",
      "Epoch 1577/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3844 - accuracy: 0.5765 - val_loss: 0.7449 - val_accuracy: 0.3876\n",
      "Epoch 1578/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3793 - accuracy: 0.5791 - val_loss: 0.7481 - val_accuracy: 0.3877\n",
      "Epoch 1579/2500\n",
      "32958/32958 [==============================] - 2s 58us/step - loss: 0.3891 - accuracy: 0.5729 - val_loss: 0.7334 - val_accuracy: 0.3843\n",
      "Epoch 1580/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3829 - accuracy: 0.5799 - val_loss: 0.7498 - val_accuracy: 0.3907\n",
      "Epoch 1581/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.3805 - accuracy: 0.5804 - val_loss: 0.7542 - val_accuracy: 0.3915\n",
      "Epoch 1582/2500\n",
      "32958/32958 [==============================] - 2s 59us/step - loss: 0.3727 - accuracy: 0.5919 - val_loss: 0.7569 - val_accuracy: 0.3926\n",
      "Epoch 1583/2500\n",
      "32958/32958 [==============================] - 2s 60us/step - loss: 0.3780 - accuracy: 0.5829 - val_loss: 0.7399 - val_accuracy: 0.3829\n",
      "Epoch 1584/2500\n",
      "32958/32958 [==============================] - 2s 66us/step - loss: 0.3770 - accuracy: 0.5842 - val_loss: 0.7586 - val_accuracy: 0.3924\n",
      "Epoch 1585/2500\n",
      "32958/32958 [==============================] - 2s 59us/step - loss: 0.3764 - accuracy: 0.5853 - val_loss: 0.7507 - val_accuracy: 0.3924\n",
      "Epoch 1586/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3749 - accuracy: 0.5869 - val_loss: 0.7482 - val_accuracy: 0.3893\n",
      "Epoch 1587/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3741 - accuracy: 0.5857 - val_loss: 0.7471 - val_accuracy: 0.3894\n",
      "Epoch 1588/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3799 - accuracy: 0.5845 - val_loss: 0.7313 - val_accuracy: 0.3868\n",
      "Epoch 1589/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3860 - accuracy: 0.5774 - val_loss: 0.7336 - val_accuracy: 0.3879\n",
      "Epoch 1590/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3786 - accuracy: 0.5828 - val_loss: 0.7446 - val_accuracy: 0.3881\n",
      "Epoch 1591/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3785 - accuracy: 0.5844 - val_loss: 0.7479 - val_accuracy: 0.3889\n",
      "Epoch 1592/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3740 - accuracy: 0.5901 - val_loss: 0.7447 - val_accuracy: 0.3906\n",
      "Epoch 1593/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3744 - accuracy: 0.5886 - val_loss: 0.7470 - val_accuracy: 0.3902\n",
      "Epoch 1594/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3783 - accuracy: 0.5835 - val_loss: 0.7580 - val_accuracy: 0.3931\n",
      "Epoch 1595/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3913 - accuracy: 0.5735 - val_loss: 0.7261 - val_accuracy: 0.3872\n",
      "Epoch 1596/2500\n",
      "32958/32958 [==============================] - 2s 57us/step - loss: 0.3939 - accuracy: 0.5693 - val_loss: 0.7445 - val_accuracy: 0.3905\n",
      "Epoch 1597/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3795 - accuracy: 0.5829 - val_loss: 0.7489 - val_accuracy: 0.3934\n",
      "Epoch 1598/2500\n",
      "32958/32958 [==============================] - 2s 60us/step - loss: 0.3745 - accuracy: 0.5887 - val_loss: 0.7602 - val_accuracy: 0.3884\n",
      "Epoch 1599/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3782 - accuracy: 0.5833 - val_loss: 0.7443 - val_accuracy: 0.3887\n",
      "Epoch 1600/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3790 - accuracy: 0.5841 - val_loss: 0.7414 - val_accuracy: 0.3908\n",
      "Epoch 1601/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3748 - accuracy: 0.5865 - val_loss: 0.7335 - val_accuracy: 0.3920\n",
      "Epoch 1602/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3740 - accuracy: 0.5886 - val_loss: 0.7405 - val_accuracy: 0.3914\n",
      "Epoch 1603/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3745 - accuracy: 0.5887 - val_loss: 0.7459 - val_accuracy: 0.3939\n",
      "Epoch 1604/2500\n",
      "32958/32958 [==============================] - 1s 46us/step - loss: 0.3780 - accuracy: 0.5844 - val_loss: 0.7447 - val_accuracy: 0.3918\n",
      "Epoch 1605/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3821 - accuracy: 0.5815 - val_loss: 0.7376 - val_accuracy: 0.3899\n",
      "Epoch 1606/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3819 - accuracy: 0.5804 - val_loss: 0.7503 - val_accuracy: 0.3923\n",
      "Epoch 1607/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3880 - accuracy: 0.5738 - val_loss: 0.7547 - val_accuracy: 0.3892\n",
      "Epoch 1608/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3880 - accuracy: 0.5774 - val_loss: 0.7331 - val_accuracy: 0.3889\n",
      "Epoch 1609/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3854 - accuracy: 0.5780 - val_loss: 0.7401 - val_accuracy: 0.3864\n",
      "Epoch 1610/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3766 - accuracy: 0.5858 - val_loss: 0.7619 - val_accuracy: 0.3912\n",
      "Epoch 1611/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3749 - accuracy: 0.5891 - val_loss: 0.7500 - val_accuracy: 0.3855\n",
      "Epoch 1612/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3781 - accuracy: 0.5824 - val_loss: 0.7445 - val_accuracy: 0.3876\n",
      "Epoch 1613/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3755 - accuracy: 0.5857 - val_loss: 0.7522 - val_accuracy: 0.3924\n",
      "Epoch 1614/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3924 - accuracy: 0.5700 - val_loss: 0.7295 - val_accuracy: 0.3849\n",
      "Epoch 1615/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3839 - accuracy: 0.5840 - val_loss: 0.7404 - val_accuracy: 0.3874\n",
      "Epoch 1616/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3765 - accuracy: 0.5863 - val_loss: 0.7634 - val_accuracy: 0.3893\n",
      "Epoch 1617/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3722 - accuracy: 0.5902 - val_loss: 0.7648 - val_accuracy: 0.3845\n",
      "Epoch 1618/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3730 - accuracy: 0.5871 - val_loss: 0.7540 - val_accuracy: 0.3875\n",
      "Epoch 1619/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3773 - accuracy: 0.5872 - val_loss: 0.7596 - val_accuracy: 0.3893\n",
      "Epoch 1620/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3744 - accuracy: 0.5874 - val_loss: 0.7551 - val_accuracy: 0.3910\n",
      "Epoch 1621/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3796 - accuracy: 0.5799 - val_loss: 0.7534 - val_accuracy: 0.3932\n",
      "Epoch 1622/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3679 - accuracy: 0.5924 - val_loss: 0.7757 - val_accuracy: 0.3926\n",
      "Epoch 1623/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3758 - accuracy: 0.5847 - val_loss: 0.7539 - val_accuracy: 0.3880\n",
      "Epoch 1624/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3720 - accuracy: 0.5904 - val_loss: 0.7520 - val_accuracy: 0.3900\n",
      "Epoch 1625/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3780 - accuracy: 0.5827 - val_loss: 0.7464 - val_accuracy: 0.3886\n",
      "Epoch 1626/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3745 - accuracy: 0.5840 - val_loss: 0.7626 - val_accuracy: 0.3868\n",
      "Epoch 1627/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3718 - accuracy: 0.5910 - val_loss: 0.7595 - val_accuracy: 0.3923\n",
      "Epoch 1628/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3754 - accuracy: 0.5866 - val_loss: 0.7569 - val_accuracy: 0.3925\n",
      "Epoch 1629/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3805 - accuracy: 0.5804 - val_loss: 0.7488 - val_accuracy: 0.3893\n",
      "Epoch 1630/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3820 - accuracy: 0.5827 - val_loss: 0.7457 - val_accuracy: 0.3917\n",
      "Epoch 1631/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3763 - accuracy: 0.5870 - val_loss: 0.7395 - val_accuracy: 0.3887\n",
      "Epoch 1632/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3782 - accuracy: 0.5851 - val_loss: 0.7375 - val_accuracy: 0.3871\n",
      "Epoch 1633/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3827 - accuracy: 0.5839 - val_loss: 0.7457 - val_accuracy: 0.3883\n",
      "Epoch 1634/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3726 - accuracy: 0.5901 - val_loss: 0.7385 - val_accuracy: 0.3870\n",
      "Epoch 1635/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3705 - accuracy: 0.5917 - val_loss: 0.7661 - val_accuracy: 0.3889\n",
      "Epoch 1636/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3717 - accuracy: 0.5881 - val_loss: 0.7706 - val_accuracy: 0.3948\n",
      "Epoch 1637/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3765 - accuracy: 0.5864 - val_loss: 0.7464 - val_accuracy: 0.3887\n",
      "Epoch 1638/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3773 - accuracy: 0.5867 - val_loss: 0.7674 - val_accuracy: 0.3930\n",
      "Epoch 1639/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3751 - accuracy: 0.5884 - val_loss: 0.7554 - val_accuracy: 0.3926\n",
      "Epoch 1640/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3753 - accuracy: 0.5833 - val_loss: 0.7564 - val_accuracy: 0.3915\n",
      "Epoch 1641/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3695 - accuracy: 0.5928 - val_loss: 0.7523 - val_accuracy: 0.3891\n",
      "Epoch 1642/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3773 - accuracy: 0.5853 - val_loss: 0.7484 - val_accuracy: 0.3877\n",
      "Epoch 1643/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3722 - accuracy: 0.5899 - val_loss: 0.7779 - val_accuracy: 0.3892\n",
      "Epoch 1644/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3746 - accuracy: 0.5838 - val_loss: 0.7639 - val_accuracy: 0.3906\n",
      "Epoch 1645/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3769 - accuracy: 0.5865 - val_loss: 0.7484 - val_accuracy: 0.3920\n",
      "Epoch 1646/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3754 - accuracy: 0.5901 - val_loss: 0.7530 - val_accuracy: 0.3917\n",
      "Epoch 1647/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3715 - accuracy: 0.5902 - val_loss: 0.7541 - val_accuracy: 0.3916\n",
      "Epoch 1648/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3728 - accuracy: 0.5918 - val_loss: 0.7431 - val_accuracy: 0.3883\n",
      "Epoch 1649/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3747 - accuracy: 0.5882 - val_loss: 0.7554 - val_accuracy: 0.3875\n",
      "Epoch 1650/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3760 - accuracy: 0.5867 - val_loss: 0.7437 - val_accuracy: 0.3876\n",
      "Epoch 1651/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3745 - accuracy: 0.5889 - val_loss: 0.7494 - val_accuracy: 0.3867\n",
      "Epoch 1652/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3771 - accuracy: 0.5836 - val_loss: 0.7381 - val_accuracy: 0.3900\n",
      "Epoch 1653/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3748 - accuracy: 0.5886 - val_loss: 0.7397 - val_accuracy: 0.3870\n",
      "Epoch 1654/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3684 - accuracy: 0.5933 - val_loss: 0.7528 - val_accuracy: 0.3885\n",
      "Epoch 1655/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3741 - accuracy: 0.5890 - val_loss: 0.7445 - val_accuracy: 0.3869\n",
      "Epoch 1656/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3726 - accuracy: 0.5926 - val_loss: 0.7749 - val_accuracy: 0.3937\n",
      "Epoch 1657/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3763 - accuracy: 0.5871 - val_loss: 0.7536 - val_accuracy: 0.3920\n",
      "Epoch 1658/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3776 - accuracy: 0.5882 - val_loss: 0.7651 - val_accuracy: 0.3943\n",
      "Epoch 1659/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3715 - accuracy: 0.5897 - val_loss: 0.7568 - val_accuracy: 0.3906\n",
      "Epoch 1660/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3779 - accuracy: 0.5833 - val_loss: 0.7418 - val_accuracy: 0.3888\n",
      "Epoch 1661/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3723 - accuracy: 0.5880 - val_loss: 0.7621 - val_accuracy: 0.3924\n",
      "Epoch 1662/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3687 - accuracy: 0.5923 - val_loss: 0.7624 - val_accuracy: 0.3890\n",
      "Epoch 1663/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3773 - accuracy: 0.5854 - val_loss: 0.7625 - val_accuracy: 0.3928\n",
      "Epoch 1664/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3732 - accuracy: 0.5927 - val_loss: 0.7435 - val_accuracy: 0.3889\n",
      "Epoch 1665/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3749 - accuracy: 0.5892 - val_loss: 0.7477 - val_accuracy: 0.3865\n",
      "Epoch 1666/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3733 - accuracy: 0.5922 - val_loss: 0.7472 - val_accuracy: 0.3924\n",
      "Epoch 1667/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3735 - accuracy: 0.5936 - val_loss: 0.7432 - val_accuracy: 0.3849\n",
      "Epoch 1668/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3752 - accuracy: 0.5860 - val_loss: 0.7523 - val_accuracy: 0.3902\n",
      "Epoch 1669/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3779 - accuracy: 0.5869 - val_loss: 0.7598 - val_accuracy: 0.3838\n",
      "Epoch 1670/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3778 - accuracy: 0.5865 - val_loss: 0.7397 - val_accuracy: 0.3882\n",
      "Epoch 1671/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3737 - accuracy: 0.5875 - val_loss: 0.7552 - val_accuracy: 0.3857\n",
      "Epoch 1672/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3759 - accuracy: 0.5879 - val_loss: 0.7541 - val_accuracy: 0.3901\n",
      "Epoch 1673/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3822 - accuracy: 0.5838 - val_loss: 0.7518 - val_accuracy: 0.3884\n",
      "Epoch 1674/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3750 - accuracy: 0.5848 - val_loss: 0.7609 - val_accuracy: 0.3915\n",
      "Epoch 1675/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3761 - accuracy: 0.5879 - val_loss: 0.7525 - val_accuracy: 0.3910\n",
      "Epoch 1676/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3694 - accuracy: 0.5935 - val_loss: 0.7538 - val_accuracy: 0.3913\n",
      "Epoch 1677/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3740 - accuracy: 0.5862 - val_loss: 0.7463 - val_accuracy: 0.3881\n",
      "Epoch 1678/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3721 - accuracy: 0.5884 - val_loss: 0.7600 - val_accuracy: 0.3909\n",
      "Epoch 1679/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3745 - accuracy: 0.5897 - val_loss: 0.7480 - val_accuracy: 0.3905\n",
      "Epoch 1680/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3703 - accuracy: 0.5936 - val_loss: 0.7482 - val_accuracy: 0.3923\n",
      "Epoch 1681/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3692 - accuracy: 0.5932 - val_loss: 0.7592 - val_accuracy: 0.3906\n",
      "Epoch 1682/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3723 - accuracy: 0.5906 - val_loss: 0.7523 - val_accuracy: 0.3897\n",
      "Epoch 1683/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3726 - accuracy: 0.5885 - val_loss: 0.7612 - val_accuracy: 0.3936\n",
      "Epoch 1684/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3831 - accuracy: 0.5794 - val_loss: 0.7406 - val_accuracy: 0.3865\n",
      "Epoch 1685/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3771 - accuracy: 0.5837 - val_loss: 0.7543 - val_accuracy: 0.3912\n",
      "Epoch 1686/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3764 - accuracy: 0.5865 - val_loss: 0.7449 - val_accuracy: 0.3900\n",
      "Epoch 1687/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3766 - accuracy: 0.5863 - val_loss: 0.7488 - val_accuracy: 0.3913\n",
      "Epoch 1688/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3779 - accuracy: 0.5892 - val_loss: 0.7413 - val_accuracy: 0.3883\n",
      "Epoch 1689/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3759 - accuracy: 0.5910 - val_loss: 0.7469 - val_accuracy: 0.3873\n",
      "Epoch 1690/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3790 - accuracy: 0.5830 - val_loss: 0.7568 - val_accuracy: 0.3920\n",
      "Epoch 1691/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3734 - accuracy: 0.5884 - val_loss: 0.7554 - val_accuracy: 0.3918\n",
      "Epoch 1692/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3759 - accuracy: 0.5867 - val_loss: 0.7578 - val_accuracy: 0.3920\n",
      "Epoch 1693/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3732 - accuracy: 0.5896 - val_loss: 0.7430 - val_accuracy: 0.3900\n",
      "Epoch 1694/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3704 - accuracy: 0.5923 - val_loss: 0.7470 - val_accuracy: 0.3892\n",
      "Epoch 1695/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3731 - accuracy: 0.5899 - val_loss: 0.7447 - val_accuracy: 0.3894\n",
      "Epoch 1696/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3728 - accuracy: 0.5908 - val_loss: 0.7421 - val_accuracy: 0.3872\n",
      "Epoch 1697/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3733 - accuracy: 0.5893 - val_loss: 0.7387 - val_accuracy: 0.3893\n",
      "Epoch 1698/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3695 - accuracy: 0.5928 - val_loss: 0.7588 - val_accuracy: 0.3923\n",
      "Epoch 1699/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3679 - accuracy: 0.5922 - val_loss: 0.7619 - val_accuracy: 0.3881\n",
      "Epoch 1700/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3748 - accuracy: 0.5921 - val_loss: 0.7434 - val_accuracy: 0.3921\n",
      "Epoch 1701/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3722 - accuracy: 0.5943 - val_loss: 0.7554 - val_accuracy: 0.3884\n",
      "Epoch 1702/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3740 - accuracy: 0.5917 - val_loss: 0.7542 - val_accuracy: 0.3901\n",
      "Epoch 1703/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3782 - accuracy: 0.5820 - val_loss: 0.7429 - val_accuracy: 0.3919\n",
      "Epoch 1704/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3763 - accuracy: 0.5869 - val_loss: 0.7419 - val_accuracy: 0.3930\n",
      "Epoch 1705/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3744 - accuracy: 0.5910 - val_loss: 0.7568 - val_accuracy: 0.3924\n",
      "Epoch 1706/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3720 - accuracy: 0.5951 - val_loss: 0.7560 - val_accuracy: 0.3924\n",
      "Epoch 1707/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3757 - accuracy: 0.5870 - val_loss: 0.7395 - val_accuracy: 0.3864\n",
      "Epoch 1708/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3742 - accuracy: 0.5866 - val_loss: 0.7578 - val_accuracy: 0.3874\n",
      "Epoch 1709/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3729 - accuracy: 0.5923 - val_loss: 0.7411 - val_accuracy: 0.3883\n",
      "Epoch 1710/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3747 - accuracy: 0.5902 - val_loss: 0.7470 - val_accuracy: 0.3888\n",
      "Epoch 1711/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3816 - accuracy: 0.5795 - val_loss: 0.7486 - val_accuracy: 0.3914\n",
      "Epoch 1712/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3804 - accuracy: 0.5863 - val_loss: 0.7537 - val_accuracy: 0.3900\n",
      "Epoch 1713/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3785 - accuracy: 0.5849 - val_loss: 0.7377 - val_accuracy: 0.3860\n",
      "Epoch 1714/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3678 - accuracy: 0.5941 - val_loss: 0.7498 - val_accuracy: 0.3900\n",
      "Epoch 1715/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3725 - accuracy: 0.5869 - val_loss: 0.7646 - val_accuracy: 0.3927\n",
      "Epoch 1716/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3728 - accuracy: 0.5886 - val_loss: 0.7502 - val_accuracy: 0.3942\n",
      "Epoch 1717/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3733 - accuracy: 0.5886 - val_loss: 0.7601 - val_accuracy: 0.3889\n",
      "Epoch 1718/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3724 - accuracy: 0.5922 - val_loss: 0.7561 - val_accuracy: 0.3889\n",
      "Epoch 1719/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3768 - accuracy: 0.5842 - val_loss: 0.7457 - val_accuracy: 0.3890\n",
      "Epoch 1720/2500\n",
      "32958/32958 [==============================] - 1s 46us/step - loss: 0.3811 - accuracy: 0.5871 - val_loss: 0.7455 - val_accuracy: 0.3900\n",
      "Epoch 1721/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3801 - accuracy: 0.5867 - val_loss: 0.7233 - val_accuracy: 0.3883\n",
      "Epoch 1722/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3771 - accuracy: 0.5878 - val_loss: 0.7408 - val_accuracy: 0.3916\n",
      "Epoch 1723/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3723 - accuracy: 0.5871 - val_loss: 0.7440 - val_accuracy: 0.3905\n",
      "Epoch 1724/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3734 - accuracy: 0.5915 - val_loss: 0.7511 - val_accuracy: 0.3863\n",
      "Epoch 1725/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3765 - accuracy: 0.5840 - val_loss: 0.7470 - val_accuracy: 0.3849\n",
      "Epoch 1726/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3748 - accuracy: 0.5892 - val_loss: 0.7504 - val_accuracy: 0.3929\n",
      "Epoch 1727/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3721 - accuracy: 0.5905 - val_loss: 0.7523 - val_accuracy: 0.3914\n",
      "Epoch 1728/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3740 - accuracy: 0.5880 - val_loss: 0.7481 - val_accuracy: 0.3953\n",
      "Epoch 1729/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3711 - accuracy: 0.5892 - val_loss: 0.7536 - val_accuracy: 0.3930\n",
      "Epoch 1730/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3812 - accuracy: 0.5825 - val_loss: 0.7270 - val_accuracy: 0.3845\n",
      "Epoch 1731/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3776 - accuracy: 0.5807 - val_loss: 0.7433 - val_accuracy: 0.3882\n",
      "Epoch 1732/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3812 - accuracy: 0.5788 - val_loss: 0.7462 - val_accuracy: 0.3907\n",
      "Epoch 1733/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3807 - accuracy: 0.5812 - val_loss: 0.7454 - val_accuracy: 0.3833\n",
      "Epoch 1734/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3752 - accuracy: 0.5861 - val_loss: 0.7391 - val_accuracy: 0.3860\n",
      "Epoch 1735/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3961 - accuracy: 0.5704 - val_loss: 0.7099 - val_accuracy: 0.3796\n",
      "Epoch 1736/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3857 - accuracy: 0.5719 - val_loss: 0.7463 - val_accuracy: 0.3841\n",
      "Epoch 1737/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3873 - accuracy: 0.5766 - val_loss: 0.7395 - val_accuracy: 0.3841\n",
      "Epoch 1738/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3745 - accuracy: 0.5892 - val_loss: 0.7363 - val_accuracy: 0.3879\n",
      "Epoch 1739/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3782 - accuracy: 0.5849 - val_loss: 0.7511 - val_accuracy: 0.3865\n",
      "Epoch 1740/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3699 - accuracy: 0.5929 - val_loss: 0.7604 - val_accuracy: 0.3892\n",
      "Epoch 1741/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3709 - accuracy: 0.5918 - val_loss: 0.7581 - val_accuracy: 0.3889\n",
      "Epoch 1742/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3720 - accuracy: 0.5887 - val_loss: 0.7345 - val_accuracy: 0.3905\n",
      "Epoch 1743/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3771 - accuracy: 0.5843 - val_loss: 0.7379 - val_accuracy: 0.3858\n",
      "Epoch 1744/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3730 - accuracy: 0.5872 - val_loss: 0.7368 - val_accuracy: 0.3908\n",
      "Epoch 1745/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3703 - accuracy: 0.5908 - val_loss: 0.7561 - val_accuracy: 0.3906\n",
      "Epoch 1746/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3686 - accuracy: 0.5948 - val_loss: 0.7557 - val_accuracy: 0.3912\n",
      "Epoch 1747/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3749 - accuracy: 0.5924 - val_loss: 0.7601 - val_accuracy: 0.3893\n",
      "Epoch 1748/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3752 - accuracy: 0.5930 - val_loss: 0.7608 - val_accuracy: 0.3948\n",
      "Epoch 1749/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3770 - accuracy: 0.5898 - val_loss: 0.7580 - val_accuracy: 0.3935\n",
      "Epoch 1750/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3728 - accuracy: 0.5903 - val_loss: 0.7417 - val_accuracy: 0.3910\n",
      "Epoch 1751/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3652 - accuracy: 0.5966 - val_loss: 0.7535 - val_accuracy: 0.3900\n",
      "Epoch 1752/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3667 - accuracy: 0.5957 - val_loss: 0.7465 - val_accuracy: 0.3934\n",
      "Epoch 1753/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3660 - accuracy: 0.5966 - val_loss: 0.7532 - val_accuracy: 0.3915\n",
      "Epoch 1754/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3667 - accuracy: 0.5989 - val_loss: 0.7437 - val_accuracy: 0.3918\n",
      "Epoch 1755/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3698 - accuracy: 0.5931 - val_loss: 0.7511 - val_accuracy: 0.3888\n",
      "Epoch 1756/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3729 - accuracy: 0.5909 - val_loss: 0.7599 - val_accuracy: 0.3882\n",
      "Epoch 1757/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3773 - accuracy: 0.5874 - val_loss: 0.7385 - val_accuracy: 0.3849\n",
      "Epoch 1758/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3764 - accuracy: 0.5868 - val_loss: 0.7319 - val_accuracy: 0.3854\n",
      "Epoch 1759/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3715 - accuracy: 0.5871 - val_loss: 0.7462 - val_accuracy: 0.3841\n",
      "Epoch 1760/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3750 - accuracy: 0.5869 - val_loss: 0.7388 - val_accuracy: 0.3910\n",
      "Epoch 1761/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3774 - accuracy: 0.5847 - val_loss: 0.7509 - val_accuracy: 0.3906\n",
      "Epoch 1762/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3774 - accuracy: 0.5824 - val_loss: 0.7330 - val_accuracy: 0.3864\n",
      "Epoch 1763/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3724 - accuracy: 0.5877 - val_loss: 0.7477 - val_accuracy: 0.3956\n",
      "Epoch 1764/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3735 - accuracy: 0.5897 - val_loss: 0.7401 - val_accuracy: 0.3863\n",
      "Epoch 1765/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3698 - accuracy: 0.5901 - val_loss: 0.7404 - val_accuracy: 0.3861\n",
      "Epoch 1766/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3701 - accuracy: 0.5911 - val_loss: 0.7336 - val_accuracy: 0.3847\n",
      "Epoch 1767/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3720 - accuracy: 0.5879 - val_loss: 0.7512 - val_accuracy: 0.3861\n",
      "Epoch 1768/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3722 - accuracy: 0.5909 - val_loss: 0.7427 - val_accuracy: 0.3869\n",
      "Epoch 1769/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3710 - accuracy: 0.5921 - val_loss: 0.7430 - val_accuracy: 0.3895\n",
      "Epoch 1770/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3717 - accuracy: 0.5915 - val_loss: 0.7415 - val_accuracy: 0.3877\n",
      "Epoch 1771/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3708 - accuracy: 0.5913 - val_loss: 0.7435 - val_accuracy: 0.3875\n",
      "Epoch 1772/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3710 - accuracy: 0.5911 - val_loss: 0.7649 - val_accuracy: 0.3939\n",
      "Epoch 1773/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3715 - accuracy: 0.5935 - val_loss: 0.7405 - val_accuracy: 0.3873\n",
      "Epoch 1774/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3720 - accuracy: 0.5891 - val_loss: 0.7463 - val_accuracy: 0.3912\n",
      "Epoch 1775/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3711 - accuracy: 0.5929 - val_loss: 0.7504 - val_accuracy: 0.3953\n",
      "Epoch 1776/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3742 - accuracy: 0.5934 - val_loss: 0.7552 - val_accuracy: 0.3915\n",
      "Epoch 1777/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3795 - accuracy: 0.5863 - val_loss: 0.7311 - val_accuracy: 0.3909\n",
      "Epoch 1778/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3742 - accuracy: 0.5889 - val_loss: 0.7382 - val_accuracy: 0.3879\n",
      "Epoch 1779/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3711 - accuracy: 0.5943 - val_loss: 0.7300 - val_accuracy: 0.3880\n",
      "Epoch 1780/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3714 - accuracy: 0.5938 - val_loss: 0.7409 - val_accuracy: 0.3886\n",
      "Epoch 1781/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3697 - accuracy: 0.5941 - val_loss: 0.7602 - val_accuracy: 0.3887\n",
      "Epoch 1782/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3709 - accuracy: 0.5934 - val_loss: 0.7524 - val_accuracy: 0.3902\n",
      "Epoch 1783/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3722 - accuracy: 0.5934 - val_loss: 0.7542 - val_accuracy: 0.3896\n",
      "Epoch 1784/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3675 - accuracy: 0.5950 - val_loss: 0.7454 - val_accuracy: 0.3894\n",
      "Epoch 1785/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3765 - accuracy: 0.5875 - val_loss: 0.7425 - val_accuracy: 0.3855\n",
      "Epoch 1786/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3728 - accuracy: 0.5899 - val_loss: 0.7549 - val_accuracy: 0.3900\n",
      "Epoch 1787/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3723 - accuracy: 0.5886 - val_loss: 0.7415 - val_accuracy: 0.3898\n",
      "Epoch 1788/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3911 - accuracy: 0.5895 - val_loss: 0.7311 - val_accuracy: 0.3768\n",
      "Epoch 1789/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3874 - accuracy: 0.5777 - val_loss: 0.7379 - val_accuracy: 0.3849\n",
      "Epoch 1790/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3769 - accuracy: 0.5871 - val_loss: 0.7421 - val_accuracy: 0.3872\n",
      "Epoch 1791/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3769 - accuracy: 0.5882 - val_loss: 0.7403 - val_accuracy: 0.3846\n",
      "Epoch 1792/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3850 - accuracy: 0.5793 - val_loss: 0.7310 - val_accuracy: 0.3842\n",
      "Epoch 1793/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3837 - accuracy: 0.5780 - val_loss: 0.7406 - val_accuracy: 0.3882\n",
      "Epoch 1794/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3750 - accuracy: 0.5858 - val_loss: 0.7413 - val_accuracy: 0.3890\n",
      "Epoch 1795/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3692 - accuracy: 0.5951 - val_loss: 0.7476 - val_accuracy: 0.3891\n",
      "Epoch 1796/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3772 - accuracy: 0.5869 - val_loss: 0.7486 - val_accuracy: 0.3916\n",
      "Epoch 1797/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3676 - accuracy: 0.5969 - val_loss: 0.7651 - val_accuracy: 0.3954\n",
      "Epoch 1798/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3709 - accuracy: 0.5938 - val_loss: 0.7490 - val_accuracy: 0.3866\n",
      "Epoch 1799/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3705 - accuracy: 0.5886 - val_loss: 0.7430 - val_accuracy: 0.3884\n",
      "Epoch 1800/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3704 - accuracy: 0.5911 - val_loss: 0.7341 - val_accuracy: 0.3871\n",
      "Epoch 1801/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3701 - accuracy: 0.5908 - val_loss: 0.7378 - val_accuracy: 0.3863\n",
      "Epoch 1802/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3742 - accuracy: 0.5870 - val_loss: 0.7316 - val_accuracy: 0.3896\n",
      "Epoch 1803/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3718 - accuracy: 0.5874 - val_loss: 0.7555 - val_accuracy: 0.3903\n",
      "Epoch 1804/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3677 - accuracy: 0.5943 - val_loss: 0.7441 - val_accuracy: 0.3864\n",
      "Epoch 1805/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3706 - accuracy: 0.5927 - val_loss: 0.7536 - val_accuracy: 0.3869\n",
      "Epoch 1806/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3777 - accuracy: 0.5830 - val_loss: 0.7432 - val_accuracy: 0.3903\n",
      "Epoch 1807/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3740 - accuracy: 0.5901 - val_loss: 0.7469 - val_accuracy: 0.3900\n",
      "Epoch 1808/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3723 - accuracy: 0.5890 - val_loss: 0.7504 - val_accuracy: 0.3847\n",
      "Epoch 1809/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3712 - accuracy: 0.5922 - val_loss: 0.7542 - val_accuracy: 0.3912\n",
      "Epoch 1810/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3778 - accuracy: 0.5878 - val_loss: 0.7629 - val_accuracy: 0.3866\n",
      "Epoch 1811/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3706 - accuracy: 0.5931 - val_loss: 0.7460 - val_accuracy: 0.3892\n",
      "Epoch 1812/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3706 - accuracy: 0.5931 - val_loss: 0.7467 - val_accuracy: 0.3883\n",
      "Epoch 1813/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3677 - accuracy: 0.5951 - val_loss: 0.7511 - val_accuracy: 0.3886\n",
      "Epoch 1814/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3680 - accuracy: 0.5939 - val_loss: 0.7371 - val_accuracy: 0.3886\n",
      "Epoch 1815/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3709 - accuracy: 0.5922 - val_loss: 0.7654 - val_accuracy: 0.3897\n",
      "Epoch 1816/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3734 - accuracy: 0.5907 - val_loss: 0.7466 - val_accuracy: 0.3887\n",
      "Epoch 1817/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3768 - accuracy: 0.5857 - val_loss: 0.7423 - val_accuracy: 0.3849\n",
      "Epoch 1818/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3751 - accuracy: 0.5879 - val_loss: 0.7487 - val_accuracy: 0.3871\n",
      "Epoch 1819/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3744 - accuracy: 0.5890 - val_loss: 0.7452 - val_accuracy: 0.3910\n",
      "Epoch 1820/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3712 - accuracy: 0.5931 - val_loss: 0.7653 - val_accuracy: 0.3869\n",
      "Epoch 1821/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3688 - accuracy: 0.5969 - val_loss: 0.7555 - val_accuracy: 0.3910\n",
      "Epoch 1822/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3734 - accuracy: 0.5896 - val_loss: 0.7388 - val_accuracy: 0.3869\n",
      "Epoch 1823/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3730 - accuracy: 0.5921 - val_loss: 0.7443 - val_accuracy: 0.3821\n",
      "Epoch 1824/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3733 - accuracy: 0.5962 - val_loss: 0.7510 - val_accuracy: 0.3927\n",
      "Epoch 1825/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3670 - accuracy: 0.5962 - val_loss: 0.7529 - val_accuracy: 0.3939\n",
      "Epoch 1826/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3731 - accuracy: 0.5892 - val_loss: 0.7443 - val_accuracy: 0.3884\n",
      "Epoch 1827/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3668 - accuracy: 0.5943 - val_loss: 0.7493 - val_accuracy: 0.3916\n",
      "Epoch 1828/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3699 - accuracy: 0.5962 - val_loss: 0.7571 - val_accuracy: 0.3906\n",
      "Epoch 1829/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3772 - accuracy: 0.5865 - val_loss: 0.7471 - val_accuracy: 0.3858\n",
      "Epoch 1830/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3662 - accuracy: 0.5988 - val_loss: 0.7574 - val_accuracy: 0.3906\n",
      "Epoch 1831/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3682 - accuracy: 0.5940 - val_loss: 0.7519 - val_accuracy: 0.3911\n",
      "Epoch 1832/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3686 - accuracy: 0.5941 - val_loss: 0.7485 - val_accuracy: 0.3956\n",
      "Epoch 1833/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3720 - accuracy: 0.5898 - val_loss: 0.7392 - val_accuracy: 0.3900\n",
      "Epoch 1834/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3776 - accuracy: 0.5815 - val_loss: 0.7426 - val_accuracy: 0.3862\n",
      "Epoch 1835/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3755 - accuracy: 0.5846 - val_loss: 0.7455 - val_accuracy: 0.3900\n",
      "Epoch 1836/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3703 - accuracy: 0.5926 - val_loss: 0.7358 - val_accuracy: 0.3878\n",
      "Epoch 1837/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3704 - accuracy: 0.5911 - val_loss: 0.7519 - val_accuracy: 0.3903\n",
      "Epoch 1838/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3733 - accuracy: 0.5940 - val_loss: 0.7436 - val_accuracy: 0.3951\n",
      "Epoch 1839/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3789 - accuracy: 0.5839 - val_loss: 0.7449 - val_accuracy: 0.3855\n",
      "Epoch 1840/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3748 - accuracy: 0.5886 - val_loss: 0.7503 - val_accuracy: 0.3827\n",
      "Epoch 1841/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3745 - accuracy: 0.5919 - val_loss: 0.7467 - val_accuracy: 0.3871\n",
      "Epoch 1842/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3795 - accuracy: 0.5864 - val_loss: 0.7170 - val_accuracy: 0.3881\n",
      "Epoch 1843/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3801 - accuracy: 0.5823 - val_loss: 0.7469 - val_accuracy: 0.3843\n",
      "Epoch 1844/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3756 - accuracy: 0.5885 - val_loss: 0.7320 - val_accuracy: 0.3869\n",
      "Epoch 1845/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3751 - accuracy: 0.5865 - val_loss: 0.7366 - val_accuracy: 0.3912\n",
      "Epoch 1846/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3734 - accuracy: 0.5881 - val_loss: 0.7530 - val_accuracy: 0.3938\n",
      "Epoch 1847/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3683 - accuracy: 0.5960 - val_loss: 0.7279 - val_accuracy: 0.3871\n",
      "Epoch 1848/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3757 - accuracy: 0.5854 - val_loss: 0.7547 - val_accuracy: 0.3900\n",
      "Epoch 1849/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3735 - accuracy: 0.5895 - val_loss: 0.7371 - val_accuracy: 0.3852\n",
      "Epoch 1850/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3750 - accuracy: 0.5877 - val_loss: 0.7418 - val_accuracy: 0.3863\n",
      "Epoch 1851/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3733 - accuracy: 0.5889 - val_loss: 0.7481 - val_accuracy: 0.3898\n",
      "Epoch 1852/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3687 - accuracy: 0.5932 - val_loss: 0.7422 - val_accuracy: 0.3830\n",
      "Epoch 1853/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3690 - accuracy: 0.5936 - val_loss: 0.7434 - val_accuracy: 0.3911\n",
      "Epoch 1854/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3644 - accuracy: 0.5964 - val_loss: 0.7553 - val_accuracy: 0.3890\n",
      "Epoch 1855/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3734 - accuracy: 0.5920 - val_loss: 0.7470 - val_accuracy: 0.3865\n",
      "Epoch 1856/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3675 - accuracy: 0.5940 - val_loss: 0.7656 - val_accuracy: 0.3912\n",
      "Epoch 1857/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3769 - accuracy: 0.5898 - val_loss: 0.7516 - val_accuracy: 0.3915\n",
      "Epoch 1858/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3644 - accuracy: 0.6003 - val_loss: 0.7516 - val_accuracy: 0.3920\n",
      "Epoch 1859/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3654 - accuracy: 0.5958 - val_loss: 0.7585 - val_accuracy: 0.3933\n",
      "Epoch 1860/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3865 - accuracy: 0.5780 - val_loss: 0.7509 - val_accuracy: 0.3893\n",
      "Epoch 1861/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3745 - accuracy: 0.5868 - val_loss: 0.7379 - val_accuracy: 0.3871\n",
      "Epoch 1862/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3736 - accuracy: 0.5880 - val_loss: 0.7314 - val_accuracy: 0.3878\n",
      "Epoch 1863/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3667 - accuracy: 0.5981 - val_loss: 0.7455 - val_accuracy: 0.3829\n",
      "Epoch 1864/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3716 - accuracy: 0.5916 - val_loss: 0.7429 - val_accuracy: 0.3890\n",
      "Epoch 1865/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3728 - accuracy: 0.5902 - val_loss: 0.7427 - val_accuracy: 0.3872\n",
      "Epoch 1866/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3777 - accuracy: 0.5830 - val_loss: 0.7443 - val_accuracy: 0.3896\n",
      "Epoch 1867/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3724 - accuracy: 0.5916 - val_loss: 0.7502 - val_accuracy: 0.3883\n",
      "Epoch 1868/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3706 - accuracy: 0.5952 - val_loss: 0.7609 - val_accuracy: 0.3928\n",
      "Epoch 1869/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3677 - accuracy: 0.6003 - val_loss: 0.7347 - val_accuracy: 0.3874\n",
      "Epoch 1870/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3682 - accuracy: 0.5972 - val_loss: 0.7526 - val_accuracy: 0.3900\n",
      "Epoch 1871/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3621 - accuracy: 0.6036 - val_loss: 0.7547 - val_accuracy: 0.3889\n",
      "Epoch 1872/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3668 - accuracy: 0.5951 - val_loss: 0.7600 - val_accuracy: 0.3910\n",
      "Epoch 1873/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3661 - accuracy: 0.5962 - val_loss: 0.7457 - val_accuracy: 0.3895\n",
      "Epoch 1874/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3681 - accuracy: 0.5904 - val_loss: 0.7405 - val_accuracy: 0.3859\n",
      "Epoch 1875/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3742 - accuracy: 0.5888 - val_loss: 0.7380 - val_accuracy: 0.3889\n",
      "Epoch 1876/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3677 - accuracy: 0.5967 - val_loss: 0.7508 - val_accuracy: 0.3889\n",
      "Epoch 1877/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3701 - accuracy: 0.5954 - val_loss: 0.7349 - val_accuracy: 0.3849\n",
      "Epoch 1878/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3750 - accuracy: 0.5897 - val_loss: 0.7581 - val_accuracy: 0.3912\n",
      "Epoch 1879/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3694 - accuracy: 0.5914 - val_loss: 0.7343 - val_accuracy: 0.3851\n",
      "Epoch 1880/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3674 - accuracy: 0.5945 - val_loss: 0.7532 - val_accuracy: 0.3922\n",
      "Epoch 1881/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3656 - accuracy: 0.5954 - val_loss: 0.7430 - val_accuracy: 0.3895\n",
      "Epoch 1882/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3704 - accuracy: 0.5917 - val_loss: 0.7322 - val_accuracy: 0.3836\n",
      "Epoch 1883/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3689 - accuracy: 0.5935 - val_loss: 0.7521 - val_accuracy: 0.3909\n",
      "Epoch 1884/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3762 - accuracy: 0.5908 - val_loss: 0.7532 - val_accuracy: 0.3909\n",
      "Epoch 1885/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3663 - accuracy: 0.5963 - val_loss: 0.7469 - val_accuracy: 0.3866\n",
      "Epoch 1886/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3673 - accuracy: 0.5982 - val_loss: 0.7479 - val_accuracy: 0.3933\n",
      "Epoch 1887/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3688 - accuracy: 0.5962 - val_loss: 0.7530 - val_accuracy: 0.3900\n",
      "Epoch 1888/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3688 - accuracy: 0.5946 - val_loss: 0.7526 - val_accuracy: 0.3895\n",
      "Epoch 1889/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3681 - accuracy: 0.5975 - val_loss: 0.7496 - val_accuracy: 0.3931\n",
      "Epoch 1890/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3719 - accuracy: 0.5921 - val_loss: 0.7446 - val_accuracy: 0.3901\n",
      "Epoch 1891/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3681 - accuracy: 0.5955 - val_loss: 0.7553 - val_accuracy: 0.3930\n",
      "Epoch 1892/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3717 - accuracy: 0.5894 - val_loss: 0.7697 - val_accuracy: 0.3906\n",
      "Epoch 1893/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3662 - accuracy: 0.5959 - val_loss: 0.7493 - val_accuracy: 0.3889\n",
      "Epoch 1894/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3670 - accuracy: 0.6002 - val_loss: 0.7507 - val_accuracy: 0.3902\n",
      "Epoch 1895/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3614 - accuracy: 0.6019 - val_loss: 0.7626 - val_accuracy: 0.3909\n",
      "Epoch 1896/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3663 - accuracy: 0.5957 - val_loss: 0.7600 - val_accuracy: 0.3884\n",
      "Epoch 1897/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3615 - accuracy: 0.6046 - val_loss: 0.7517 - val_accuracy: 0.3833\n",
      "Epoch 1898/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3632 - accuracy: 0.6011 - val_loss: 0.7486 - val_accuracy: 0.3836\n",
      "Epoch 1899/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3689 - accuracy: 0.5943 - val_loss: 0.7503 - val_accuracy: 0.3869\n",
      "Epoch 1900/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3670 - accuracy: 0.5978 - val_loss: 0.7394 - val_accuracy: 0.3877\n",
      "Epoch 1901/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3725 - accuracy: 0.5919 - val_loss: 0.7471 - val_accuracy: 0.3926\n",
      "Epoch 1902/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3674 - accuracy: 0.5957 - val_loss: 0.7484 - val_accuracy: 0.3895\n",
      "Epoch 1903/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3724 - accuracy: 0.5898 - val_loss: 0.7447 - val_accuracy: 0.3892\n",
      "Epoch 1904/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3670 - accuracy: 0.5962 - val_loss: 0.7370 - val_accuracy: 0.3871\n",
      "Epoch 1905/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3678 - accuracy: 0.5955 - val_loss: 0.7505 - val_accuracy: 0.3910\n",
      "Epoch 1906/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3678 - accuracy: 0.5948 - val_loss: 0.7566 - val_accuracy: 0.3906\n",
      "Epoch 1907/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3652 - accuracy: 0.5993 - val_loss: 0.7515 - val_accuracy: 0.3876\n",
      "Epoch 1908/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3693 - accuracy: 0.5940 - val_loss: 0.7591 - val_accuracy: 0.3897\n",
      "Epoch 1909/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3695 - accuracy: 0.5953 - val_loss: 0.7461 - val_accuracy: 0.3845\n",
      "Epoch 1910/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3702 - accuracy: 0.5938 - val_loss: 0.7453 - val_accuracy: 0.3848\n",
      "Epoch 1911/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3700 - accuracy: 0.5945 - val_loss: 0.7583 - val_accuracy: 0.3906\n",
      "Epoch 1912/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3683 - accuracy: 0.5971 - val_loss: 0.7420 - val_accuracy: 0.3896\n",
      "Epoch 1913/2500\n",
      "32958/32958 [==============================] - 2s 57us/step - loss: 0.3656 - accuracy: 0.5962 - val_loss: 0.7507 - val_accuracy: 0.3899\n",
      "Epoch 1914/2500\n",
      "32958/32958 [==============================] - 2s 60us/step - loss: 0.3683 - accuracy: 0.5949 - val_loss: 0.7536 - val_accuracy: 0.3915\n",
      "Epoch 1915/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3679 - accuracy: 0.5965 - val_loss: 0.7515 - val_accuracy: 0.3924\n",
      "Epoch 1916/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3658 - accuracy: 0.5999 - val_loss: 0.7479 - val_accuracy: 0.3876\n",
      "Epoch 1917/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3707 - accuracy: 0.5923 - val_loss: 0.7457 - val_accuracy: 0.3878\n",
      "Epoch 1918/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3716 - accuracy: 0.5914 - val_loss: 0.7537 - val_accuracy: 0.3884\n",
      "Epoch 1919/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.3632 - accuracy: 0.5967 - val_loss: 0.7549 - val_accuracy: 0.3865\n",
      "Epoch 1920/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3668 - accuracy: 0.5963 - val_loss: 0.7617 - val_accuracy: 0.3908\n",
      "Epoch 1921/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3651 - accuracy: 0.5997 - val_loss: 0.7438 - val_accuracy: 0.3839\n",
      "Epoch 1922/2500\n",
      "32958/32958 [==============================] - 2s 57us/step - loss: 0.3686 - accuracy: 0.5968 - val_loss: 0.7494 - val_accuracy: 0.3885\n",
      "Epoch 1923/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3650 - accuracy: 0.5994 - val_loss: 0.7453 - val_accuracy: 0.3900\n",
      "Epoch 1924/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3607 - accuracy: 0.6013 - val_loss: 0.7577 - val_accuracy: 0.3871\n",
      "Epoch 1925/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3662 - accuracy: 0.5984 - val_loss: 0.7468 - val_accuracy: 0.3888\n",
      "Epoch 1926/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3695 - accuracy: 0.5936 - val_loss: 0.7506 - val_accuracy: 0.3904\n",
      "Epoch 1927/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3678 - accuracy: 0.5972 - val_loss: 0.7501 - val_accuracy: 0.3899\n",
      "Epoch 1928/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3643 - accuracy: 0.5971 - val_loss: 0.7597 - val_accuracy: 0.3904\n",
      "Epoch 1929/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3693 - accuracy: 0.5984 - val_loss: 0.7694 - val_accuracy: 0.3920\n",
      "Epoch 1930/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3706 - accuracy: 0.5940 - val_loss: 0.7580 - val_accuracy: 0.3881\n",
      "Epoch 1931/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3711 - accuracy: 0.5945 - val_loss: 0.7450 - val_accuracy: 0.3857\n",
      "Epoch 1932/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3714 - accuracy: 0.5913 - val_loss: 0.7617 - val_accuracy: 0.3910\n",
      "Epoch 1933/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3682 - accuracy: 0.5970 - val_loss: 0.7512 - val_accuracy: 0.3896\n",
      "Epoch 1934/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3675 - accuracy: 0.5991 - val_loss: 0.7524 - val_accuracy: 0.3908\n",
      "Epoch 1935/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3631 - accuracy: 0.5988 - val_loss: 0.7685 - val_accuracy: 0.3906\n",
      "Epoch 1936/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3635 - accuracy: 0.5979 - val_loss: 0.7551 - val_accuracy: 0.3885\n",
      "Epoch 1937/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3650 - accuracy: 0.5968 - val_loss: 0.7582 - val_accuracy: 0.3882\n",
      "Epoch 1938/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3654 - accuracy: 0.5984 - val_loss: 0.7590 - val_accuracy: 0.3881\n",
      "Epoch 1939/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3660 - accuracy: 0.5971 - val_loss: 0.7589 - val_accuracy: 0.3917\n",
      "Epoch 1940/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3688 - accuracy: 0.5970 - val_loss: 0.7461 - val_accuracy: 0.3896\n",
      "Epoch 1941/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3638 - accuracy: 0.6016 - val_loss: 0.7547 - val_accuracy: 0.3879\n",
      "Epoch 1942/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3709 - accuracy: 0.5938 - val_loss: 0.7623 - val_accuracy: 0.3911\n",
      "Epoch 1943/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3656 - accuracy: 0.5998 - val_loss: 0.7438 - val_accuracy: 0.3889\n",
      "Epoch 1944/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3638 - accuracy: 0.5948 - val_loss: 0.7542 - val_accuracy: 0.3879\n",
      "Epoch 1945/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3691 - accuracy: 0.5941 - val_loss: 0.7566 - val_accuracy: 0.3899\n",
      "Epoch 1946/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3700 - accuracy: 0.5953 - val_loss: 0.7570 - val_accuracy: 0.3919\n",
      "Epoch 1947/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3676 - accuracy: 0.5973 - val_loss: 0.7445 - val_accuracy: 0.3883\n",
      "Epoch 1948/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3682 - accuracy: 0.5965 - val_loss: 0.7578 - val_accuracy: 0.3921\n",
      "Epoch 1949/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3650 - accuracy: 0.5984 - val_loss: 0.7564 - val_accuracy: 0.3893\n",
      "Epoch 1950/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3667 - accuracy: 0.5984 - val_loss: 0.7497 - val_accuracy: 0.3914\n",
      "Epoch 1951/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3661 - accuracy: 0.5980 - val_loss: 0.7610 - val_accuracy: 0.3940\n",
      "Epoch 1952/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3666 - accuracy: 0.5972 - val_loss: 0.7598 - val_accuracy: 0.3913\n",
      "Epoch 1953/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3659 - accuracy: 0.5976 - val_loss: 0.7623 - val_accuracy: 0.3925\n",
      "Epoch 1954/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3644 - accuracy: 0.6019 - val_loss: 0.7529 - val_accuracy: 0.3957\n",
      "Epoch 1955/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3744 - accuracy: 0.5910 - val_loss: 0.7357 - val_accuracy: 0.3908\n",
      "Epoch 1956/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3731 - accuracy: 0.5918 - val_loss: 0.7624 - val_accuracy: 0.3915\n",
      "Epoch 1957/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3992 - accuracy: 0.5827 - val_loss: 0.7640 - val_accuracy: 0.3876\n",
      "Epoch 1958/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3715 - accuracy: 0.5927 - val_loss: 0.7477 - val_accuracy: 0.3881\n",
      "Epoch 1959/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3727 - accuracy: 0.5925 - val_loss: 0.7592 - val_accuracy: 0.3891\n",
      "Epoch 1960/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3718 - accuracy: 0.5885 - val_loss: 0.7559 - val_accuracy: 0.3899\n",
      "Epoch 1961/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3734 - accuracy: 0.5906 - val_loss: 0.7499 - val_accuracy: 0.3901\n",
      "Epoch 1962/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3677 - accuracy: 0.5993 - val_loss: 0.7610 - val_accuracy: 0.3889\n",
      "Epoch 1963/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3667 - accuracy: 0.5942 - val_loss: 0.7453 - val_accuracy: 0.3924\n",
      "Epoch 1964/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3678 - accuracy: 0.5941 - val_loss: 0.7576 - val_accuracy: 0.3910\n",
      "Epoch 1965/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3712 - accuracy: 0.5916 - val_loss: 0.7562 - val_accuracy: 0.3879\n",
      "Epoch 1966/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3695 - accuracy: 0.5939 - val_loss: 0.7510 - val_accuracy: 0.3907\n",
      "Epoch 1967/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3667 - accuracy: 0.5970 - val_loss: 0.7555 - val_accuracy: 0.3875\n",
      "Epoch 1968/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3712 - accuracy: 0.5913 - val_loss: 0.7452 - val_accuracy: 0.3887\n",
      "Epoch 1969/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3628 - accuracy: 0.6026 - val_loss: 0.7437 - val_accuracy: 0.3870\n",
      "Epoch 1970/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3657 - accuracy: 0.5970 - val_loss: 0.7438 - val_accuracy: 0.3871\n",
      "Epoch 1971/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3666 - accuracy: 0.5953 - val_loss: 0.7571 - val_accuracy: 0.3915\n",
      "Epoch 1972/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3631 - accuracy: 0.6031 - val_loss: 0.7438 - val_accuracy: 0.3908\n",
      "Epoch 1973/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3698 - accuracy: 0.5912 - val_loss: 0.7595 - val_accuracy: 0.3918\n",
      "Epoch 1974/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3662 - accuracy: 0.5976 - val_loss: 0.7608 - val_accuracy: 0.3909\n",
      "Epoch 1975/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3660 - accuracy: 0.5964 - val_loss: 0.7376 - val_accuracy: 0.3890\n",
      "Epoch 1976/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3669 - accuracy: 0.5964 - val_loss: 0.7565 - val_accuracy: 0.3924\n",
      "Epoch 1977/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3633 - accuracy: 0.5985 - val_loss: 0.7579 - val_accuracy: 0.3911\n",
      "Epoch 1978/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3743 - accuracy: 0.5870 - val_loss: 0.7444 - val_accuracy: 0.3909\n",
      "Epoch 1979/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3675 - accuracy: 0.5963 - val_loss: 0.7527 - val_accuracy: 0.3891\n",
      "Epoch 1980/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3619 - accuracy: 0.6007 - val_loss: 0.7571 - val_accuracy: 0.3929\n",
      "Epoch 1981/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3696 - accuracy: 0.5953 - val_loss: 0.7602 - val_accuracy: 0.3902\n",
      "Epoch 1982/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3651 - accuracy: 0.5965 - val_loss: 0.7376 - val_accuracy: 0.3918\n",
      "Epoch 1983/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3631 - accuracy: 0.5999 - val_loss: 0.7655 - val_accuracy: 0.3883\n",
      "Epoch 1984/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3643 - accuracy: 0.6027 - val_loss: 0.7627 - val_accuracy: 0.3914\n",
      "Epoch 1985/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3741 - accuracy: 0.5903 - val_loss: 0.7601 - val_accuracy: 0.3903\n",
      "Epoch 1986/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3712 - accuracy: 0.5918 - val_loss: 0.7569 - val_accuracy: 0.3886\n",
      "Epoch 1987/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3685 - accuracy: 0.5983 - val_loss: 0.7618 - val_accuracy: 0.3868\n",
      "Epoch 1988/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3729 - accuracy: 0.5915 - val_loss: 0.7444 - val_accuracy: 0.3839\n",
      "Epoch 1989/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3645 - accuracy: 0.5984 - val_loss: 0.7617 - val_accuracy: 0.3907\n",
      "Epoch 1990/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3724 - accuracy: 0.5930 - val_loss: 0.7672 - val_accuracy: 0.3880\n",
      "Epoch 1991/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3826 - accuracy: 0.5851 - val_loss: 0.7486 - val_accuracy: 0.3915\n",
      "Epoch 1992/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3750 - accuracy: 0.5909 - val_loss: 0.7700 - val_accuracy: 0.3920\n",
      "Epoch 1993/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3719 - accuracy: 0.5922 - val_loss: 0.7598 - val_accuracy: 0.3924\n",
      "Epoch 1994/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3656 - accuracy: 0.6005 - val_loss: 0.7418 - val_accuracy: 0.3868\n",
      "Epoch 1995/2500\n",
      "32958/32958 [==============================] - 2s 59us/step - loss: 0.3641 - accuracy: 0.6019 - val_loss: 0.7568 - val_accuracy: 0.3920\n",
      "Epoch 1996/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3635 - accuracy: 0.6019 - val_loss: 0.7535 - val_accuracy: 0.3871\n",
      "Epoch 1997/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3709 - accuracy: 0.5949 - val_loss: 0.7566 - val_accuracy: 0.3897\n",
      "Epoch 1998/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3665 - accuracy: 0.5962 - val_loss: 0.7524 - val_accuracy: 0.3918\n",
      "Epoch 1999/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3608 - accuracy: 0.6043 - val_loss: 0.7596 - val_accuracy: 0.3939\n",
      "Epoch 2000/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3670 - accuracy: 0.5998 - val_loss: 0.7496 - val_accuracy: 0.3929\n",
      "Epoch 2001/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3668 - accuracy: 0.5957 - val_loss: 0.7499 - val_accuracy: 0.3930\n",
      "Epoch 2002/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3705 - accuracy: 0.5939 - val_loss: 0.7470 - val_accuracy: 0.3886\n",
      "Epoch 2003/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3662 - accuracy: 0.5959 - val_loss: 0.7487 - val_accuracy: 0.3885\n",
      "Epoch 2004/2500\n",
      "32958/32958 [==============================] - 2s 57us/step - loss: 0.3685 - accuracy: 0.5955 - val_loss: 0.7384 - val_accuracy: 0.3892\n",
      "Epoch 2005/2500\n",
      "32958/32958 [==============================] - 2s 59us/step - loss: 0.3707 - accuracy: 0.5937 - val_loss: 0.7331 - val_accuracy: 0.3893\n",
      "Epoch 2006/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3745 - accuracy: 0.5891 - val_loss: 0.7555 - val_accuracy: 0.3867\n",
      "Epoch 2007/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3650 - accuracy: 0.5986 - val_loss: 0.7533 - val_accuracy: 0.3910\n",
      "Epoch 2008/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3666 - accuracy: 0.5947 - val_loss: 0.7563 - val_accuracy: 0.3884\n",
      "Epoch 2009/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3661 - accuracy: 0.5889 - val_loss: 0.7667 - val_accuracy: 0.3925\n",
      "Epoch 2010/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3658 - accuracy: 0.5955 - val_loss: 0.7522 - val_accuracy: 0.3876\n",
      "Epoch 2011/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3685 - accuracy: 0.5948 - val_loss: 0.7510 - val_accuracy: 0.3909\n",
      "Epoch 2012/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3764 - accuracy: 0.5843 - val_loss: 0.7702 - val_accuracy: 0.3885\n",
      "Epoch 2013/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3725 - accuracy: 0.5914 - val_loss: 0.7484 - val_accuracy: 0.3890\n",
      "Epoch 2014/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3716 - accuracy: 0.5910 - val_loss: 0.7634 - val_accuracy: 0.3911\n",
      "Epoch 2015/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3722 - accuracy: 0.5942 - val_loss: 0.7554 - val_accuracy: 0.3894\n",
      "Epoch 2016/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3791 - accuracy: 0.5885 - val_loss: 0.7364 - val_accuracy: 0.3903\n",
      "Epoch 2017/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3863 - accuracy: 0.5785 - val_loss: 0.7326 - val_accuracy: 0.3847\n",
      "Epoch 2018/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3796 - accuracy: 0.5852 - val_loss: 0.7536 - val_accuracy: 0.3901\n",
      "Epoch 2019/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.9498 - accuracy: 0.5909 - val_loss: 0.7743 - val_accuracy: 0.3887\n",
      "Epoch 2020/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.4643 - accuracy: 0.5272 - val_loss: 0.7232 - val_accuracy: 0.3859\n",
      "Epoch 2021/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.4247 - accuracy: 0.5500 - val_loss: 0.7350 - val_accuracy: 0.3872\n",
      "Epoch 2022/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.4071 - accuracy: 0.5691 - val_loss: 0.7517 - val_accuracy: 0.3849\n",
      "Epoch 2023/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3999 - accuracy: 0.5695 - val_loss: 0.7412 - val_accuracy: 0.3887\n",
      "Epoch 2024/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3946 - accuracy: 0.5754 - val_loss: 0.7453 - val_accuracy: 0.3884\n",
      "Epoch 2025/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3833 - accuracy: 0.5831 - val_loss: 0.7429 - val_accuracy: 0.3913\n",
      "Epoch 2026/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3871 - accuracy: 0.5803 - val_loss: 0.7511 - val_accuracy: 0.3889\n",
      "Epoch 2027/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3792 - accuracy: 0.5867 - val_loss: 0.7663 - val_accuracy: 0.3941\n",
      "Epoch 2028/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3748 - accuracy: 0.5915 - val_loss: 0.7641 - val_accuracy: 0.3911\n",
      "Epoch 2029/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3776 - accuracy: 0.5886 - val_loss: 0.7560 - val_accuracy: 0.3889\n",
      "Epoch 2030/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3720 - accuracy: 0.5958 - val_loss: 0.7631 - val_accuracy: 0.3938\n",
      "Epoch 2031/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3975 - accuracy: 0.5824 - val_loss: 0.7467 - val_accuracy: 0.3881\n",
      "Epoch 2032/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3924 - accuracy: 0.5764 - val_loss: 0.7463 - val_accuracy: 0.3865\n",
      "Epoch 2033/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3787 - accuracy: 0.5876 - val_loss: 0.7435 - val_accuracy: 0.3898\n",
      "Epoch 2034/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3715 - accuracy: 0.5950 - val_loss: 0.7312 - val_accuracy: 0.3851\n",
      "Epoch 2035/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3815 - accuracy: 0.5855 - val_loss: 0.7466 - val_accuracy: 0.3879\n",
      "Epoch 2036/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3734 - accuracy: 0.5934 - val_loss: 0.7488 - val_accuracy: 0.3898\n",
      "Epoch 2037/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3672 - accuracy: 0.5971 - val_loss: 0.7603 - val_accuracy: 0.3932\n",
      "Epoch 2038/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3645 - accuracy: 0.6023 - val_loss: 0.7564 - val_accuracy: 0.3912\n",
      "Epoch 2039/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3696 - accuracy: 0.5959 - val_loss: 0.7602 - val_accuracy: 0.3878\n",
      "Epoch 2040/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3672 - accuracy: 0.5985 - val_loss: 0.7659 - val_accuracy: 0.3941\n",
      "Epoch 2041/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3650 - accuracy: 0.6018 - val_loss: 0.7566 - val_accuracy: 0.3906\n",
      "Epoch 2042/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3799 - accuracy: 0.5871 - val_loss: 0.7546 - val_accuracy: 0.3923\n",
      "Epoch 2043/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3774 - accuracy: 0.5908 - val_loss: 0.7378 - val_accuracy: 0.3882\n",
      "Epoch 2044/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3671 - accuracy: 0.5932 - val_loss: 0.7640 - val_accuracy: 0.3943\n",
      "Epoch 2045/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3583 - accuracy: 0.6068 - val_loss: 0.7604 - val_accuracy: 0.3886\n",
      "Epoch 2046/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3618 - accuracy: 0.6040 - val_loss: 0.7632 - val_accuracy: 0.3901\n",
      "Epoch 2047/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3603 - accuracy: 0.6043 - val_loss: 0.7546 - val_accuracy: 0.3928\n",
      "Epoch 2048/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3616 - accuracy: 0.6014 - val_loss: 0.7590 - val_accuracy: 0.3922\n",
      "Epoch 2049/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3610 - accuracy: 0.6003 - val_loss: 0.7597 - val_accuracy: 0.3931\n",
      "Epoch 2050/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3634 - accuracy: 0.6013 - val_loss: 0.7672 - val_accuracy: 0.3897\n",
      "Epoch 2051/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3672 - accuracy: 0.5987 - val_loss: 0.7653 - val_accuracy: 0.3951\n",
      "Epoch 2052/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3732 - accuracy: 0.5904 - val_loss: 0.7426 - val_accuracy: 0.3893\n",
      "Epoch 2053/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3654 - accuracy: 0.5974 - val_loss: 0.7587 - val_accuracy: 0.3934\n",
      "Epoch 2054/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3694 - accuracy: 0.5957 - val_loss: 0.7565 - val_accuracy: 0.3930\n",
      "Epoch 2055/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3683 - accuracy: 0.5979 - val_loss: 0.7612 - val_accuracy: 0.3884\n",
      "Epoch 2056/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3909 - accuracy: 0.5820 - val_loss: 0.7381 - val_accuracy: 0.3899\n",
      "Epoch 2057/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3767 - accuracy: 0.5851 - val_loss: 0.7600 - val_accuracy: 0.3975\n",
      "Epoch 2058/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3674 - accuracy: 0.5967 - val_loss: 0.7573 - val_accuracy: 0.3918\n",
      "Epoch 2059/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3679 - accuracy: 0.5931 - val_loss: 0.7573 - val_accuracy: 0.3913\n",
      "Epoch 2060/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3652 - accuracy: 0.5985 - val_loss: 0.7662 - val_accuracy: 0.3897\n",
      "Epoch 2061/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3704 - accuracy: 0.5941 - val_loss: 0.7728 - val_accuracy: 0.3938\n",
      "Epoch 2062/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3714 - accuracy: 0.5972 - val_loss: 0.7573 - val_accuracy: 0.3889\n",
      "Epoch 2063/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3719 - accuracy: 0.5904 - val_loss: 0.7686 - val_accuracy: 0.3900\n",
      "Epoch 2064/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3655 - accuracy: 0.6009 - val_loss: 0.7507 - val_accuracy: 0.3969\n",
      "Epoch 2065/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3696 - accuracy: 0.5947 - val_loss: 0.7596 - val_accuracy: 0.3935\n",
      "Epoch 2066/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3663 - accuracy: 0.5983 - val_loss: 0.7428 - val_accuracy: 0.3887\n",
      "Epoch 2067/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3615 - accuracy: 0.6004 - val_loss: 0.7524 - val_accuracy: 0.3915\n",
      "Epoch 2068/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3644 - accuracy: 0.5990 - val_loss: 0.7597 - val_accuracy: 0.3928\n",
      "Epoch 2069/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3652 - accuracy: 0.5978 - val_loss: 0.7707 - val_accuracy: 0.3947\n",
      "Epoch 2070/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3730 - accuracy: 0.5914 - val_loss: 0.7580 - val_accuracy: 0.3934\n",
      "Epoch 2071/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3663 - accuracy: 0.5961 - val_loss: 0.7331 - val_accuracy: 0.3898\n",
      "Epoch 2072/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3608 - accuracy: 0.6009 - val_loss: 0.7540 - val_accuracy: 0.3898\n",
      "Epoch 2073/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3698 - accuracy: 0.5926 - val_loss: 0.7668 - val_accuracy: 0.3913\n",
      "Epoch 2074/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3692 - accuracy: 0.5931 - val_loss: 0.7499 - val_accuracy: 0.3944\n",
      "Epoch 2075/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3671 - accuracy: 0.5948 - val_loss: 0.7417 - val_accuracy: 0.3886\n",
      "Epoch 2076/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3692 - accuracy: 0.5926 - val_loss: 0.7595 - val_accuracy: 0.3897\n",
      "Epoch 2077/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3680 - accuracy: 0.5949 - val_loss: 0.7512 - val_accuracy: 0.3869\n",
      "Epoch 2078/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3653 - accuracy: 0.5962 - val_loss: 0.7643 - val_accuracy: 0.3916\n",
      "Epoch 2079/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3759 - accuracy: 0.5906 - val_loss: 0.7435 - val_accuracy: 0.3893\n",
      "Epoch 2080/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3715 - accuracy: 0.5915 - val_loss: 0.7455 - val_accuracy: 0.3859\n",
      "Epoch 2081/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3840 - accuracy: 0.5788 - val_loss: 0.7357 - val_accuracy: 0.3870\n",
      "Epoch 2082/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3701 - accuracy: 0.5938 - val_loss: 0.7460 - val_accuracy: 0.3905\n",
      "Epoch 2083/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3691 - accuracy: 0.5954 - val_loss: 0.7576 - val_accuracy: 0.3912\n",
      "Epoch 2084/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3665 - accuracy: 0.5983 - val_loss: 0.7610 - val_accuracy: 0.3933\n",
      "Epoch 2085/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3741 - accuracy: 0.5927 - val_loss: 0.7393 - val_accuracy: 0.3882\n",
      "Epoch 2086/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3761 - accuracy: 0.5874 - val_loss: 0.7538 - val_accuracy: 0.3940\n",
      "Epoch 2087/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3657 - accuracy: 0.5986 - val_loss: 0.7652 - val_accuracy: 0.3915\n",
      "Epoch 2088/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3628 - accuracy: 0.6005 - val_loss: 0.7588 - val_accuracy: 0.3902\n",
      "Epoch 2089/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.3616 - accuracy: 0.5995 - val_loss: 0.7617 - val_accuracy: 0.3958\n",
      "Epoch 2090/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3652 - accuracy: 0.6002 - val_loss: 0.7601 - val_accuracy: 0.3929\n",
      "Epoch 2091/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3643 - accuracy: 0.5954 - val_loss: 0.7674 - val_accuracy: 0.3941\n",
      "Epoch 2092/2500\n",
      "32958/32958 [==============================] - 2s 60us/step - loss: 0.3657 - accuracy: 0.5969 - val_loss: 0.7566 - val_accuracy: 0.3913\n",
      "Epoch 2093/2500\n",
      "32958/32958 [==============================] - 2s 66us/step - loss: 0.3675 - accuracy: 0.5994 - val_loss: 0.7565 - val_accuracy: 0.3890\n",
      "Epoch 2094/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3732 - accuracy: 0.5902 - val_loss: 0.7403 - val_accuracy: 0.3877\n",
      "Epoch 2095/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3677 - accuracy: 0.5926 - val_loss: 0.7601 - val_accuracy: 0.3906\n",
      "Epoch 2096/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3631 - accuracy: 0.5993 - val_loss: 0.7578 - val_accuracy: 0.3945\n",
      "Epoch 2097/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3686 - accuracy: 0.5947 - val_loss: 0.7400 - val_accuracy: 0.3929\n",
      "Epoch 2098/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3756 - accuracy: 0.5874 - val_loss: 0.7475 - val_accuracy: 0.3890\n",
      "Epoch 2099/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3780 - accuracy: 0.5858 - val_loss: 0.7302 - val_accuracy: 0.3900\n",
      "Epoch 2100/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3869 - accuracy: 0.5763 - val_loss: 0.7661 - val_accuracy: 0.3926\n",
      "Epoch 2101/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3846 - accuracy: 0.5807 - val_loss: 0.7258 - val_accuracy: 0.3870\n",
      "Epoch 2102/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3827 - accuracy: 0.5805 - val_loss: 0.7465 - val_accuracy: 0.3891\n",
      "Epoch 2103/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3787 - accuracy: 0.5872 - val_loss: 0.7456 - val_accuracy: 0.3916\n",
      "Epoch 2104/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.4019 - accuracy: 0.5622 - val_loss: 0.7376 - val_accuracy: 0.3839\n",
      "Epoch 2105/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3833 - accuracy: 0.5790 - val_loss: 0.7509 - val_accuracy: 0.3920\n",
      "Epoch 2106/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3757 - accuracy: 0.5850 - val_loss: 0.7525 - val_accuracy: 0.3900\n",
      "Epoch 2107/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3698 - accuracy: 0.5928 - val_loss: 0.7511 - val_accuracy: 0.3911\n",
      "Epoch 2108/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3751 - accuracy: 0.5914 - val_loss: 0.7430 - val_accuracy: 0.3887\n",
      "Epoch 2109/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3713 - accuracy: 0.5918 - val_loss: 0.7470 - val_accuracy: 0.3903\n",
      "Epoch 2110/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3784 - accuracy: 0.5876 - val_loss: 0.7210 - val_accuracy: 0.3955\n",
      "Epoch 2111/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3859 - accuracy: 0.5812 - val_loss: 0.7510 - val_accuracy: 0.3925\n",
      "Epoch 2112/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3767 - accuracy: 0.5883 - val_loss: 0.7493 - val_accuracy: 0.3898\n",
      "Epoch 2113/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3713 - accuracy: 0.5916 - val_loss: 0.7515 - val_accuracy: 0.3960\n",
      "Epoch 2114/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3685 - accuracy: 0.5931 - val_loss: 0.7575 - val_accuracy: 0.3915\n",
      "Epoch 2115/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3749 - accuracy: 0.5914 - val_loss: 0.7374 - val_accuracy: 0.3905\n",
      "Epoch 2116/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3778 - accuracy: 0.5871 - val_loss: 0.7475 - val_accuracy: 0.3912\n",
      "Epoch 2117/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3748 - accuracy: 0.5896 - val_loss: 0.7395 - val_accuracy: 0.3884\n",
      "Epoch 2118/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3714 - accuracy: 0.5921 - val_loss: 0.7525 - val_accuracy: 0.3926\n",
      "Epoch 2119/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3665 - accuracy: 0.6014 - val_loss: 0.7455 - val_accuracy: 0.3908\n",
      "Epoch 2120/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3688 - accuracy: 0.5917 - val_loss: 0.7506 - val_accuracy: 0.3906\n",
      "Epoch 2121/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3684 - accuracy: 0.5949 - val_loss: 0.7479 - val_accuracy: 0.3886\n",
      "Epoch 2122/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3650 - accuracy: 0.5987 - val_loss: 0.7329 - val_accuracy: 0.3907\n",
      "Epoch 2123/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3681 - accuracy: 0.5926 - val_loss: 0.7612 - val_accuracy: 0.3917\n",
      "Epoch 2124/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3706 - accuracy: 0.5955 - val_loss: 0.7607 - val_accuracy: 0.3906\n",
      "Epoch 2125/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3680 - accuracy: 0.5980 - val_loss: 0.7541 - val_accuracy: 0.3935\n",
      "Epoch 2126/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3780 - accuracy: 0.5877 - val_loss: 0.7513 - val_accuracy: 0.3909\n",
      "Epoch 2127/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3696 - accuracy: 0.5960 - val_loss: 0.7545 - val_accuracy: 0.3901\n",
      "Epoch 2128/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3692 - accuracy: 0.5966 - val_loss: 0.7484 - val_accuracy: 0.3937\n",
      "Epoch 2129/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3691 - accuracy: 0.6031 - val_loss: 0.7506 - val_accuracy: 0.3917\n",
      "Epoch 2130/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3713 - accuracy: 0.5939 - val_loss: 0.7479 - val_accuracy: 0.3895\n",
      "Epoch 2131/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.4055 - accuracy: 0.5651 - val_loss: 0.7364 - val_accuracy: 0.3917\n",
      "Epoch 2132/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3744 - accuracy: 0.5926 - val_loss: 0.7533 - val_accuracy: 0.3849\n",
      "Epoch 2133/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3704 - accuracy: 0.5948 - val_loss: 0.7722 - val_accuracy: 0.3945\n",
      "Epoch 2134/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3714 - accuracy: 0.5959 - val_loss: 0.7421 - val_accuracy: 0.3917\n",
      "Epoch 2135/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3707 - accuracy: 0.5907 - val_loss: 0.7577 - val_accuracy: 0.3873\n",
      "Epoch 2136/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3760 - accuracy: 0.5853 - val_loss: 0.7477 - val_accuracy: 0.3870\n",
      "Epoch 2137/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3685 - accuracy: 0.5904 - val_loss: 0.7532 - val_accuracy: 0.3918\n",
      "Epoch 2138/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3692 - accuracy: 0.5972 - val_loss: 0.7614 - val_accuracy: 0.3941\n",
      "Epoch 2139/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3744 - accuracy: 0.5934 - val_loss: 0.7468 - val_accuracy: 0.3940\n",
      "Epoch 2140/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3725 - accuracy: 0.5927 - val_loss: 0.7387 - val_accuracy: 0.3940\n",
      "Epoch 2141/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3698 - accuracy: 0.5957 - val_loss: 0.7449 - val_accuracy: 0.3882\n",
      "Epoch 2142/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3588 - accuracy: 0.6045 - val_loss: 0.7609 - val_accuracy: 0.3939\n",
      "Epoch 2143/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3676 - accuracy: 0.5968 - val_loss: 0.7628 - val_accuracy: 0.3904\n",
      "Epoch 2144/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3645 - accuracy: 0.6038 - val_loss: 0.7496 - val_accuracy: 0.3934\n",
      "Epoch 2145/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3620 - accuracy: 0.6019 - val_loss: 0.7687 - val_accuracy: 0.3941\n",
      "Epoch 2146/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3633 - accuracy: 0.6004 - val_loss: 0.7519 - val_accuracy: 0.3878\n",
      "Epoch 2147/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3693 - accuracy: 0.5941 - val_loss: 0.7485 - val_accuracy: 0.3879\n",
      "Epoch 2148/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3678 - accuracy: 0.5961 - val_loss: 0.7628 - val_accuracy: 0.3928\n",
      "Epoch 2149/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3625 - accuracy: 0.6009 - val_loss: 0.7753 - val_accuracy: 0.3941\n",
      "Epoch 2150/2500\n",
      "32958/32958 [==============================] - 2s 57us/step - loss: 0.3680 - accuracy: 0.5978 - val_loss: 0.7706 - val_accuracy: 0.3903\n",
      "Epoch 2151/2500\n",
      "32958/32958 [==============================] - 2s 57us/step - loss: 0.3654 - accuracy: 0.5996 - val_loss: 0.7614 - val_accuracy: 0.3902\n",
      "Epoch 2152/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.3639 - accuracy: 0.5997 - val_loss: 0.7491 - val_accuracy: 0.3927\n",
      "Epoch 2153/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3701 - accuracy: 0.5948 - val_loss: 0.7413 - val_accuracy: 0.3903\n",
      "Epoch 2154/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3660 - accuracy: 0.5980 - val_loss: 0.7764 - val_accuracy: 0.3949\n",
      "Epoch 2155/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3675 - accuracy: 0.5977 - val_loss: 0.7541 - val_accuracy: 0.3954\n",
      "Epoch 2156/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3586 - accuracy: 0.6056 - val_loss: 0.7598 - val_accuracy: 0.3963\n",
      "Epoch 2157/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3848 - accuracy: 0.5835 - val_loss: 0.7528 - val_accuracy: 0.3873\n",
      "Epoch 2158/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3764 - accuracy: 0.5868 - val_loss: 0.7573 - val_accuracy: 0.3884\n",
      "Epoch 2159/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3657 - accuracy: 0.5967 - val_loss: 0.7661 - val_accuracy: 0.3879\n",
      "Epoch 2160/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3609 - accuracy: 0.6019 - val_loss: 0.7662 - val_accuracy: 0.3937\n",
      "Epoch 2161/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3626 - accuracy: 0.5990 - val_loss: 0.7597 - val_accuracy: 0.3880\n",
      "Epoch 2162/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3734 - accuracy: 0.5922 - val_loss: 0.7537 - val_accuracy: 0.3916\n",
      "Epoch 2163/2500\n",
      "32958/32958 [==============================] - ETA: 0s - loss: 0.3640 - accuracy: 0.60 - 1s 45us/step - loss: 0.3641 - accuracy: 0.6013 - val_loss: 0.7724 - val_accuracy: 0.3959\n",
      "Epoch 2164/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3603 - accuracy: 0.6017 - val_loss: 0.7667 - val_accuracy: 0.3862\n",
      "Epoch 2165/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3678 - accuracy: 0.5975 - val_loss: 0.7630 - val_accuracy: 0.3873\n",
      "Epoch 2166/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3642 - accuracy: 0.5996 - val_loss: 0.7680 - val_accuracy: 0.3895\n",
      "Epoch 2167/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3610 - accuracy: 0.6036 - val_loss: 0.7566 - val_accuracy: 0.3914\n",
      "Epoch 2168/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3585 - accuracy: 0.6060 - val_loss: 0.7556 - val_accuracy: 0.3913\n",
      "Epoch 2169/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3599 - accuracy: 0.6057 - val_loss: 0.7439 - val_accuracy: 0.3878\n",
      "Epoch 2170/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3655 - accuracy: 0.5930 - val_loss: 0.7517 - val_accuracy: 0.3918\n",
      "Epoch 2171/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3752 - accuracy: 0.5893 - val_loss: 0.7413 - val_accuracy: 0.3886\n",
      "Epoch 2172/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3675 - accuracy: 0.5969 - val_loss: 0.7488 - val_accuracy: 0.3884\n",
      "Epoch 2173/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3666 - accuracy: 0.5964 - val_loss: 0.7492 - val_accuracy: 0.3918\n",
      "Epoch 2174/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3676 - accuracy: 0.5927 - val_loss: 0.7642 - val_accuracy: 0.3896\n",
      "Epoch 2175/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3731 - accuracy: 0.5920 - val_loss: 0.7612 - val_accuracy: 0.3948\n",
      "Epoch 2176/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3590 - accuracy: 0.6038 - val_loss: 0.7527 - val_accuracy: 0.3919\n",
      "Epoch 2177/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3726 - accuracy: 0.5938 - val_loss: 0.7613 - val_accuracy: 0.3904\n",
      "Epoch 2178/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3716 - accuracy: 0.5956 - val_loss: 0.7503 - val_accuracy: 0.3895\n",
      "Epoch 2179/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3663 - accuracy: 0.5949 - val_loss: 0.7582 - val_accuracy: 0.3916\n",
      "Epoch 2180/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3684 - accuracy: 0.5967 - val_loss: 0.7583 - val_accuracy: 0.3960\n",
      "Epoch 2181/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3703 - accuracy: 0.5955 - val_loss: 0.7621 - val_accuracy: 0.3878\n",
      "Epoch 2182/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3735 - accuracy: 0.5917 - val_loss: 0.7537 - val_accuracy: 0.3934\n",
      "Epoch 2183/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3669 - accuracy: 0.5963 - val_loss: 0.7516 - val_accuracy: 0.3913\n",
      "Epoch 2184/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3683 - accuracy: 0.5943 - val_loss: 0.7454 - val_accuracy: 0.3888\n",
      "Epoch 2185/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3702 - accuracy: 0.5946 - val_loss: 0.7233 - val_accuracy: 0.3866\n",
      "Epoch 2186/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3689 - accuracy: 0.5931 - val_loss: 0.7387 - val_accuracy: 0.3910\n",
      "Epoch 2187/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3622 - accuracy: 0.5977 - val_loss: 0.7440 - val_accuracy: 0.3910\n",
      "Epoch 2188/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3607 - accuracy: 0.6010 - val_loss: 0.7520 - val_accuracy: 0.3874\n",
      "Epoch 2189/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3618 - accuracy: 0.6010 - val_loss: 0.7588 - val_accuracy: 0.3879\n",
      "Epoch 2190/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3752 - accuracy: 0.5891 - val_loss: 0.7499 - val_accuracy: 0.3922\n",
      "Epoch 2191/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3619 - accuracy: 0.6030 - val_loss: 0.7545 - val_accuracy: 0.3900\n",
      "Epoch 2192/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3617 - accuracy: 0.6018 - val_loss: 0.7341 - val_accuracy: 0.3882\n",
      "Epoch 2193/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3688 - accuracy: 0.5954 - val_loss: 0.7631 - val_accuracy: 0.3923\n",
      "Epoch 2194/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3631 - accuracy: 0.5999 - val_loss: 0.7654 - val_accuracy: 0.3914\n",
      "Epoch 2195/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3637 - accuracy: 0.6014 - val_loss: 0.7531 - val_accuracy: 0.3904\n",
      "Epoch 2196/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3694 - accuracy: 0.5990 - val_loss: 0.7587 - val_accuracy: 0.3906\n",
      "Epoch 2197/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3661 - accuracy: 0.5998 - val_loss: 0.7657 - val_accuracy: 0.3918\n",
      "Epoch 2198/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3669 - accuracy: 0.5985 - val_loss: 0.7618 - val_accuracy: 0.3889\n",
      "Epoch 2199/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3688 - accuracy: 0.5935 - val_loss: 0.7681 - val_accuracy: 0.3881\n",
      "Epoch 2200/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3601 - accuracy: 0.5998 - val_loss: 0.7664 - val_accuracy: 0.3893\n",
      "Epoch 2201/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3706 - accuracy: 0.5962 - val_loss: 0.7524 - val_accuracy: 0.3896\n",
      "Epoch 2202/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3642 - accuracy: 0.5995 - val_loss: 0.7548 - val_accuracy: 0.3918\n",
      "Epoch 2203/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3617 - accuracy: 0.6016 - val_loss: 0.7497 - val_accuracy: 0.3889\n",
      "Epoch 2204/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3633 - accuracy: 0.6032 - val_loss: 0.7624 - val_accuracy: 0.3938\n",
      "Epoch 2205/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3681 - accuracy: 0.5951 - val_loss: 0.7522 - val_accuracy: 0.3915\n",
      "Epoch 2206/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3622 - accuracy: 0.6026 - val_loss: 0.7509 - val_accuracy: 0.3906\n",
      "Epoch 2207/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3639 - accuracy: 0.5975 - val_loss: 0.7656 - val_accuracy: 0.3880\n",
      "Epoch 2208/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3608 - accuracy: 0.6036 - val_loss: 0.7691 - val_accuracy: 0.3899\n",
      "Epoch 2209/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3649 - accuracy: 0.5952 - val_loss: 0.7337 - val_accuracy: 0.3887\n",
      "Epoch 2210/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3644 - accuracy: 0.6003 - val_loss: 0.7447 - val_accuracy: 0.3917\n",
      "Epoch 2211/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3683 - accuracy: 0.5940 - val_loss: 0.7440 - val_accuracy: 0.3855\n",
      "Epoch 2212/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3755 - accuracy: 0.5908 - val_loss: 0.7427 - val_accuracy: 0.3940\n",
      "Epoch 2213/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3709 - accuracy: 0.5920 - val_loss: 0.7413 - val_accuracy: 0.3873\n",
      "Epoch 2214/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3620 - accuracy: 0.6005 - val_loss: 0.7332 - val_accuracy: 0.3896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2215/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3646 - accuracy: 0.6002 - val_loss: 0.7501 - val_accuracy: 0.3913\n",
      "Epoch 2216/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3638 - accuracy: 0.6005 - val_loss: 0.7574 - val_accuracy: 0.3913\n",
      "Epoch 2217/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3673 - accuracy: 0.5982 - val_loss: 0.7596 - val_accuracy: 0.3910\n",
      "Epoch 2218/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3655 - accuracy: 0.5998 - val_loss: 0.7649 - val_accuracy: 0.3897\n",
      "Epoch 2219/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3700 - accuracy: 0.5950 - val_loss: 0.7464 - val_accuracy: 0.3911\n",
      "Epoch 2220/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3627 - accuracy: 0.5996 - val_loss: 0.7448 - val_accuracy: 0.3903\n",
      "Epoch 2221/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3616 - accuracy: 0.6019 - val_loss: 0.7569 - val_accuracy: 0.3895\n",
      "Epoch 2222/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3633 - accuracy: 0.6006 - val_loss: 0.7491 - val_accuracy: 0.3883\n",
      "Epoch 2223/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3669 - accuracy: 0.5943 - val_loss: 0.7503 - val_accuracy: 0.3853\n",
      "Epoch 2224/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3714 - accuracy: 0.5910 - val_loss: 0.7498 - val_accuracy: 0.3882\n",
      "Epoch 2225/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3627 - accuracy: 0.5996 - val_loss: 0.7541 - val_accuracy: 0.3884\n",
      "Epoch 2226/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3675 - accuracy: 0.5914 - val_loss: 0.7591 - val_accuracy: 0.3950\n",
      "Epoch 2227/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3743 - accuracy: 0.5888 - val_loss: 0.7654 - val_accuracy: 0.3869\n",
      "Epoch 2228/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3645 - accuracy: 0.5969 - val_loss: 0.7550 - val_accuracy: 0.3879\n",
      "Epoch 2229/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3617 - accuracy: 0.6028 - val_loss: 0.7495 - val_accuracy: 0.3898\n",
      "Epoch 2230/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3656 - accuracy: 0.5969 - val_loss: 0.7442 - val_accuracy: 0.3886\n",
      "Epoch 2231/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3800 - accuracy: 0.5876 - val_loss: 0.7395 - val_accuracy: 0.3922\n",
      "Epoch 2232/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3642 - accuracy: 0.5988 - val_loss: 0.7523 - val_accuracy: 0.3912\n",
      "Epoch 2233/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3646 - accuracy: 0.5963 - val_loss: 0.7492 - val_accuracy: 0.3843\n",
      "Epoch 2234/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3617 - accuracy: 0.6014 - val_loss: 0.7509 - val_accuracy: 0.3907\n",
      "Epoch 2235/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3591 - accuracy: 0.6026 - val_loss: 0.7596 - val_accuracy: 0.3887\n",
      "Epoch 2236/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3554 - accuracy: 0.6078 - val_loss: 0.7506 - val_accuracy: 0.3922\n",
      "Epoch 2237/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3623 - accuracy: 0.5972 - val_loss: 0.7419 - val_accuracy: 0.3875\n",
      "Epoch 2238/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3626 - accuracy: 0.6034 - val_loss: 0.7490 - val_accuracy: 0.3889\n",
      "Epoch 2239/2500\n",
      "32958/32958 [==============================] - 1s 46us/step - loss: 0.3683 - accuracy: 0.5969 - val_loss: 0.7464 - val_accuracy: 0.3913\n",
      "Epoch 2240/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3703 - accuracy: 0.5969 - val_loss: 0.7444 - val_accuracy: 0.3919\n",
      "Epoch 2241/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3641 - accuracy: 0.6010 - val_loss: 0.7642 - val_accuracy: 0.3920\n",
      "Epoch 2242/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3929 - accuracy: 0.5789 - val_loss: 0.7357 - val_accuracy: 0.3920\n",
      "Epoch 2243/2500\n",
      "32958/32958 [==============================] - 1s 46us/step - loss: 0.3748 - accuracy: 0.5928 - val_loss: 0.7420 - val_accuracy: 0.3914\n",
      "Epoch 2244/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3950 - accuracy: 0.5721 - val_loss: 0.7361 - val_accuracy: 0.3908\n",
      "Epoch 2245/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3697 - accuracy: 0.5968 - val_loss: 0.7592 - val_accuracy: 0.3907\n",
      "Epoch 2246/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.3662 - accuracy: 0.5990 - val_loss: 0.7454 - val_accuracy: 0.3893\n",
      "Epoch 2247/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3720 - accuracy: 0.5908 - val_loss: 0.7458 - val_accuracy: 0.3917\n",
      "Epoch 2248/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.3645 - accuracy: 0.5998 - val_loss: 0.7587 - val_accuracy: 0.3934\n",
      "Epoch 2249/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.3577 - accuracy: 0.6046 - val_loss: 0.7588 - val_accuracy: 0.3926\n",
      "Epoch 2250/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3623 - accuracy: 0.6010 - val_loss: 0.7534 - val_accuracy: 0.3907\n",
      "Epoch 2251/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3680 - accuracy: 0.5951 - val_loss: 0.7530 - val_accuracy: 0.3872\n",
      "Epoch 2252/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.3818 - accuracy: 0.5886 - val_loss: 0.7355 - val_accuracy: 0.3888\n",
      "Epoch 2253/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3657 - accuracy: 0.6004 - val_loss: 0.7502 - val_accuracy: 0.3887\n",
      "Epoch 2254/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3618 - accuracy: 0.6021 - val_loss: 0.7387 - val_accuracy: 0.3905\n",
      "Epoch 2255/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3608 - accuracy: 0.6017 - val_loss: 0.7457 - val_accuracy: 0.3901\n",
      "Epoch 2256/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3548 - accuracy: 0.6067 - val_loss: 0.7644 - val_accuracy: 0.3910\n",
      "Epoch 2257/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3883 - accuracy: 0.5881 - val_loss: 0.7447 - val_accuracy: 0.3868\n",
      "Epoch 2258/2500\n",
      "32958/32958 [==============================] - 2s 57us/step - loss: 0.3681 - accuracy: 0.5972 - val_loss: 0.7617 - val_accuracy: 0.3888\n",
      "Epoch 2259/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3689 - accuracy: 0.5941 - val_loss: 0.7374 - val_accuracy: 0.3862\n",
      "Epoch 2260/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.3667 - accuracy: 0.5958 - val_loss: 0.7467 - val_accuracy: 0.3891\n",
      "Epoch 2261/2500\n",
      "32958/32958 [==============================] - 2s 57us/step - loss: 0.3607 - accuracy: 0.6024 - val_loss: 0.7524 - val_accuracy: 0.3897\n",
      "Epoch 2262/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3572 - accuracy: 0.6063 - val_loss: 0.7491 - val_accuracy: 0.3902\n",
      "Epoch 2263/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3612 - accuracy: 0.5994 - val_loss: 0.7746 - val_accuracy: 0.3927\n",
      "Epoch 2264/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3590 - accuracy: 0.6036 - val_loss: 0.7503 - val_accuracy: 0.3932\n",
      "Epoch 2265/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3586 - accuracy: 0.6056 - val_loss: 0.7514 - val_accuracy: 0.3849\n",
      "Epoch 2266/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.3664 - accuracy: 0.5972 - val_loss: 0.7510 - val_accuracy: 0.3870\n",
      "Epoch 2267/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3630 - accuracy: 0.5999 - val_loss: 0.7520 - val_accuracy: 0.3900\n",
      "Epoch 2268/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3603 - accuracy: 0.6063 - val_loss: 0.7591 - val_accuracy: 0.3912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2269/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3604 - accuracy: 0.6026 - val_loss: 0.7397 - val_accuracy: 0.3874\n",
      "Epoch 2270/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3588 - accuracy: 0.6031 - val_loss: 0.7596 - val_accuracy: 0.3874\n",
      "Epoch 2271/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3637 - accuracy: 0.5966 - val_loss: 0.7545 - val_accuracy: 0.3900\n",
      "Epoch 2272/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3606 - accuracy: 0.6024 - val_loss: 0.7553 - val_accuracy: 0.3889\n",
      "Epoch 2273/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3599 - accuracy: 0.6036 - val_loss: 0.7495 - val_accuracy: 0.3917\n",
      "Epoch 2274/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3614 - accuracy: 0.6028 - val_loss: 0.7499 - val_accuracy: 0.3889\n",
      "Epoch 2275/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3611 - accuracy: 0.6028 - val_loss: 0.7487 - val_accuracy: 0.3898\n",
      "Epoch 2276/2500\n",
      "32958/32958 [==============================] - 1s 41us/step - loss: 0.3636 - accuracy: 0.6020 - val_loss: 0.7393 - val_accuracy: 0.3915\n",
      "Epoch 2277/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3692 - accuracy: 0.5995 - val_loss: 0.7578 - val_accuracy: 0.3939\n",
      "Epoch 2278/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3694 - accuracy: 0.5952 - val_loss: 0.7299 - val_accuracy: 0.3903\n",
      "Epoch 2279/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3684 - accuracy: 0.5969 - val_loss: 0.7709 - val_accuracy: 0.3958\n",
      "Epoch 2280/2500\n",
      "32958/32958 [==============================] - 1s 41us/step - loss: 0.3639 - accuracy: 0.5983 - val_loss: 0.7467 - val_accuracy: 0.3886\n",
      "Epoch 2281/2500\n",
      "32958/32958 [==============================] - 1s 41us/step - loss: 0.3639 - accuracy: 0.5969 - val_loss: 0.7381 - val_accuracy: 0.3889\n",
      "Epoch 2282/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3631 - accuracy: 0.5997 - val_loss: 0.7459 - val_accuracy: 0.3902\n",
      "Epoch 2283/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3659 - accuracy: 0.5999 - val_loss: 0.7546 - val_accuracy: 0.3899\n",
      "Epoch 2284/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3611 - accuracy: 0.6040 - val_loss: 0.7477 - val_accuracy: 0.3910\n",
      "Epoch 2285/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3620 - accuracy: 0.6036 - val_loss: 0.7506 - val_accuracy: 0.3890\n",
      "Epoch 2286/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3668 - accuracy: 0.5955 - val_loss: 0.7511 - val_accuracy: 0.3917\n",
      "Epoch 2287/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3682 - accuracy: 0.5955 - val_loss: 0.7403 - val_accuracy: 0.3872\n",
      "Epoch 2288/2500\n",
      "32958/32958 [==============================] - 1s 41us/step - loss: 0.3715 - accuracy: 0.5891 - val_loss: 0.7371 - val_accuracy: 0.3878\n",
      "Epoch 2289/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3682 - accuracy: 0.5942 - val_loss: 0.7504 - val_accuracy: 0.3904\n",
      "Epoch 2290/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3635 - accuracy: 0.6000 - val_loss: 0.7642 - val_accuracy: 0.3929\n",
      "Epoch 2291/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3582 - accuracy: 0.6036 - val_loss: 0.7664 - val_accuracy: 0.3933\n",
      "Epoch 2292/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3605 - accuracy: 0.6036 - val_loss: 0.7551 - val_accuracy: 0.3941\n",
      "Epoch 2293/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3599 - accuracy: 0.6043 - val_loss: 0.7554 - val_accuracy: 0.3874\n",
      "Epoch 2294/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3666 - accuracy: 0.6006 - val_loss: 0.7461 - val_accuracy: 0.3898\n",
      "Epoch 2295/2500\n",
      "32958/32958 [==============================] - 1s 41us/step - loss: 0.3637 - accuracy: 0.5990 - val_loss: 0.7773 - val_accuracy: 0.3946\n",
      "Epoch 2296/2500\n",
      "32958/32958 [==============================] - 1s 41us/step - loss: 0.3622 - accuracy: 0.6029 - val_loss: 0.7716 - val_accuracy: 0.3889\n",
      "Epoch 2297/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3638 - accuracy: 0.5973 - val_loss: 0.7833 - val_accuracy: 0.3910\n",
      "Epoch 2298/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3611 - accuracy: 0.6019 - val_loss: 0.7544 - val_accuracy: 0.3924\n",
      "Epoch 2299/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3584 - accuracy: 0.6053 - val_loss: 0.7659 - val_accuracy: 0.3917\n",
      "Epoch 2300/2500\n",
      "32958/32958 [==============================] - 2s 57us/step - loss: 0.3614 - accuracy: 0.6034 - val_loss: 0.7678 - val_accuracy: 0.3914\n",
      "Epoch 2301/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3585 - accuracy: 0.6060 - val_loss: 0.7623 - val_accuracy: 0.3914\n",
      "Epoch 2302/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3625 - accuracy: 0.6013 - val_loss: 0.7645 - val_accuracy: 0.3907\n",
      "Epoch 2303/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3729 - accuracy: 0.5929 - val_loss: 0.7450 - val_accuracy: 0.3949\n",
      "Epoch 2304/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3665 - accuracy: 0.5973 - val_loss: 0.7662 - val_accuracy: 0.3942\n",
      "Epoch 2305/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3576 - accuracy: 0.6041 - val_loss: 0.7518 - val_accuracy: 0.3897\n",
      "Epoch 2306/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3660 - accuracy: 0.5974 - val_loss: 0.7653 - val_accuracy: 0.3920\n",
      "Epoch 2307/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3682 - accuracy: 0.5982 - val_loss: 0.7451 - val_accuracy: 0.3925\n",
      "Epoch 2308/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3607 - accuracy: 0.6030 - val_loss: 0.7568 - val_accuracy: 0.3903\n",
      "Epoch 2309/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3593 - accuracy: 0.6065 - val_loss: 0.7654 - val_accuracy: 0.3961\n",
      "Epoch 2310/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3616 - accuracy: 0.5978 - val_loss: 0.7517 - val_accuracy: 0.3884\n",
      "Epoch 2311/2500\n",
      "32958/32958 [==============================] - 2s 62us/step - loss: 0.3618 - accuracy: 0.6013 - val_loss: 0.7463 - val_accuracy: 0.3918\n",
      "Epoch 2312/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3685 - accuracy: 0.5987 - val_loss: 0.7533 - val_accuracy: 0.3918\n",
      "Epoch 2313/2500\n",
      "32958/32958 [==============================] - 2s 62us/step - loss: 0.3613 - accuracy: 0.6000 - val_loss: 0.7564 - val_accuracy: 0.3910\n",
      "Epoch 2314/2500\n",
      "32958/32958 [==============================] - 2s 59us/step - loss: 0.3936 - accuracy: 0.5749 - val_loss: 0.7336 - val_accuracy: 0.3846\n",
      "Epoch 2315/2500\n",
      "32958/32958 [==============================] - 2s 65us/step - loss: 0.3826 - accuracy: 0.5827 - val_loss: 0.7431 - val_accuracy: 0.3938\n",
      "Epoch 2316/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3673 - accuracy: 0.5984 - val_loss: 0.7414 - val_accuracy: 0.3897\n",
      "Epoch 2317/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3655 - accuracy: 0.5970 - val_loss: 0.7437 - val_accuracy: 0.3906\n",
      "Epoch 2318/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3681 - accuracy: 0.5933 - val_loss: 0.7565 - val_accuracy: 0.3938\n",
      "Epoch 2319/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3600 - accuracy: 0.6012 - val_loss: 0.7676 - val_accuracy: 0.3934\n",
      "Epoch 2320/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3557 - accuracy: 0.6042 - val_loss: 0.7574 - val_accuracy: 0.3950\n",
      "Epoch 2321/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3581 - accuracy: 0.6055 - val_loss: 0.7602 - val_accuracy: 0.3933\n",
      "Epoch 2322/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3683 - accuracy: 0.5999 - val_loss: 0.7573 - val_accuracy: 0.3944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2323/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3622 - accuracy: 0.6018 - val_loss: 0.7482 - val_accuracy: 0.3907\n",
      "Epoch 2324/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3645 - accuracy: 0.6024 - val_loss: 0.7571 - val_accuracy: 0.3940\n",
      "Epoch 2325/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3658 - accuracy: 0.5988 - val_loss: 0.7499 - val_accuracy: 0.3913\n",
      "Epoch 2326/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3610 - accuracy: 0.6023 - val_loss: 0.7469 - val_accuracy: 0.3897\n",
      "Epoch 2327/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3511 - accuracy: 0.6075 - val_loss: 0.7579 - val_accuracy: 0.3918\n",
      "Epoch 2328/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3726 - accuracy: 0.5930 - val_loss: 0.7470 - val_accuracy: 0.3917\n",
      "Epoch 2329/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3660 - accuracy: 0.5961 - val_loss: 0.7549 - val_accuracy: 0.3922\n",
      "Epoch 2330/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3690 - accuracy: 0.5958 - val_loss: 0.7498 - val_accuracy: 0.3929\n",
      "Epoch 2331/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3668 - accuracy: 0.5969 - val_loss: 0.7556 - val_accuracy: 0.3930\n",
      "Epoch 2332/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3634 - accuracy: 0.6028 - val_loss: 0.7490 - val_accuracy: 0.3930\n",
      "Epoch 2333/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3652 - accuracy: 0.5986 - val_loss: 0.7462 - val_accuracy: 0.3944\n",
      "Epoch 2334/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3774 - accuracy: 0.5877 - val_loss: 0.7519 - val_accuracy: 0.3926\n",
      "Epoch 2335/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3624 - accuracy: 0.6018 - val_loss: 0.7397 - val_accuracy: 0.3905\n",
      "Epoch 2336/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3680 - accuracy: 0.5977 - val_loss: 0.7524 - val_accuracy: 0.3917\n",
      "Epoch 2337/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3622 - accuracy: 0.6038 - val_loss: 0.7684 - val_accuracy: 0.3921\n",
      "Epoch 2338/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3620 - accuracy: 0.6045 - val_loss: 0.7594 - val_accuracy: 0.3934\n",
      "Epoch 2339/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3581 - accuracy: 0.6015 - val_loss: 0.7656 - val_accuracy: 0.3939\n",
      "Epoch 2340/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3519 - accuracy: 0.6110 - val_loss: 0.7684 - val_accuracy: 0.3921\n",
      "Epoch 2341/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3589 - accuracy: 0.6045 - val_loss: 0.7612 - val_accuracy: 0.3891\n",
      "Epoch 2342/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3603 - accuracy: 0.6056 - val_loss: 0.7634 - val_accuracy: 0.3933\n",
      "Epoch 2343/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3628 - accuracy: 0.6040 - val_loss: 0.7436 - val_accuracy: 0.3892\n",
      "Epoch 2344/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3628 - accuracy: 0.6001 - val_loss: 0.7725 - val_accuracy: 0.3949\n",
      "Epoch 2345/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3625 - accuracy: 0.6007 - val_loss: 0.7521 - val_accuracy: 0.3930\n",
      "Epoch 2346/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3655 - accuracy: 0.5983 - val_loss: 0.7452 - val_accuracy: 0.3882\n",
      "Epoch 2347/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3671 - accuracy: 0.5953 - val_loss: 0.7503 - val_accuracy: 0.3964\n",
      "Epoch 2348/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3600 - accuracy: 0.6045 - val_loss: 0.7573 - val_accuracy: 0.3910\n",
      "Epoch 2349/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3543 - accuracy: 0.6051 - val_loss: 0.7536 - val_accuracy: 0.3917\n",
      "Epoch 2350/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3584 - accuracy: 0.6055 - val_loss: 0.7715 - val_accuracy: 0.3938\n",
      "Epoch 2351/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3580 - accuracy: 0.6096 - val_loss: 0.7736 - val_accuracy: 0.3896\n",
      "Epoch 2352/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3583 - accuracy: 0.6077 - val_loss: 0.7597 - val_accuracy: 0.3932\n",
      "Epoch 2353/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3572 - accuracy: 0.6073 - val_loss: 0.7570 - val_accuracy: 0.3895\n",
      "Epoch 2354/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3544 - accuracy: 0.6117 - val_loss: 0.7653 - val_accuracy: 0.3909\n",
      "Epoch 2355/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3585 - accuracy: 0.6069 - val_loss: 0.7572 - val_accuracy: 0.3905\n",
      "Epoch 2356/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3580 - accuracy: 0.6086 - val_loss: 0.7557 - val_accuracy: 0.3910\n",
      "Epoch 2357/2500\n",
      "32958/32958 [==============================] - 1s 43us/step - loss: 0.3574 - accuracy: 0.6091 - val_loss: 0.7558 - val_accuracy: 0.3917\n",
      "Epoch 2358/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3613 - accuracy: 0.6029 - val_loss: 0.7628 - val_accuracy: 0.3907\n",
      "Epoch 2359/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3583 - accuracy: 0.6073 - val_loss: 0.7726 - val_accuracy: 0.3897\n",
      "Epoch 2360/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3646 - accuracy: 0.5964 - val_loss: 0.7692 - val_accuracy: 0.3920\n",
      "Epoch 2361/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3686 - accuracy: 0.5956 - val_loss: 0.7705 - val_accuracy: 0.3904\n",
      "Epoch 2362/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.3599 - accuracy: 0.6043 - val_loss: 0.7641 - val_accuracy: 0.3886\n",
      "Epoch 2363/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3576 - accuracy: 0.6080 - val_loss: 0.7723 - val_accuracy: 0.3879\n",
      "Epoch 2364/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3684 - accuracy: 0.5962 - val_loss: 0.7676 - val_accuracy: 0.3927\n",
      "Epoch 2365/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3651 - accuracy: 0.6015 - val_loss: 0.7568 - val_accuracy: 0.3876\n",
      "Epoch 2366/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3643 - accuracy: 0.5998 - val_loss: 0.7647 - val_accuracy: 0.3913\n",
      "Epoch 2367/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3649 - accuracy: 0.6033 - val_loss: 0.7578 - val_accuracy: 0.3941\n",
      "Epoch 2368/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3661 - accuracy: 0.5960 - val_loss: 0.7568 - val_accuracy: 0.3907\n",
      "Epoch 2369/2500\n",
      "32958/32958 [==============================] - 1s 44us/step - loss: 0.3569 - accuracy: 0.6038 - val_loss: 0.7637 - val_accuracy: 0.3836\n",
      "Epoch 2370/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3695 - accuracy: 0.5953 - val_loss: 0.7608 - val_accuracy: 0.3897\n",
      "Epoch 2371/2500\n",
      "32958/32958 [==============================] - 1s 42us/step - loss: 0.3543 - accuracy: 0.6080 - val_loss: 0.7681 - val_accuracy: 0.3897\n",
      "Epoch 2372/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3566 - accuracy: 0.6085 - val_loss: 0.7488 - val_accuracy: 0.3908\n",
      "Epoch 2373/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.3594 - accuracy: 0.6066 - val_loss: 0.7509 - val_accuracy: 0.3912\n",
      "Epoch 2374/2500\n",
      "32958/32958 [==============================] - 2s 57us/step - loss: 0.3621 - accuracy: 0.5987 - val_loss: 0.7460 - val_accuracy: 0.3902\n",
      "Epoch 2375/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3612 - accuracy: 0.6012 - val_loss: 0.7797 - val_accuracy: 0.3914\n",
      "Epoch 2376/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3626 - accuracy: 0.6016 - val_loss: 0.7442 - val_accuracy: 0.3881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2377/2500\n",
      "32958/32958 [==============================] - 2s 61us/step - loss: 0.3603 - accuracy: 0.6030 - val_loss: 0.7691 - val_accuracy: 0.3912\n",
      "Epoch 2378/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3591 - accuracy: 0.6058 - val_loss: 0.7586 - val_accuracy: 0.3900\n",
      "Epoch 2379/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3567 - accuracy: 0.6076 - val_loss: 0.7700 - val_accuracy: 0.3903\n",
      "Epoch 2380/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3586 - accuracy: 0.6084 - val_loss: 0.7693 - val_accuracy: 0.3886\n",
      "Epoch 2381/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3590 - accuracy: 0.6078 - val_loss: 0.7522 - val_accuracy: 0.3877\n",
      "Epoch 2382/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3535 - accuracy: 0.6102 - val_loss: 0.7621 - val_accuracy: 0.3879\n",
      "Epoch 2383/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3537 - accuracy: 0.6100 - val_loss: 0.7566 - val_accuracy: 0.3889\n",
      "Epoch 2384/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3593 - accuracy: 0.6028 - val_loss: 0.7689 - val_accuracy: 0.3904\n",
      "Epoch 2385/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3581 - accuracy: 0.6084 - val_loss: 0.7558 - val_accuracy: 0.3885\n",
      "Epoch 2386/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3573 - accuracy: 0.6081 - val_loss: 0.7613 - val_accuracy: 0.3902\n",
      "Epoch 2387/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3614 - accuracy: 0.6011 - val_loss: 0.7710 - val_accuracy: 0.3921\n",
      "Epoch 2388/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3620 - accuracy: 0.6007 - val_loss: 0.7495 - val_accuracy: 0.3890\n",
      "Epoch 2389/2500\n",
      "32958/32958 [==============================] - 2s 66us/step - loss: 0.3640 - accuracy: 0.6026 - val_loss: 0.7753 - val_accuracy: 0.3936\n",
      "Epoch 2390/2500\n",
      "32958/32958 [==============================] - 2s 60us/step - loss: 0.3603 - accuracy: 0.6025 - val_loss: 0.7812 - val_accuracy: 0.3940\n",
      "Epoch 2391/2500\n",
      "32958/32958 [==============================] - 2s 73us/step - loss: 0.3602 - accuracy: 0.6059 - val_loss: 0.7516 - val_accuracy: 0.3901\n",
      "Epoch 2392/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3598 - accuracy: 0.6061 - val_loss: 0.7613 - val_accuracy: 0.3900\n",
      "Epoch 2393/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3631 - accuracy: 0.6005 - val_loss: 0.7492 - val_accuracy: 0.3853\n",
      "Epoch 2394/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3586 - accuracy: 0.6044 - val_loss: 0.7616 - val_accuracy: 0.3924\n",
      "Epoch 2395/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3616 - accuracy: 0.6034 - val_loss: 0.7686 - val_accuracy: 0.3925\n",
      "Epoch 2396/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3564 - accuracy: 0.6075 - val_loss: 0.7665 - val_accuracy: 0.3928\n",
      "Epoch 2397/2500\n",
      "32958/32958 [==============================] - 2s 66us/step - loss: 0.3615 - accuracy: 0.6019 - val_loss: 0.7725 - val_accuracy: 0.3901\n",
      "Epoch 2398/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3626 - accuracy: 0.5999 - val_loss: 0.7593 - val_accuracy: 0.3910\n",
      "Epoch 2399/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3571 - accuracy: 0.6096 - val_loss: 0.7746 - val_accuracy: 0.3917\n",
      "Epoch 2400/2500\n",
      "32958/32958 [==============================] - 2s 75us/step - loss: 0.3590 - accuracy: 0.6060 - val_loss: 0.7637 - val_accuracy: 0.3942\n",
      "Epoch 2401/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3604 - accuracy: 0.6065 - val_loss: 0.7563 - val_accuracy: 0.3944\n",
      "Epoch 2402/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3686 - accuracy: 0.5925 - val_loss: 0.7586 - val_accuracy: 0.3928\n",
      "Epoch 2403/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3711 - accuracy: 0.5915 - val_loss: 0.7563 - val_accuracy: 0.3911\n",
      "Epoch 2404/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3642 - accuracy: 0.5969 - val_loss: 0.7586 - val_accuracy: 0.3949\n",
      "Epoch 2405/2500\n",
      "32958/32958 [==============================] - 1s 45us/step - loss: 0.3648 - accuracy: 0.6006 - val_loss: 0.7585 - val_accuracy: 0.3903\n",
      "Epoch 2406/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.3593 - accuracy: 0.6067 - val_loss: 0.7546 - val_accuracy: 0.3910\n",
      "Epoch 2407/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3682 - accuracy: 0.5972 - val_loss: 0.7596 - val_accuracy: 0.3895\n",
      "Epoch 2408/2500\n",
      "32958/32958 [==============================] - 2s 46us/step - loss: 0.3678 - accuracy: 0.5967 - val_loss: 0.7483 - val_accuracy: 0.3930\n",
      "Epoch 2409/2500\n",
      "32958/32958 [==============================] - 2s 48us/step - loss: 0.3576 - accuracy: 0.6059 - val_loss: 0.7630 - val_accuracy: 0.3943\n",
      "Epoch 2410/2500\n",
      "32958/32958 [==============================] - 2s 65us/step - loss: 0.3622 - accuracy: 0.5991 - val_loss: 0.7490 - val_accuracy: 0.3897\n",
      "Epoch 2411/2500\n",
      "32958/32958 [==============================] - 2s 59us/step - loss: 0.3594 - accuracy: 0.6045 - val_loss: 0.7550 - val_accuracy: 0.3912\n",
      "Epoch 2412/2500\n",
      "32958/32958 [==============================] - 2s 49us/step - loss: 0.3614 - accuracy: 0.6043 - val_loss: 0.7576 - val_accuracy: 0.3935\n",
      "Epoch 2413/2500\n",
      "32958/32958 [==============================] - 2s 61us/step - loss: 0.3614 - accuracy: 0.6029 - val_loss: 0.7675 - val_accuracy: 0.3932\n",
      "Epoch 2414/2500\n",
      "32958/32958 [==============================] - 2s 59us/step - loss: 0.3588 - accuracy: 0.6040 - val_loss: 0.7560 - val_accuracy: 0.3924\n",
      "Epoch 2415/2500\n",
      "32958/32958 [==============================] - 2s 66us/step - loss: 0.3563 - accuracy: 0.6039 - val_loss: 0.7795 - val_accuracy: 0.3925\n",
      "Epoch 2416/2500\n",
      "32958/32958 [==============================] - 2s 64us/step - loss: 0.3571 - accuracy: 0.6073 - val_loss: 0.7710 - val_accuracy: 0.3927\n",
      "Epoch 2417/2500\n",
      "32958/32958 [==============================] - 2s 61us/step - loss: 0.3649 - accuracy: 0.5982 - val_loss: 0.7689 - val_accuracy: 0.3946\n",
      "Epoch 2418/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3588 - accuracy: 0.6064 - val_loss: 0.7657 - val_accuracy: 0.3930\n",
      "Epoch 2419/2500\n",
      "32958/32958 [==============================] - 2s 60us/step - loss: 0.3591 - accuracy: 0.6057 - val_loss: 0.7666 - val_accuracy: 0.3916\n",
      "Epoch 2420/2500\n",
      "32958/32958 [==============================] - 2s 59us/step - loss: 0.3562 - accuracy: 0.6063 - val_loss: 0.7597 - val_accuracy: 0.3949\n",
      "Epoch 2421/2500\n",
      "32958/32958 [==============================] - 2s 50us/step - loss: 0.3630 - accuracy: 0.6013 - val_loss: 0.7600 - val_accuracy: 0.3929\n",
      "Epoch 2422/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3633 - accuracy: 0.6033 - val_loss: 0.7616 - val_accuracy: 0.3902\n",
      "Epoch 2423/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3588 - accuracy: 0.6047 - val_loss: 0.7628 - val_accuracy: 0.3909\n",
      "Epoch 2424/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3552 - accuracy: 0.6057 - val_loss: 0.7572 - val_accuracy: 0.3888\n",
      "Epoch 2425/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3535 - accuracy: 0.6094 - val_loss: 0.7599 - val_accuracy: 0.3928\n",
      "Epoch 2426/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3536 - accuracy: 0.6054 - val_loss: 0.7715 - val_accuracy: 0.3930\n",
      "Epoch 2427/2500\n",
      "32958/32958 [==============================] - 2s 66us/step - loss: 0.3626 - accuracy: 0.6009 - val_loss: 0.7588 - val_accuracy: 0.3933\n",
      "Epoch 2428/2500\n",
      "32958/32958 [==============================] - 2s 51us/step - loss: 0.3603 - accuracy: 0.6009 - val_loss: 0.7651 - val_accuracy: 0.3919\n",
      "Epoch 2429/2500\n",
      "32958/32958 [==============================] - 2s 57us/step - loss: 0.3578 - accuracy: 0.6087 - val_loss: 0.7691 - val_accuracy: 0.3939\n",
      "Epoch 2430/2500\n",
      "32958/32958 [==============================] - 2s 60us/step - loss: 0.3581 - accuracy: 0.6071 - val_loss: 0.7626 - val_accuracy: 0.3939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2431/2500\n",
      "32958/32958 [==============================] - 2s 64us/step - loss: 0.3597 - accuracy: 0.6005 - val_loss: 0.7713 - val_accuracy: 0.3904\n",
      "Epoch 2432/2500\n",
      "32958/32958 [==============================] - 2s 63us/step - loss: 0.3557 - accuracy: 0.6076 - val_loss: 0.7631 - val_accuracy: 0.3902\n",
      "Epoch 2433/2500\n",
      "32958/32958 [==============================] - 2s 67us/step - loss: 0.3569 - accuracy: 0.6039 - val_loss: 0.7609 - val_accuracy: 0.3931\n",
      "Epoch 2434/2500\n",
      "32958/32958 [==============================] - 2s 67us/step - loss: 0.3742 - accuracy: 0.5908 - val_loss: 0.7383 - val_accuracy: 0.3895\n",
      "Epoch 2435/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3637 - accuracy: 0.5974 - val_loss: 0.7612 - val_accuracy: 0.3956\n",
      "Epoch 2436/2500\n",
      "32958/32958 [==============================] - 2s 59us/step - loss: 0.3595 - accuracy: 0.6000 - val_loss: 0.7535 - val_accuracy: 0.3914\n",
      "Epoch 2437/2500\n",
      "32958/32958 [==============================] - 2s 72us/step - loss: 0.3660 - accuracy: 0.5986 - val_loss: 0.7482 - val_accuracy: 0.3919\n",
      "Epoch 2438/2500\n",
      "32958/32958 [==============================] - 2s 61us/step - loss: 0.3660 - accuracy: 0.5976 - val_loss: 0.7616 - val_accuracy: 0.3930\n",
      "Epoch 2439/2500\n",
      "32958/32958 [==============================] - 2s 64us/step - loss: 0.3567 - accuracy: 0.6076 - val_loss: 0.7378 - val_accuracy: 0.3928\n",
      "Epoch 2440/2500\n",
      "32958/32958 [==============================] - 2s 73us/step - loss: 0.3618 - accuracy: 0.6041 - val_loss: 0.7477 - val_accuracy: 0.3901\n",
      "Epoch 2441/2500\n",
      "32958/32958 [==============================] - 2s 65us/step - loss: 0.3561 - accuracy: 0.6086 - val_loss: 0.7442 - val_accuracy: 0.3911\n",
      "Epoch 2442/2500\n",
      "32958/32958 [==============================] - 2s 59us/step - loss: 0.3538 - accuracy: 0.6087 - val_loss: 0.7617 - val_accuracy: 0.3897\n",
      "Epoch 2443/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3580 - accuracy: 0.6061 - val_loss: 0.7555 - val_accuracy: 0.3912\n",
      "Epoch 2444/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3577 - accuracy: 0.6036 - val_loss: 0.7596 - val_accuracy: 0.3892\n",
      "Epoch 2445/2500\n",
      "32958/32958 [==============================] - 2s 59us/step - loss: 0.3598 - accuracy: 0.6032 - val_loss: 0.7670 - val_accuracy: 0.3900\n",
      "Epoch 2446/2500\n",
      "32958/32958 [==============================] - 2s 60us/step - loss: 0.3673 - accuracy: 0.5951 - val_loss: 0.7512 - val_accuracy: 0.3914\n",
      "Epoch 2447/2500\n",
      "32958/32958 [==============================] - 2s 59us/step - loss: 0.3608 - accuracy: 0.6043 - val_loss: 0.7606 - val_accuracy: 0.3933\n",
      "Epoch 2448/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3557 - accuracy: 0.6088 - val_loss: 0.7626 - val_accuracy: 0.3901\n",
      "Epoch 2449/2500\n",
      "32958/32958 [==============================] - 2s 59us/step - loss: 0.3497 - accuracy: 0.6166 - val_loss: 0.7576 - val_accuracy: 0.3904\n",
      "Epoch 2450/2500\n",
      "32958/32958 [==============================] - 2s 58us/step - loss: 0.3570 - accuracy: 0.6058 - val_loss: 0.7517 - val_accuracy: 0.3916\n",
      "Epoch 2451/2500\n",
      "32958/32958 [==============================] - 2s 64us/step - loss: 0.3572 - accuracy: 0.6066 - val_loss: 0.7510 - val_accuracy: 0.3927\n",
      "Epoch 2452/2500\n",
      "32958/32958 [==============================] - 2s 65us/step - loss: 0.3574 - accuracy: 0.6055 - val_loss: 0.7621 - val_accuracy: 0.3920\n",
      "Epoch 2453/2500\n",
      "32958/32958 [==============================] - 2s 72us/step - loss: 0.3645 - accuracy: 0.6005 - val_loss: 0.7680 - val_accuracy: 0.3896\n",
      "Epoch 2454/2500\n",
      "32958/32958 [==============================] - 3s 78us/step - loss: 0.3639 - accuracy: 0.6003 - val_loss: 0.7737 - val_accuracy: 0.3934\n",
      "Epoch 2455/2500\n",
      "32958/32958 [==============================] - 2s 64us/step - loss: 0.3602 - accuracy: 0.6015 - val_loss: 0.7732 - val_accuracy: 0.3908\n",
      "Epoch 2456/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3608 - accuracy: 0.6052 - val_loss: 0.7665 - val_accuracy: 0.3910\n",
      "Epoch 2457/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3700 - accuracy: 0.5962 - val_loss: 0.7721 - val_accuracy: 0.3969\n",
      "Epoch 2458/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3603 - accuracy: 0.6040 - val_loss: 0.7681 - val_accuracy: 0.3938\n",
      "Epoch 2459/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3619 - accuracy: 0.6008 - val_loss: 0.7632 - val_accuracy: 0.3937\n",
      "Epoch 2460/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3545 - accuracy: 0.6089 - val_loss: 0.7626 - val_accuracy: 0.3904\n",
      "Epoch 2461/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3619 - accuracy: 0.6038 - val_loss: 0.7444 - val_accuracy: 0.3870\n",
      "Epoch 2462/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3568 - accuracy: 0.6083 - val_loss: 0.7683 - val_accuracy: 0.3921\n",
      "Epoch 2463/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3578 - accuracy: 0.6079 - val_loss: 0.7369 - val_accuracy: 0.3900\n",
      "Epoch 2464/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3683 - accuracy: 0.5982 - val_loss: 0.7565 - val_accuracy: 0.3869\n",
      "Epoch 2465/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3512 - accuracy: 0.6117 - val_loss: 0.7648 - val_accuracy: 0.3905\n",
      "Epoch 2466/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3543 - accuracy: 0.6105 - val_loss: 0.7827 - val_accuracy: 0.3895\n",
      "Epoch 2467/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3579 - accuracy: 0.6053 - val_loss: 0.7748 - val_accuracy: 0.3915\n",
      "Epoch 2468/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3635 - accuracy: 0.6008 - val_loss: 0.7488 - val_accuracy: 0.3883\n",
      "Epoch 2469/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3642 - accuracy: 0.6023 - val_loss: 0.7590 - val_accuracy: 0.3880\n",
      "Epoch 2470/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3550 - accuracy: 0.6120 - val_loss: 0.7515 - val_accuracy: 0.3913\n",
      "Epoch 2471/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3597 - accuracy: 0.6018 - val_loss: 0.7677 - val_accuracy: 0.3943\n",
      "Epoch 2472/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3509 - accuracy: 0.6127 - val_loss: 0.7639 - val_accuracy: 0.3907\n",
      "Epoch 2473/2500\n",
      "32958/32958 [==============================] - 2s 57us/step - loss: 0.3580 - accuracy: 0.6028 - val_loss: 0.7610 - val_accuracy: 0.3884\n",
      "Epoch 2474/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3580 - accuracy: 0.6073 - val_loss: 0.7666 - val_accuracy: 0.3919\n",
      "Epoch 2475/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3562 - accuracy: 0.6063 - val_loss: 0.7558 - val_accuracy: 0.3896\n",
      "Epoch 2476/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3536 - accuracy: 0.6107 - val_loss: 0.7725 - val_accuracy: 0.3905\n",
      "Epoch 2477/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3563 - accuracy: 0.6085 - val_loss: 0.7569 - val_accuracy: 0.3899\n",
      "Epoch 2478/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3523 - accuracy: 0.6107 - val_loss: 0.7603 - val_accuracy: 0.3975\n",
      "Epoch 2479/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3575 - accuracy: 0.6077 - val_loss: 0.7692 - val_accuracy: 0.3920\n",
      "Epoch 2480/2500\n",
      "32958/32958 [==============================] - 2s 57us/step - loss: 0.3559 - accuracy: 0.6087 - val_loss: 0.7745 - val_accuracy: 0.3926\n",
      "Epoch 2481/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3540 - accuracy: 0.6121 - val_loss: 0.7637 - val_accuracy: 0.3931\n",
      "Epoch 2482/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3609 - accuracy: 0.6039 - val_loss: 0.7660 - val_accuracy: 0.3930\n",
      "Epoch 2483/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3637 - accuracy: 0.6014 - val_loss: 0.7649 - val_accuracy: 0.3925\n",
      "Epoch 2484/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3593 - accuracy: 0.6063 - val_loss: 0.7707 - val_accuracy: 0.3940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2485/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3608 - accuracy: 0.6063 - val_loss: 0.7674 - val_accuracy: 0.3920\n",
      "Epoch 2486/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3562 - accuracy: 0.6051 - val_loss: 0.7847 - val_accuracy: 0.3905\n",
      "Epoch 2487/2500\n",
      "32958/32958 [==============================] - 2s 55us/step - loss: 0.3542 - accuracy: 0.6076 - val_loss: 0.7647 - val_accuracy: 0.3925\n",
      "Epoch 2488/2500\n",
      "32958/32958 [==============================] - 2s 63us/step - loss: 0.3616 - accuracy: 0.6013 - val_loss: 0.7682 - val_accuracy: 0.3894\n",
      "Epoch 2489/2500\n",
      "32958/32958 [==============================] - 2s 68us/step - loss: 0.3598 - accuracy: 0.6053 - val_loss: 0.7639 - val_accuracy: 0.3910\n",
      "Epoch 2490/2500\n",
      "32958/32958 [==============================] - 2s 64us/step - loss: 0.3568 - accuracy: 0.6070 - val_loss: 0.7546 - val_accuracy: 0.3911\n",
      "Epoch 2491/2500\n",
      "32958/32958 [==============================] - 2s 69us/step - loss: 0.3554 - accuracy: 0.6046 - val_loss: 0.7674 - val_accuracy: 0.3903\n",
      "Epoch 2492/2500\n",
      "32958/32958 [==============================] - 2s 65us/step - loss: 0.3594 - accuracy: 0.6060 - val_loss: 0.7586 - val_accuracy: 0.3890\n",
      "Epoch 2493/2500\n",
      "32958/32958 [==============================] - 2s 59us/step - loss: 0.3592 - accuracy: 0.6045 - val_loss: 0.7659 - val_accuracy: 0.3930\n",
      "Epoch 2494/2500\n",
      "32958/32958 [==============================] - 2s 60us/step - loss: 0.3527 - accuracy: 0.6075 - val_loss: 0.7695 - val_accuracy: 0.3922\n",
      "Epoch 2495/2500\n",
      "32958/32958 [==============================] - 2s 54us/step - loss: 0.3533 - accuracy: 0.6118 - val_loss: 0.7617 - val_accuracy: 0.3934\n",
      "Epoch 2496/2500\n",
      "32958/32958 [==============================] - 2s 47us/step - loss: 0.3742 - accuracy: 0.5933 - val_loss: 0.7381 - val_accuracy: 0.3937\n",
      "Epoch 2497/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3620 - accuracy: 0.6021 - val_loss: 0.7601 - val_accuracy: 0.3922\n",
      "Epoch 2498/2500\n",
      "32958/32958 [==============================] - 2s 56us/step - loss: 0.3542 - accuracy: 0.6098 - val_loss: 0.7541 - val_accuracy: 0.3916\n",
      "Epoch 2499/2500\n",
      "32958/32958 [==============================] - 2s 53us/step - loss: 0.3667 - accuracy: 0.5990 - val_loss: 0.7345 - val_accuracy: 0.3905\n",
      "Epoch 2500/2500\n",
      "32958/32958 [==============================] - 2s 52us/step - loss: 0.3670 - accuracy: 0.5939 - val_loss: 0.7588 - val_accuracy: 0.3921\n"
     ]
    }
   ],
   "source": [
    "res = model.fit(X_train, y_train, epochs=2500, batch_size=128, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_training_results(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss and accuracy may show signs of overfitting but the validation accuracy appears to have reached its limit. More epochs or more layers/nodes will most likely not solve the issue. \n",
    "\n",
    "A Neural Network most likely will not beat the results from other classification models such as XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
